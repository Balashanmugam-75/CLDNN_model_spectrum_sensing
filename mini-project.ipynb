{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-22T00:47:38.724193Z","iopub.execute_input":"2023-04-22T00:47:38.724983Z","iopub.status.idle":"2023-04-22T00:47:38.737971Z","shell.execute_reply.started":"2023-04-22T00:47:38.724943Z","shell.execute_reply":"2023-04-22T00:47:38.736765Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/input/radioml2016-deepsigcom/RML2016.10a_dict.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Reshape, Conv2D, MaxPool2D, ZeroPadding2D, Dense, Dropout, Activation, Flatten, GaussianNoise\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2023-04-22T00:47:38.739371Z","iopub.execute_input":"2023-04-22T00:47:38.739924Z","iopub.status.idle":"2023-04-22T00:47:38.757239Z","shell.execute_reply.started":"2023-04-22T00:47:38.739885Z","shell.execute_reply":"2023-04-22T00:47:38.756086Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def digitizer(labels):\n    \n    unique_labels = np.unique(labels)\n    label_dict = {}\n    num = 1\n    for i in unique_labels:\n        label_dict[i] = num\n        num += 1 \n    \n    digit_label = []\n    for i in labels:\n        digit_label.append(label_dict[i])\n    \n    return label_dict,  digit_label \n    \n            \ndef onehot_encoder(L_dict,  labels):\n    num_classes = len(L_dict)\n    vector = np.zeros(num_classes)\n    vector[L_dict[labels]-1] = 1\n    return vector\n\n\n\ndef confusion_matrix_create (y_true, y_pred, labels_dict, title):\n    \n    labels = []\n    for i in labels_dict.items():\n        labels.append(i[0])\n    y_true = np.argmax(y_true, axis =1)\n    y_true = np.array(y_true) + 1\n    y_pred = np.array(y_pred) + 1\n    \n    \n    \n    updated_pred = []\n    updated_true = []\n\n    for i in range(len(y_true)):\n\n        for key,value in labels_dict.items():\n            if value == y_true[i]:\n                updated_true.append(key)\n\n            if value == y_pred[i]:\n                updated_pred.append(key)\n\n    cm = confusion_matrix(updated_true,updated_pred, labels)\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    fig, ax = plt.subplots()\n    fig.set_figheight(10)\n    fig.set_figwidth(10)\n    plt.xticks(ticks=[-1,0,1,2,3,4,5,6,7,8,9,10], rotation=45)\n    plt.yticks(ticks=[-1,0,1,2,3,4,5,6,7,8,9,10], rotation=45)\n    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    ax.figure.colorbar(im, ax=ax)\n    ax.set_xticklabels([''] + labels)\n    ax.set_yticklabels([''] + labels)\n    ax.set (title=title, \n            ylabel='True label',\n            xlabel='Predicted label')\n    fmt = '.2f' \n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T00:47:38.759088Z","iopub.execute_input":"2023-04-22T00:47:38.759493Z","iopub.status.idle":"2023-04-22T00:47:38.775366Z","shell.execute_reply.started":"2023-04-22T00:47:38.759457Z","shell.execute_reply":"2023-04-22T00:47:38.774243Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pickle \n\nwith open('/kaggle/input/radioml2016-deepsigcom/RML2016.10a_dict.pkl', \"rb\") as p:\n    d = pickle.load(p, encoding='latin1')\n\nclasses = []    \nfor i in d.keys():    \n    if i[0] not in classes:\n        classes.append(i[0])\n\n# creating class dictionary for strings to digits transformation.\nlabel_dict,  digit_label = digitizer(classes)\n\n\n\nSNRs = {}\nfor key in d.keys():\n    if key not in SNRs:\n        SNRs[key[1]] = []\nSNRs.keys()\n\n\n\nj = 0\nfor keys in d.keys():\n    for arrays in d[keys]:\n        # convert labels to one-hot encoders.\n        SNRs[keys[1]].append([onehot_encoder(label_dict, keys[0]),np.array(arrays)]) \n\noutfile = open('dataset','wb')\npickle.dump(SNRs,outfile)\noutfile.close()\n\n\noutfile = open('class_dict','wb')\npickle.dump(label_dict,outfile)\noutfile.close()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T00:47:38.776900Z","iopub.execute_input":"2023-04-22T00:47:38.777688Z","iopub.status.idle":"2023-04-22T00:47:44.768986Z","shell.execute_reply.started":"2023-04-22T00:47:38.777646Z","shell.execute_reply":"2023-04-22T00:47:44.767728Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport itertools\nfrom random import shuffle\n\nwith open('dataset', 'rb') as file:\n    data = pickle.load(file, encoding='Latin')\n\nfor key in data.keys():\n    shuffle(data[key])\n\nnew_data = {'combined': []}\nSNR_test = {}\n\nfor key in data.keys():\n    train_len = int(0.9 * len(data[key]))\n    new_data['combined'].append(data[key][:train_len])\n    SNR_test[key] = data[key][train_len:]\n\nnew_data['combined'] = list(itertools.chain.from_iterable(new_data['combined']))\n\noutfile = open('new_model_SNR_test_samples', 'wb')\npickle.dump(SNR_test, outfile)\noutfile.close()\n\noutfile = open('combined_SNR_data', 'wb')\npickle.dump(new_data, outfile)\noutfile.close()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T00:47:44.770903Z","iopub.execute_input":"2023-04-22T00:47:44.771304Z","iopub.status.idle":"2023-04-22T00:47:49.685627Z","shell.execute_reply.started":"2023-04-22T00:47:44.771265Z","shell.execute_reply":"2023-04-22T00:47:49.684118Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from keras.datasets import cifar10\nfrom keras.utils import np_utils\nfrom keras import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, LSTM, BatchNormalization\nfrom keras import metrics\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import SGD\nimport pickle\nimport matplotlib.pyplot as plt\nimport numpy as np \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import layers\nfrom keras.callbacks import EarlyStopping\n\ndef CLDNN():\n    model = Sequential()\n    model.add(Conv2D(120, 10, activation='relu', padding='same',kernel_initializer= 'glorot_uniform',input_shape=(2, 128, 1)))\n    model.add(MaxPooling2D(pool_size=(1, 2), padding='valid',  data_format=None))\n    model.add(layers.Dropout(0.3))\n\n    model.add(Conv2D(80, 10, activation='relu',kernel_initializer= 'glorot_uniform', padding='same'))\n    model.add(MaxPooling2D(pool_size=(1, 2), padding='valid',  data_format=None))\n    model.add(layers.Dropout(0.3))\n    \n    model.add(Conv2D(60, 10, activation='relu',kernel_initializer= 'glorot_uniform', padding='same'))\n    model.add(MaxPooling2D(pool_size=(1, 2), padding='valid',  data_format=None))\n    model.add(layers.Dropout(0.3))\n    \n    model.add(Dense(128, activation='relu'))\n    model.add(layers.Dropout(0.3))\n\n    model.add(Reshape((2, 2048)))\n\n    model.add(LSTM(128,activation='relu'))\n    model.add(layers.Dropout(0.3))\n\n    model.add(Dense(128, activation='relu',kernel_initializer= 'he_normal'))\n    model.add(layers.Dropout(0.3))\n\n    model.add(Dense(11, activation='softmax',kernel_initializer= 'he_normal'))\n\n    return model\n\ndef Robust_CNN():\n    \n    model = Sequential()\n    model.add(Conv2D(256, (3, 3), activation='relu', padding='same',kernel_initializer= 'glorot_uniform', input_shape=(2,128,1)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(1, 2), padding='valid',  data_format=None))\n    model.add(layers.Dropout(.3))\n    model.add(Conv2D(128, (3, 3), activation='relu', padding='same',kernel_initializer= 'glorot_uniform',))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(1, 2), padding='valid', data_format=None))\n    model.add(layers.Dropout(.3))\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_initializer= 'glorot_uniform',))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(1, 2), padding='valid', data_format=None))\n    model.add(layers.Dropout(.3))\n    model.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_initializer= 'glorot_uniform',))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(1, 2), padding='valid', data_format=None))\n    model.add(layers.Dropout(.3))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu',kernel_initializer= 'he_normal'))\n    model.add(BatchNormalization())\n    model.add(Dense(11, activation='softmax',kernel_initializer= 'he_normal'))\n    \n    return model\n\ndef DNN():\n    model = Sequential()\n    model.add(Dense(512,activation='relu'))\n    model.add(Dense(256,activation='relu'))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dense(64,activation='relu'))\n    model.add(Flatten())\n    model.add(Dense(128,activation='relu'))\n    model.add(Dense(11,activation='softmax'))\n    return model\n\ndef Robust_LSTM():\n    model = Sequential()\n    model.add(LSTM(units=300,activation='relu',input_shape=(2,128)))\n    model.add(BatchNormalization())\n    model.add(layers.Dropout(.3))\n    model.add(Reshape((2,150)))\n    model.add(LSTM(units=200,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(layers.Dropout(.3))\n    model.add(Reshape((2,25)))\n    model.add(layers.Dropout(.3))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dense(11,activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-22T06:43:30.845617Z","iopub.execute_input":"2023-04-22T06:43:30.846219Z","iopub.status.idle":"2023-04-22T06:43:40.997199Z","shell.execute_reply.started":"2023-04-22T06:43:30.846185Z","shell.execute_reply":"2023-04-22T06:43:40.996019Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\nimport os\nimport pickle\nimport numpy as np\n# Use this code only if you want to generate 20 different models corresponding to 20 SNR values\naccuracies_All = []\nconfusion_matrices_All = []\n\nfor key in SNRs.keys():\n    dataset = []\n    labels = []\n\n    for values in SNRs[key]:\n        labels.append(values[0])\n        dataset.append(values[1])\n\n    print('Starting training for SNR:', key)\n\n    N = len(dataset)\n    shuffled_indeces = np.random.permutation(range(N))\n    new_dataset = np.array(dataset)[shuffled_indeces,:,:]\n    new_labels = np.array(labels)[shuffled_indeces,:]\n\n    num_train = int(0.8*N)\n    x_train = new_dataset[:num_train,:,:]\n    y_train = new_labels[:num_train,:]\n\n    num_val = int(0.1*len(x_train))\n\n    x_val = x_train[:num_val,:,:]\n    x_val = x_val.reshape(x_val.shape[0],x_val.shape[1],x_val.shape[2], -1)\n    y_val = y_train[:num_val,:]\n\n    x_train = x_train[num_val:,:,:]\n    x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2], -1)\n    y_train = y_train[num_val:,:]\n\n    x_test = new_dataset[num_train:,:,:]\n    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2], -1)\n    y_test = new_labels[num_train:,:]\n\n    models = CLDNN()\n    opt = Adam(learning_rate=0.0003)\n    models.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n\n    num_epochs = 300\n\n    # Checkpoint for models\n    ckpt_folder = \"cldnn_models/\"\n    ckpt_file_path = 'cldnn_model_SNR_{}'.format(key)\n    if not os.path.exists(ckpt_folder):\n        os.mkdir(ckpt_folder)\n    model_ckpt_callback = ModelCheckpoint(filepath=ckpt_folder+ckpt_file_path,monitor='val_loss', mode='min', save_best_only=True)\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1, epsilon=1e-4, mode='min')\n\n    history = models.fit(x_train,\n                         y_train,\n                         epochs=num_epochs,\n                         batch_size=200,\n                         callbacks = [reduce_lr_loss, model_ckpt_callback],\n                         validation_data=(x_val, y_val))\n    loss, acc = models.evaluate(x_test, y_test, verbose=2)\n    predicted_data = models.predict(x_test)\n    accuracies_All.append([acc, key])\n    print('accuracy =', acc)\n    res = np.argmax(predicted_data, 1)\n    y_test_res = np.argmax(y_test, 1)\n    results = confusion_matrix((y_test_res+1), (res+1))\n    confusion_matrices_All.append([results, key])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T01:05:59.664115Z","iopub.execute_input":"2023-04-21T01:05:59.664885Z","iopub.status.idle":"2023-04-21T01:13:29.394581Z","shell.execute_reply.started":"2023-04-21T01:05:59.664840Z","shell.execute_reply":"2023-04-21T01:13:29.392139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pickle \n\nwith open(\"/kaggle/input/radioml2016-deepsigcom/RML2016.10a_dict.pkl\", \"rb\") as p:\n    d = pickle.load(p, encoding='latin1')\n\nclasses = []    \nfor i in d.keys():    \n    if i[0] not in classes:\n        classes.append(i[0])\n\n# creating class dictionary for strings to digits transformation.\nlabel_dict,  digit_label = digitizer(classes)\n\n\n\nSNRs = {}\nfor key in d.keys():\n    if key not in SNRs:\n        SNRs[key[1]] = []\nSNRs.keys()\n\n\n\nj = 0\nfor keys in d.keys():\n    for arrays in d[keys]:\n        # convert labels to one-hot encoders.\n        SNRs[keys[1]].append([onehot_encoder(label_dict, keys[0]),np.array(arrays)]) \n\noutfile = open('dataset','wb')\npickle.dump(SNRs,outfile)\noutfile.close()\n\n\noutfile = open('class_dict','wb')\npickle.dump(label_dict,outfile)\noutfile.close()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T00:47:49.719380Z","iopub.execute_input":"2023-04-22T00:47:49.719803Z","iopub.status.idle":"2023-04-22T00:47:55.741192Z","shell.execute_reply.started":"2023-04-22T00:47:49.719763Z","shell.execute_reply":"2023-04-22T00:47:55.740116Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pickle \nimport itertools\nfrom random import shuffle\n\nwith open('./dataset', 'rb') as file:\n    data = pickle.load(file,encoding = 'Latin')\n    \n    \n\nfor key in data.keys():  \n    shuffle(data[key])\n    \n\n\nnew_data = {'combined':[]}\nSNR_test = {}\n\n\nfor key in data.keys():\n       \n    train_len = int(0.9*len(data[key]))    \n    new_data['combined'].append(data[key][:train_len])\n    SNR_test[key] = data[key][train_len:]\n    \n    \nnew_data['combined'] = list(itertools.chain.from_iterable(new_data['combined']))   \n    \n\noutfile = open('new_model_SNR_test_samples','wb')\npickle.dump(SNR_test,outfile)\noutfile.close()\n\n\noutfile = open('combined_SNR_data','wb')\npickle.dump(new_data,outfile)\noutfile.close()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T00:47:55.744846Z","iopub.execute_input":"2023-04-22T00:47:55.745144Z","iopub.status.idle":"2023-04-22T00:48:00.855203Z","shell.execute_reply.started":"2023-04-22T00:47:55.745116Z","shell.execute_reply":"2023-04-22T00:48:00.853731Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\nimport os\nimport pickle\nimport numpy as np\n# Use this code only if you want to generate 20 different models corresponding to 20 SNR values\naccuracies_All_cnn = []\nconfusion_matrices_All_cnn = []\n\nfor key in SNRs.keys():\n    dataset = []\n    labels = []\n\n    for values in SNRs[key]:\n        labels.append(values[0])\n        dataset.append(values[1])\n\n    print('Starting training for SNR:', key)\n\n    N = len(dataset)\n    shuffled_indeces = np.random.permutation(range(N))\n    new_dataset = np.array(dataset)[shuffled_indeces,:,:]\n    new_labels = np.array(labels)[shuffled_indeces,:]\n\n    num_train = int(0.8*N)\n    x_train = new_dataset[:num_train,:,:]\n    y_train = new_labels[:num_train,:]\n\n    num_val = int(0.1*len(x_train))\n\n    x_val = x_train[:num_val,:,:]\n    x_val = x_val.reshape(x_val.shape[0],x_val.shape[1],x_val.shape[2], -1)\n    y_val = y_train[:num_val,:]\n\n    x_train = x_train[num_val:,:,:]\n    x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2], -1)\n    y_train = y_train[num_val:,:]\n\n    x_test = new_dataset[num_train:,:,:]\n    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2], -1)\n    y_test = new_labels[num_train:,:]\n\n    models_cnn = Robust_CNN()\n    opt = Adam(learning_rate=0.0003)\n    models_cnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n\n    num_epochs = 100\n\n    # Checkpoint for models\n    ckpt_folder = \"cldnn_models/\"\n    ckpt_file_path = 'cldnn_model_SNR_{}'.format(key)\n    if not os.path.exists(ckpt_folder):\n        os.mkdir(ckpt_folder)\n    model_ckpt_callback = ModelCheckpoint(filepath=ckpt_folder+ckpt_file_path,monitor='val_loss', mode='min', save_best_only=True)\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1, epsilon=1e-4, mode='min')\n\n    history_cnn = models_cnn.fit(x_train,\n                         y_train,\n                         epochs=num_epochs,\n                         batch_size=200,\n                         callbacks = [reduce_lr_loss, model_ckpt_callback],\n                         validation_data=(x_val, y_val))\n    loss, acc = models_cnn.evaluate(x_test, y_test, verbose=2)\n    predicted_data = models_cnn.predict(x_test)\n    accuracies_All_cnn.append([acc, key])\n    print('accuracy =', acc)\n    res = np.argmax(predicted_data, 1)\n    y_test_res = np.argmax(y_test, 1)\n    results = confusion_matrix((y_test_res+1), (res+1))\n    confusion_matrices_All_cnn.append([results, key])\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T00:48:00.860475Z","iopub.execute_input":"2023-04-22T00:48:00.860818Z","iopub.status.idle":"2023-04-22T01:46:25.309245Z","shell.execute_reply.started":"2023-04-22T00:48:00.860788Z","shell.execute_reply":"2023-04-22T01:46:25.308214Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Starting training for SNR: 2\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2023-04-22 00:48:07.520747: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 20s 153ms/step - loss: 2.2357 - accuracy: 0.2847 - val_loss: 2.5760 - val_accuracy: 0.0830 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.4815 - accuracy: 0.4399 - val_loss: 3.4066 - val_accuracy: 0.0830 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.1693 - accuracy: 0.5133 - val_loss: 4.5483 - val_accuracy: 0.0830 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0211 - accuracy: 0.5708 - val_loss: 5.5626 - val_accuracy: 0.0830 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.9144 - accuracy: 0.6096 - val_loss: 6.5512 - val_accuracy: 0.0830 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.8275 - accuracy: 0.6503 - val_loss: 7.4277 - val_accuracy: 0.0830 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7518 - accuracy: 0.6848 - val_loss: 8.1910 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6959 - accuracy: 0.7047 - val_loss: 9.0963 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.6391 - accuracy: 0.7313 - val_loss: 9.8004 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.5860 - accuracy: 0.7487 - val_loss: 10.2997 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.5470 - accuracy: 0.7638 - val_loss: 10.5426 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.5115 - accuracy: 0.7744 - val_loss: 10.6642 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4836 - accuracy: 0.7895 - val_loss: 10.6610 - val_accuracy: 0.0955 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4658 - accuracy: 0.7896 - val_loss: 10.1359 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4324 - accuracy: 0.8045 - val_loss: 8.2847 - val_accuracy: 0.1205 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4206 - accuracy: 0.8069 - val_loss: 6.9490 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4068 - accuracy: 0.8169 - val_loss: 4.9438 - val_accuracy: 0.1875 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3920 - accuracy: 0.8236 - val_loss: 3.9724 - val_accuracy: 0.2455 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.3859 - accuracy: 0.8210 - val_loss: 2.4342 - val_accuracy: 0.4568 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.3786 - accuracy: 0.8274 - val_loss: 1.7157 - val_accuracy: 0.5239 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.3770 - accuracy: 0.8241 - val_loss: 1.1561 - val_accuracy: 0.5795 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 5s 120ms/step - loss: 0.3588 - accuracy: 0.8298 - val_loss: 0.8579 - val_accuracy: 0.6568 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.3660 - accuracy: 0.8273 - val_loss: 0.7238 - val_accuracy: 0.7330 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.3461 - accuracy: 0.8388 - val_loss: 0.5963 - val_accuracy: 0.7864 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.3427 - accuracy: 0.8381 - val_loss: 0.4554 - val_accuracy: 0.7943 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3360 - accuracy: 0.8400 - val_loss: 0.5021 - val_accuracy: 0.7977 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3336 - accuracy: 0.8461 - val_loss: 0.4815 - val_accuracy: 0.7989 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3259 - accuracy: 0.8437 - val_loss: 0.5458 - val_accuracy: 0.7784 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3245 - accuracy: 0.8472 - val_loss: 0.5241 - val_accuracy: 0.7625 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3203 - accuracy: 0.8463 - val_loss: 0.5868 - val_accuracy: 0.7523 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3135 - accuracy: 0.8568 - val_loss: 0.5130 - val_accuracy: 0.7909 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3233 - accuracy: 0.8489 - val_loss: 0.5991 - val_accuracy: 0.7352 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3214 - accuracy: 0.8518 - val_loss: 0.7230 - val_accuracy: 0.7455 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3072 - accuracy: 0.8566 - val_loss: 1.1889 - val_accuracy: 0.6659 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3085 - accuracy: 0.8559 - val_loss: 0.6390 - val_accuracy: 0.7170 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 4s 113ms/step - loss: 0.3012 - accuracy: 0.8615 - val_loss: 0.4408 - val_accuracy: 0.7920 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 4s 102ms/step - loss: 0.2910 - accuracy: 0.8624 - val_loss: 0.4314 - val_accuracy: 0.8034 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3011 - accuracy: 0.8557 - val_loss: 0.7115 - val_accuracy: 0.7568 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.2938 - accuracy: 0.8626 - val_loss: 0.3820 - val_accuracy: 0.8261 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2913 - accuracy: 0.8630 - val_loss: 0.5668 - val_accuracy: 0.7784 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2828 - accuracy: 0.8678 - val_loss: 0.3908 - val_accuracy: 0.8375 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2825 - accuracy: 0.8669 - val_loss: 0.4098 - val_accuracy: 0.7989 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2705 - accuracy: 0.8721 - val_loss: 1.2982 - val_accuracy: 0.6705 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.2841 - accuracy: 0.8660 - val_loss: 0.3654 - val_accuracy: 0.8261 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2695 - accuracy: 0.8731 - val_loss: 0.6235 - val_accuracy: 0.7739 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 4s 114ms/step - loss: 0.2682 - accuracy: 0.8746 - val_loss: 0.3449 - val_accuracy: 0.8455 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2644 - accuracy: 0.8761 - val_loss: 0.4571 - val_accuracy: 0.7841 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2586 - accuracy: 0.8812 - val_loss: 1.0123 - val_accuracy: 0.7205 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2634 - accuracy: 0.8801 - val_loss: 0.8882 - val_accuracy: 0.7455 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2518 - accuracy: 0.8854 - val_loss: 0.4201 - val_accuracy: 0.8136 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2498 - accuracy: 0.8837 - val_loss: 0.5982 - val_accuracy: 0.7886 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 4s 111ms/step - loss: 0.2375 - accuracy: 0.8914 - val_loss: 0.3234 - val_accuracy: 0.8557 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2354 - accuracy: 0.8923 - val_loss: 0.8884 - val_accuracy: 0.7455 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2428 - accuracy: 0.8881 - val_loss: 0.8250 - val_accuracy: 0.7648 - lr: 3.0000e-04\nEpoch 55/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2340 - accuracy: 0.8948 - val_loss: 0.6028 - val_accuracy: 0.7693 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2286 - accuracy: 0.8943 - val_loss: 0.3827 - val_accuracy: 0.8307 - lr: 3.0000e-04\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2386 - accuracy: 0.8915 - val_loss: 0.6124 - val_accuracy: 0.7750 - lr: 3.0000e-04\nEpoch 58/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.2333 - accuracy: 0.8899 - val_loss: 0.3036 - val_accuracy: 0.8682 - lr: 3.0000e-04\nEpoch 59/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2201 - accuracy: 0.8975 - val_loss: 0.3766 - val_accuracy: 0.8455 - lr: 3.0000e-04\nEpoch 60/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2179 - accuracy: 0.9043 - val_loss: 0.4967 - val_accuracy: 0.7943 - lr: 3.0000e-04\nEpoch 61/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.2185 - accuracy: 0.9014 - val_loss: 0.2949 - val_accuracy: 0.8636 - lr: 3.0000e-04\nEpoch 62/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2085 - accuracy: 0.9052 - val_loss: 0.3986 - val_accuracy: 0.8341 - lr: 3.0000e-04\nEpoch 63/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2067 - accuracy: 0.9000 - val_loss: 0.6542 - val_accuracy: 0.7864 - lr: 3.0000e-04\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2142 - accuracy: 0.9015 - val_loss: 0.3083 - val_accuracy: 0.8716 - lr: 3.0000e-04\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2146 - accuracy: 0.9018 - val_loss: 0.3302 - val_accuracy: 0.8557 - lr: 3.0000e-04\nEpoch 66/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.2027 - accuracy: 0.9063 - val_loss: 0.2782 - val_accuracy: 0.8739 - lr: 3.0000e-04\nEpoch 67/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2027 - accuracy: 0.9067 - val_loss: 0.6801 - val_accuracy: 0.7841 - lr: 3.0000e-04\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2088 - accuracy: 0.9048 - val_loss: 0.3283 - val_accuracy: 0.8614 - lr: 3.0000e-04\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2007 - accuracy: 0.9071 - val_loss: 0.2814 - val_accuracy: 0.8716 - lr: 3.0000e-04\nEpoch 70/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2026 - accuracy: 0.9034 - val_loss: 0.4200 - val_accuracy: 0.8239 - lr: 3.0000e-04\nEpoch 71/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2027 - accuracy: 0.9018 - val_loss: 0.8980 - val_accuracy: 0.7716 - lr: 3.0000e-04\nEpoch 72/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1905 - accuracy: 0.9090 - val_loss: 1.2369 - val_accuracy: 0.7261 - lr: 3.0000e-04\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1891 - accuracy: 0.9092 - val_loss: 0.5228 - val_accuracy: 0.8227 - lr: 3.0000e-04\nEpoch 74/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1883 - accuracy: 0.9100 - val_loss: 0.4755 - val_accuracy: 0.8023 - lr: 3.0000e-04\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1952 - accuracy: 0.9049 - val_loss: 0.3932 - val_accuracy: 0.8341 - lr: 3.0000e-04\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1924 - accuracy: 0.9096 - val_loss: 1.0436 - val_accuracy: 0.7750 - lr: 3.0000e-04\nEpoch 77/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1828 - accuracy: 0.9138 - val_loss: 0.4312 - val_accuracy: 0.8364 - lr: 3.0000e-04\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1826 - accuracy: 0.9138 - val_loss: 0.2923 - val_accuracy: 0.8727 - lr: 3.0000e-04\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1804 - accuracy: 0.9144 - val_loss: 0.4651 - val_accuracy: 0.8330 - lr: 3.0000e-04\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1825 - accuracy: 0.9144 - val_loss: 0.8908 - val_accuracy: 0.7705 - lr: 3.0000e-04\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1792 - accuracy: 0.9129 - val_loss: 0.2999 - val_accuracy: 0.8648 - lr: 3.0000e-04\nEpoch 82/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1740 - accuracy: 0.9159 - val_loss: 0.7687 - val_accuracy: 0.7841 - lr: 3.0000e-04\nEpoch 83/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1724 - accuracy: 0.9173 - val_loss: 0.4078 - val_accuracy: 0.8466 - lr: 3.0000e-04\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1718 - accuracy: 0.9174 - val_loss: 0.6940 - val_accuracy: 0.7955 - lr: 3.0000e-04\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1680 - accuracy: 0.9181 - val_loss: 0.3153 - val_accuracy: 0.8648 - lr: 3.0000e-04\nEpoch 86/100\n39/40 [============================>.] - ETA: 0s - loss: 0.1659 - accuracy: 0.9187\nEpoch 86: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.1658 - accuracy: 0.9189 - val_loss: 0.4343 - val_accuracy: 0.8273 - lr: 3.0000e-04\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1611 - accuracy: 0.9241 - val_loss: 0.2835 - val_accuracy: 0.8750 - lr: 3.0000e-05\nEpoch 88/100\n40/40 [==============================] - 5s 116ms/step - loss: 0.1634 - accuracy: 0.9207 - val_loss: 0.2676 - val_accuracy: 0.8841 - lr: 3.0000e-05\nEpoch 89/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.1551 - accuracy: 0.9288 - val_loss: 0.2657 - val_accuracy: 0.8886 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1554 - accuracy: 0.9273 - val_loss: 0.2854 - val_accuracy: 0.8750 - lr: 3.0000e-05\nEpoch 91/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.1526 - accuracy: 0.9279 - val_loss: 0.2708 - val_accuracy: 0.8841 - lr: 3.0000e-05\nEpoch 92/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1544 - accuracy: 0.9283 - val_loss: 0.2888 - val_accuracy: 0.8818 - lr: 3.0000e-05\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1553 - accuracy: 0.9258 - val_loss: 0.2674 - val_accuracy: 0.8886 - lr: 3.0000e-05\nEpoch 94/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.1528 - accuracy: 0.9279 - val_loss: 0.2621 - val_accuracy: 0.8864 - lr: 3.0000e-05\nEpoch 95/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1536 - accuracy: 0.9280 - val_loss: 0.2667 - val_accuracy: 0.8852 - lr: 3.0000e-05\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1534 - accuracy: 0.9274 - val_loss: 0.2644 - val_accuracy: 0.8886 - lr: 3.0000e-05\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1498 - accuracy: 0.9301 - val_loss: 0.2654 - val_accuracy: 0.8864 - lr: 3.0000e-05\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1466 - accuracy: 0.9327 - val_loss: 0.2652 - val_accuracy: 0.8830 - lr: 3.0000e-05\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1479 - accuracy: 0.9317 - val_loss: 0.2646 - val_accuracy: 0.8852 - lr: 3.0000e-05\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1495 - accuracy: 0.9284 - val_loss: 0.2693 - val_accuracy: 0.8818 - lr: 3.0000e-05\n69/69 - 0s - loss: 0.3153 - accuracy: 0.8732 - 493ms/epoch - 7ms/step\n69/69 [==============================] - 0s 4ms/step\naccuracy = 0.8731818199157715\nStarting training for SNR: 8\nEpoch 1/100\n 1/40 [..............................] - ETA: 41s - loss: 3.2666 - accuracy: 0.1000","output_type":"stream"},{"name":"stderr","text":"2023-04-22 00:51:21.454886: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_4/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 6s 117ms/step - loss: 2.2147 - accuracy: 0.2828 - val_loss: 2.7893 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6109 - accuracy: 0.4085 - val_loss: 4.2071 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3338 - accuracy: 0.4938 - val_loss: 6.0926 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1331 - accuracy: 0.5707 - val_loss: 7.7451 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.9877 - accuracy: 0.6217 - val_loss: 9.1508 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8693 - accuracy: 0.6486 - val_loss: 10.3563 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7905 - accuracy: 0.6768 - val_loss: 11.2631 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7188 - accuracy: 0.6977 - val_loss: 11.9004 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.6692 - accuracy: 0.7106 - val_loss: 12.1643 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.6187 - accuracy: 0.7332 - val_loss: 12.6934 - val_accuracy: 0.0784 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5903 - accuracy: 0.7366 - val_loss: 12.9696 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5689 - accuracy: 0.7383 - val_loss: 12.8252 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5340 - accuracy: 0.7527 - val_loss: 12.6231 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5186 - accuracy: 0.7681 - val_loss: 12.0108 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4954 - accuracy: 0.7693 - val_loss: 10.9820 - val_accuracy: 0.0773 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4901 - accuracy: 0.7712 - val_loss: 10.6906 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4841 - accuracy: 0.7693 - val_loss: 8.1761 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4642 - accuracy: 0.7817 - val_loss: 5.6350 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4613 - accuracy: 0.7823 - val_loss: 4.8402 - val_accuracy: 0.1864 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4540 - accuracy: 0.7814 - val_loss: 2.2545 - val_accuracy: 0.3545 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4473 - accuracy: 0.7896 - val_loss: 1.2189 - val_accuracy: 0.5750 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4304 - accuracy: 0.8001 - val_loss: 1.4604 - val_accuracy: 0.5352 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.4238 - accuracy: 0.8015 - val_loss: 1.1510 - val_accuracy: 0.6170 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 100ms/step - loss: 0.4229 - accuracy: 0.8029 - val_loss: 0.7686 - val_accuracy: 0.7045 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 5s 125ms/step - loss: 0.4143 - accuracy: 0.8069 - val_loss: 0.7612 - val_accuracy: 0.6932 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4059 - accuracy: 0.8102 - val_loss: 2.3555 - val_accuracy: 0.4205 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.4020 - accuracy: 0.8167 - val_loss: 0.7020 - val_accuracy: 0.7182 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3973 - accuracy: 0.8133 - val_loss: 0.8824 - val_accuracy: 0.6557 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3945 - accuracy: 0.8165 - val_loss: 2.4175 - val_accuracy: 0.4341 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.3867 - accuracy: 0.8218 - val_loss: 0.5606 - val_accuracy: 0.7466 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3844 - accuracy: 0.8223 - val_loss: 0.7101 - val_accuracy: 0.7068 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3810 - accuracy: 0.8239 - val_loss: 0.6703 - val_accuracy: 0.7102 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.3781 - accuracy: 0.8240 - val_loss: 0.4696 - val_accuracy: 0.7898 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3648 - accuracy: 0.8342 - val_loss: 0.7062 - val_accuracy: 0.6886 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3686 - accuracy: 0.8297 - val_loss: 1.1069 - val_accuracy: 0.5989 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3617 - accuracy: 0.8351 - val_loss: 1.3494 - val_accuracy: 0.5443 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3538 - accuracy: 0.8399 - val_loss: 3.2236 - val_accuracy: 0.4898 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3487 - accuracy: 0.8429 - val_loss: 1.9988 - val_accuracy: 0.5443 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3409 - accuracy: 0.8490 - val_loss: 0.9534 - val_accuracy: 0.6386 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3388 - accuracy: 0.8452 - val_loss: 1.2279 - val_accuracy: 0.5795 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3337 - accuracy: 0.8503 - val_loss: 0.4705 - val_accuracy: 0.7773 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3360 - accuracy: 0.8457 - val_loss: 2.8797 - val_accuracy: 0.5125 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3241 - accuracy: 0.8527 - val_loss: 2.7009 - val_accuracy: 0.4989 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3255 - accuracy: 0.8535 - val_loss: 2.9648 - val_accuracy: 0.5159 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3135 - accuracy: 0.8611 - val_loss: 2.4350 - val_accuracy: 0.5375 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3074 - accuracy: 0.8625 - val_loss: 1.1192 - val_accuracy: 0.5955 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3086 - accuracy: 0.8636 - val_loss: 3.3928 - val_accuracy: 0.4932 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3119 - accuracy: 0.8566 - val_loss: 3.2503 - val_accuracy: 0.4841 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2954 - accuracy: 0.8706 - val_loss: 3.4402 - val_accuracy: 0.4830 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2962 - accuracy: 0.8717 - val_loss: 3.5128 - val_accuracy: 0.4534 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3018 - accuracy: 0.8606 - val_loss: 4.4254 - val_accuracy: 0.4625 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2893 - accuracy: 0.8754 - val_loss: 2.6724 - val_accuracy: 0.5375 - lr: 3.0000e-04\nEpoch 53/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2838 - accuracy: 0.8724\nEpoch 53: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 31ms/step - loss: 0.2834 - accuracy: 0.8723 - val_loss: 2.9458 - val_accuracy: 0.5352 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2653 - accuracy: 0.8866 - val_loss: 2.0945 - val_accuracy: 0.5625 - lr: 3.0000e-05\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2637 - accuracy: 0.8876 - val_loss: 1.1794 - val_accuracy: 0.6148 - lr: 3.0000e-05\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2611 - accuracy: 0.8898 - val_loss: 1.0241 - val_accuracy: 0.6432 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2620 - accuracy: 0.8857 - val_loss: 0.8880 - val_accuracy: 0.6830 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 4s 114ms/step - loss: 0.2585 - accuracy: 0.8927 - val_loss: 0.4607 - val_accuracy: 0.7818 - lr: 3.0000e-05\nEpoch 59/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2614 - accuracy: 0.8861 - val_loss: 0.6298 - val_accuracy: 0.7386 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2554 - accuracy: 0.8900 - val_loss: 0.6187 - val_accuracy: 0.7398 - lr: 3.0000e-05\nEpoch 61/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.2593 - accuracy: 0.8884 - val_loss: 0.3252 - val_accuracy: 0.8659 - lr: 3.0000e-05\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2627 - accuracy: 0.8879 - val_loss: 0.3288 - val_accuracy: 0.8557 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2635 - accuracy: 0.8880 - val_loss: 0.4146 - val_accuracy: 0.8068 - lr: 3.0000e-05\nEpoch 64/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2523 - accuracy: 0.8895 - val_loss: 0.6764 - val_accuracy: 0.7307 - lr: 3.0000e-05\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2493 - accuracy: 0.8943 - val_loss: 0.3354 - val_accuracy: 0.8614 - lr: 3.0000e-05\nEpoch 66/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2502 - accuracy: 0.8931 - val_loss: 0.4278 - val_accuracy: 0.7977 - lr: 3.0000e-05\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2500 - accuracy: 0.8936 - val_loss: 0.5380 - val_accuracy: 0.7659 - lr: 3.0000e-05\nEpoch 68/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.2559 - accuracy: 0.8884 - val_loss: 0.3225 - val_accuracy: 0.8625 - lr: 3.0000e-05\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2482 - accuracy: 0.8936 - val_loss: 0.3267 - val_accuracy: 0.8705 - lr: 3.0000e-05\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2537 - accuracy: 0.8895 - val_loss: 0.3867 - val_accuracy: 0.8284 - lr: 3.0000e-05\nEpoch 71/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2461 - accuracy: 0.8976 - val_loss: 0.7265 - val_accuracy: 0.7273 - lr: 3.0000e-05\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2479 - accuracy: 0.8967 - val_loss: 0.3372 - val_accuracy: 0.8602 - lr: 3.0000e-05\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2461 - accuracy: 0.8967 - val_loss: 0.5981 - val_accuracy: 0.7500 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2454 - accuracy: 0.8960 - val_loss: 0.3280 - val_accuracy: 0.8500 - lr: 3.0000e-05\nEpoch 75/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.2513 - accuracy: 0.8894 - val_loss: 0.3146 - val_accuracy: 0.8670 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2481 - accuracy: 0.8942 - val_loss: 0.4075 - val_accuracy: 0.8125 - lr: 3.0000e-05\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2447 - accuracy: 0.8929 - val_loss: 0.3965 - val_accuracy: 0.8182 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2443 - accuracy: 0.9000 - val_loss: 0.6622 - val_accuracy: 0.7386 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2448 - accuracy: 0.8970 - val_loss: 0.3777 - val_accuracy: 0.8398 - lr: 3.0000e-05\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2419 - accuracy: 0.8961 - val_loss: 0.6172 - val_accuracy: 0.7477 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2457 - accuracy: 0.8928 - val_loss: 0.4290 - val_accuracy: 0.7989 - lr: 3.0000e-05\nEpoch 82/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2431 - accuracy: 0.8963 - val_loss: 0.5842 - val_accuracy: 0.7591 - lr: 3.0000e-05\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2468 - accuracy: 0.8894 - val_loss: 0.7739 - val_accuracy: 0.7284 - lr: 3.0000e-05\nEpoch 84/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2406 - accuracy: 0.8952 - val_loss: 0.9068 - val_accuracy: 0.7011 - lr: 3.0000e-05\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2404 - accuracy: 0.8985 - val_loss: 0.7546 - val_accuracy: 0.7307 - lr: 3.0000e-05\nEpoch 86/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2436 - accuracy: 0.8961 - val_loss: 0.5869 - val_accuracy: 0.7602 - lr: 3.0000e-05\nEpoch 87/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2369 - accuracy: 0.8991 - val_loss: 1.3585 - val_accuracy: 0.6114 - lr: 3.0000e-05\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2421 - accuracy: 0.8975 - val_loss: 0.5196 - val_accuracy: 0.7682 - lr: 3.0000e-05\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2397 - accuracy: 0.8970 - val_loss: 0.3734 - val_accuracy: 0.8375 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2400 - accuracy: 0.9021 - val_loss: 0.9745 - val_accuracy: 0.6875 - lr: 3.0000e-05\nEpoch 91/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2353 - accuracy: 0.9029 - val_loss: 0.6949 - val_accuracy: 0.7375 - lr: 3.0000e-05\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2406 - accuracy: 0.8966 - val_loss: 0.4024 - val_accuracy: 0.8170 - lr: 3.0000e-05\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2384 - accuracy: 0.8981 - val_loss: 0.5721 - val_accuracy: 0.7602 - lr: 3.0000e-05\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2340 - accuracy: 0.9014 - val_loss: 0.5028 - val_accuracy: 0.7727 - lr: 3.0000e-05\nEpoch 95/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.8958\nEpoch 95: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 30ms/step - loss: 0.2340 - accuracy: 0.8961 - val_loss: 0.8101 - val_accuracy: 0.7216 - lr: 3.0000e-05\nEpoch 96/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2302 - accuracy: 0.9043 - val_loss: 0.4782 - val_accuracy: 0.7818 - lr: 3.0000e-06\nEpoch 97/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2378 - accuracy: 0.8977 - val_loss: 0.3443 - val_accuracy: 0.8545 - lr: 3.0000e-06\nEpoch 98/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2316 - accuracy: 0.9006 - val_loss: 0.3267 - val_accuracy: 0.8614 - lr: 3.0000e-06\nEpoch 99/100\n40/40 [==============================] - 4s 112ms/step - loss: 0.2285 - accuracy: 0.9037 - val_loss: 0.3042 - val_accuracy: 0.8761 - lr: 3.0000e-06\nEpoch 100/100\n40/40 [==============================] - 4s 101ms/step - loss: 0.2379 - accuracy: 0.8985 - val_loss: 0.2982 - val_accuracy: 0.8761 - lr: 3.0000e-06\n69/69 - 0s - loss: 0.3051 - accuracy: 0.8823 - 279ms/epoch - 4ms/step\n69/69 [==============================] - 0s 4ms/step\naccuracy = 0.8822727203369141\nStarting training for SNR: -4\nEpoch 1/100\n 1/40 [..............................] - ETA: 48s - loss: 3.1045 - accuracy: 0.1050","output_type":"stream"},{"name":"stderr","text":"2023-04-22 00:54:45.756730: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout_8/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 104ms/step - loss: 2.2043 - accuracy: 0.2712 - val_loss: 2.4799 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5600 - accuracy: 0.4227 - val_loss: 2.8277 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3197 - accuracy: 0.4984 - val_loss: 3.4817 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1731 - accuracy: 0.5389 - val_loss: 4.2466 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0679 - accuracy: 0.5737 - val_loss: 4.7894 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0002 - accuracy: 0.5929 - val_loss: 5.0796 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9306 - accuracy: 0.6247 - val_loss: 5.2926 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8892 - accuracy: 0.6399 - val_loss: 5.4462 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8517 - accuracy: 0.6504 - val_loss: 5.7082 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.8191 - accuracy: 0.6643 - val_loss: 5.9964 - val_accuracy: 0.1057 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7810 - accuracy: 0.6797 - val_loss: 6.5645 - val_accuracy: 0.1080 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7537 - accuracy: 0.6880 - val_loss: 5.8139 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.7353 - accuracy: 0.6979 - val_loss: 5.7071 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7076 - accuracy: 0.7120 - val_loss: 6.0761 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.6906 - accuracy: 0.7191 - val_loss: 5.0205 - val_accuracy: 0.1227 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6751 - accuracy: 0.7227 - val_loss: 4.8844 - val_accuracy: 0.1523 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6599 - accuracy: 0.7254 - val_loss: 2.6955 - val_accuracy: 0.2261 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 4s 100ms/step - loss: 0.6455 - accuracy: 0.7275 - val_loss: 1.5269 - val_accuracy: 0.4193 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 5s 126ms/step - loss: 0.6311 - accuracy: 0.7365 - val_loss: 0.8439 - val_accuracy: 0.6761 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.6194 - accuracy: 0.7395 - val_loss: 0.8729 - val_accuracy: 0.6580 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6117 - accuracy: 0.7471 - val_loss: 1.2147 - val_accuracy: 0.5534 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.5954 - accuracy: 0.7485 - val_loss: 0.6808 - val_accuracy: 0.7261 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.5881 - accuracy: 0.7556 - val_loss: 0.6726 - val_accuracy: 0.7114 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.5646 - accuracy: 0.7694 - val_loss: 0.6755 - val_accuracy: 0.7239 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.5547 - accuracy: 0.7660 - val_loss: 0.6327 - val_accuracy: 0.7398 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5472 - accuracy: 0.7708 - val_loss: 0.6356 - val_accuracy: 0.7307 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5324 - accuracy: 0.7832 - val_loss: 0.6347 - val_accuracy: 0.7386 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 4s 112ms/step - loss: 0.5247 - accuracy: 0.7795 - val_loss: 0.6049 - val_accuracy: 0.7364 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 4s 100ms/step - loss: 0.5057 - accuracy: 0.7938 - val_loss: 0.5914 - val_accuracy: 0.7511 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 4s 106ms/step - loss: 0.5086 - accuracy: 0.7871 - val_loss: 0.5875 - val_accuracy: 0.7489 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4851 - accuracy: 0.7918 - val_loss: 0.5528 - val_accuracy: 0.7591 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.4818 - accuracy: 0.7994 - val_loss: 0.5717 - val_accuracy: 0.7716 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.4763 - accuracy: 0.8024 - val_loss: 0.5419 - val_accuracy: 0.7830 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4697 - accuracy: 0.8049 - val_loss: 0.6062 - val_accuracy: 0.7659 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 5s 115ms/step - loss: 0.4581 - accuracy: 0.8115 - val_loss: 0.5302 - val_accuracy: 0.7750 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4565 - accuracy: 0.8105 - val_loss: 0.5996 - val_accuracy: 0.7557 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4435 - accuracy: 0.8134 - val_loss: 0.5383 - val_accuracy: 0.7761 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4274 - accuracy: 0.8258 - val_loss: 0.5510 - val_accuracy: 0.7670 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4275 - accuracy: 0.8192 - val_loss: 0.5631 - val_accuracy: 0.7602 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4180 - accuracy: 0.8278 - val_loss: 0.5378 - val_accuracy: 0.7773 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4144 - accuracy: 0.8287 - val_loss: 0.5349 - val_accuracy: 0.7818 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4040 - accuracy: 0.8279 - val_loss: 0.5448 - val_accuracy: 0.7716 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4095 - accuracy: 0.8306 - val_loss: 0.5461 - val_accuracy: 0.7773 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3940 - accuracy: 0.8384 - val_loss: 0.5586 - val_accuracy: 0.7636 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3951 - accuracy: 0.8380 - val_loss: 0.5533 - val_accuracy: 0.7795 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3840 - accuracy: 0.8432 - val_loss: 0.6030 - val_accuracy: 0.7580 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3909 - accuracy: 0.8335 - val_loss: 0.5687 - val_accuracy: 0.7659 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 33ms/step - loss: 0.3771 - accuracy: 0.8490 - val_loss: 0.5519 - val_accuracy: 0.7591 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3790 - accuracy: 0.8400 - val_loss: 0.5624 - val_accuracy: 0.7682 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3651 - accuracy: 0.8472 - val_loss: 0.5419 - val_accuracy: 0.7818 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3675 - accuracy: 0.8484 - val_loss: 0.5862 - val_accuracy: 0.7534 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3508 - accuracy: 0.8539 - val_loss: 0.5677 - val_accuracy: 0.7602 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3518 - accuracy: 0.8559 - val_loss: 0.6616 - val_accuracy: 0.7409 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3432 - accuracy: 0.8564 - val_loss: 0.5641 - val_accuracy: 0.7693 - lr: 3.0000e-04\nEpoch 55/100\n39/40 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.8635\nEpoch 55: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.3362 - accuracy: 0.8636 - val_loss: 0.5816 - val_accuracy: 0.7682 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3289 - accuracy: 0.8658 - val_loss: 0.5543 - val_accuracy: 0.7807 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3231 - accuracy: 0.8703 - val_loss: 0.5456 - val_accuracy: 0.7784 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3220 - accuracy: 0.8667 - val_loss: 0.5452 - val_accuracy: 0.7807 - lr: 3.0000e-05\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3195 - accuracy: 0.8713 - val_loss: 0.5491 - val_accuracy: 0.7795 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3220 - accuracy: 0.8682 - val_loss: 0.5496 - val_accuracy: 0.7739 - lr: 3.0000e-05\nEpoch 61/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3201 - accuracy: 0.8667 - val_loss: 0.5505 - val_accuracy: 0.7795 - lr: 3.0000e-05\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3211 - accuracy: 0.8674 - val_loss: 0.5462 - val_accuracy: 0.7761 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3136 - accuracy: 0.8769 - val_loss: 0.5474 - val_accuracy: 0.7795 - lr: 3.0000e-05\nEpoch 64/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3089 - accuracy: 0.8742 - val_loss: 0.5492 - val_accuracy: 0.7761 - lr: 3.0000e-05\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3081 - accuracy: 0.8754 - val_loss: 0.5484 - val_accuracy: 0.7727 - lr: 3.0000e-05\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3154 - accuracy: 0.8713 - val_loss: 0.5520 - val_accuracy: 0.7761 - lr: 3.0000e-05\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3069 - accuracy: 0.8780 - val_loss: 0.5559 - val_accuracy: 0.7795 - lr: 3.0000e-05\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3173 - accuracy: 0.8691 - val_loss: 0.5536 - val_accuracy: 0.7750 - lr: 3.0000e-05\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3041 - accuracy: 0.8806 - val_loss: 0.5490 - val_accuracy: 0.7716 - lr: 3.0000e-05\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3129 - accuracy: 0.8746 - val_loss: 0.5485 - val_accuracy: 0.7750 - lr: 3.0000e-05\nEpoch 71/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3089 - accuracy: 0.8789 - val_loss: 0.5441 - val_accuracy: 0.7784 - lr: 3.0000e-05\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3084 - accuracy: 0.8774 - val_loss: 0.5490 - val_accuracy: 0.7784 - lr: 3.0000e-05\nEpoch 73/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3029 - accuracy: 0.8761 - val_loss: 0.5474 - val_accuracy: 0.7716 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 33ms/step - loss: 0.2989 - accuracy: 0.8827 - val_loss: 0.5570 - val_accuracy: 0.7705 - lr: 3.0000e-05\nEpoch 75/100\n39/40 [============================>.] - ETA: 0s - loss: 0.3043 - accuracy: 0.8759\nEpoch 75: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 30ms/step - loss: 0.3054 - accuracy: 0.8753 - val_loss: 0.5513 - val_accuracy: 0.7727 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3102 - accuracy: 0.8739 - val_loss: 0.5518 - val_accuracy: 0.7727 - lr: 3.0000e-06\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2984 - accuracy: 0.8784 - val_loss: 0.5516 - val_accuracy: 0.7739 - lr: 3.0000e-06\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3010 - accuracy: 0.8832 - val_loss: 0.5517 - val_accuracy: 0.7773 - lr: 3.0000e-06\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3027 - accuracy: 0.8785 - val_loss: 0.5526 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3038 - accuracy: 0.8784 - val_loss: 0.5524 - val_accuracy: 0.7750 - lr: 3.0000e-06\nEpoch 81/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3031 - accuracy: 0.8782 - val_loss: 0.5522 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 82/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3042 - accuracy: 0.8751 - val_loss: 0.5529 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 83/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3076 - accuracy: 0.8787 - val_loss: 0.5524 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 84/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3015 - accuracy: 0.8788 - val_loss: 0.5522 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2985 - accuracy: 0.8798 - val_loss: 0.5516 - val_accuracy: 0.7750 - lr: 3.0000e-06\nEpoch 86/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2974 - accuracy: 0.8790 - val_loss: 0.5520 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3024 - accuracy: 0.8797 - val_loss: 0.5517 - val_accuracy: 0.7750 - lr: 3.0000e-06\nEpoch 88/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3028 - accuracy: 0.8777 - val_loss: 0.5515 - val_accuracy: 0.7727 - lr: 3.0000e-06\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3017 - accuracy: 0.8749 - val_loss: 0.5509 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 90/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3024 - accuracy: 0.8789 - val_loss: 0.5517 - val_accuracy: 0.7750 - lr: 3.0000e-06\nEpoch 91/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3033 - accuracy: 0.8761 - val_loss: 0.5519 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3047 - accuracy: 0.8761 - val_loss: 0.5520 - val_accuracy: 0.7750 - lr: 3.0000e-06\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2959 - accuracy: 0.8816 - val_loss: 0.5515 - val_accuracy: 0.7750 - lr: 3.0000e-06\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3002 - accuracy: 0.8797 - val_loss: 0.5523 - val_accuracy: 0.7750 - lr: 3.0000e-06\nEpoch 95/100\n39/40 [============================>.] - ETA: 0s - loss: 0.3021 - accuracy: 0.8741\nEpoch 95: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-07.\n40/40 [==============================] - 1s 30ms/step - loss: 0.3030 - accuracy: 0.8739 - val_loss: 0.5520 - val_accuracy: 0.7750 - lr: 3.0000e-06\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2986 - accuracy: 0.8819 - val_loss: 0.5520 - val_accuracy: 0.7750 - lr: 3.0000e-07\nEpoch 97/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2989 - accuracy: 0.8804 - val_loss: 0.5517 - val_accuracy: 0.7750 - lr: 3.0000e-07\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3041 - accuracy: 0.8758 - val_loss: 0.5515 - val_accuracy: 0.7750 - lr: 3.0000e-07\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3034 - accuracy: 0.8775 - val_loss: 0.5515 - val_accuracy: 0.7739 - lr: 3.0000e-07\nEpoch 100/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3004 - accuracy: 0.8761 - val_loss: 0.5520 - val_accuracy: 0.7750 - lr: 3.0000e-07\n69/69 - 0s - loss: 0.5488 - accuracy: 0.7636 - 281ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.7636363506317139\nStarting training for SNR: 6\nEpoch 1/100\n 1/40 [..............................] - ETA: 41s - loss: 3.0186 - accuracy: 0.1350","output_type":"stream"},{"name":"stderr","text":"2023-04-22 00:58:09.746888: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/dropout_12/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 101ms/step - loss: 2.2565 - accuracy: 0.2826 - val_loss: 2.5634 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.6893 - accuracy: 0.3984 - val_loss: 3.3385 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3906 - accuracy: 0.4788 - val_loss: 4.4912 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1437 - accuracy: 0.5605 - val_loss: 5.5825 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9420 - accuracy: 0.6357 - val_loss: 6.7906 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8241 - accuracy: 0.6635 - val_loss: 7.9040 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7334 - accuracy: 0.6951 - val_loss: 8.8516 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6554 - accuracy: 0.7235 - val_loss: 10.0457 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.6088 - accuracy: 0.7346 - val_loss: 10.7176 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5715 - accuracy: 0.7419 - val_loss: 10.9832 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5427 - accuracy: 0.7566 - val_loss: 10.9685 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5115 - accuracy: 0.7737 - val_loss: 10.9197 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4915 - accuracy: 0.7807 - val_loss: 10.6104 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4779 - accuracy: 0.7818 - val_loss: 9.8973 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4591 - accuracy: 0.7928 - val_loss: 8.6030 - val_accuracy: 0.1500 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4513 - accuracy: 0.7991 - val_loss: 6.8361 - val_accuracy: 0.1557 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4367 - accuracy: 0.8061 - val_loss: 5.1735 - val_accuracy: 0.1580 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4273 - accuracy: 0.8093 - val_loss: 3.1551 - val_accuracy: 0.2330 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.4193 - accuracy: 0.8177 - val_loss: 2.0083 - val_accuracy: 0.4557 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.4116 - accuracy: 0.8186 - val_loss: 2.0668 - val_accuracy: 0.3636 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.3955 - accuracy: 0.8264 - val_loss: 1.4068 - val_accuracy: 0.4693 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 114ms/step - loss: 0.3859 - accuracy: 0.8335 - val_loss: 0.9011 - val_accuracy: 0.6295 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3826 - accuracy: 0.8289 - val_loss: 1.2790 - val_accuracy: 0.5227 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.3760 - accuracy: 0.8348 - val_loss: 0.8787 - val_accuracy: 0.6500 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3661 - accuracy: 0.8390 - val_loss: 1.9869 - val_accuracy: 0.4750 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 4s 100ms/step - loss: 0.3681 - accuracy: 0.8354 - val_loss: 0.5449 - val_accuracy: 0.7523 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3676 - accuracy: 0.8409 - val_loss: 2.3500 - val_accuracy: 0.5205 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3539 - accuracy: 0.8427 - val_loss: 2.9372 - val_accuracy: 0.5159 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3519 - accuracy: 0.8417 - val_loss: 2.6005 - val_accuracy: 0.5330 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3473 - accuracy: 0.8480 - val_loss: 2.0255 - val_accuracy: 0.5545 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3384 - accuracy: 0.8485 - val_loss: 1.0201 - val_accuracy: 0.6568 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3301 - accuracy: 0.8562 - val_loss: 1.2015 - val_accuracy: 0.6261 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3320 - accuracy: 0.8561 - val_loss: 2.0907 - val_accuracy: 0.5602 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3196 - accuracy: 0.8607 - val_loss: 1.4412 - val_accuracy: 0.5716 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3182 - accuracy: 0.8641 - val_loss: 2.3220 - val_accuracy: 0.5568 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3085 - accuracy: 0.8655 - val_loss: 2.4086 - val_accuracy: 0.5295 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3129 - accuracy: 0.8615 - val_loss: 1.2880 - val_accuracy: 0.6386 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3023 - accuracy: 0.8727 - val_loss: 1.0286 - val_accuracy: 0.6920 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3030 - accuracy: 0.8696 - val_loss: 2.1968 - val_accuracy: 0.5716 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2946 - accuracy: 0.8742 - val_loss: 2.5589 - val_accuracy: 0.5739 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2949 - accuracy: 0.8755 - val_loss: 2.2750 - val_accuracy: 0.5750 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2914 - accuracy: 0.8732 - val_loss: 1.5747 - val_accuracy: 0.5875 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2863 - accuracy: 0.8782 - val_loss: 0.8504 - val_accuracy: 0.7148 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2886 - accuracy: 0.8799 - val_loss: 2.2937 - val_accuracy: 0.5727 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2828 - accuracy: 0.8782 - val_loss: 2.8359 - val_accuracy: 0.5773 - lr: 3.0000e-04\nEpoch 46/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.8831\nEpoch 46: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.2721 - accuracy: 0.8828 - val_loss: 2.2645 - val_accuracy: 0.5739 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2545 - accuracy: 0.8942 - val_loss: 1.8471 - val_accuracy: 0.5795 - lr: 3.0000e-05\nEpoch 48/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2546 - accuracy: 0.8952 - val_loss: 1.5724 - val_accuracy: 0.6034 - lr: 3.0000e-05\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2504 - accuracy: 0.8943 - val_loss: 0.8898 - val_accuracy: 0.7352 - lr: 3.0000e-05\nEpoch 50/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2472 - accuracy: 0.8956 - val_loss: 0.8682 - val_accuracy: 0.7477 - lr: 3.0000e-05\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2416 - accuracy: 0.9008 - val_loss: 0.6341 - val_accuracy: 0.7625 - lr: 3.0000e-05\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2484 - accuracy: 0.8922 - val_loss: 0.5698 - val_accuracy: 0.7716 - lr: 3.0000e-05\nEpoch 53/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2482 - accuracy: 0.8967 - val_loss: 0.6601 - val_accuracy: 0.7602 - lr: 3.0000e-05\nEpoch 54/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.2448 - accuracy: 0.8972 - val_loss: 0.4644 - val_accuracy: 0.8102 - lr: 3.0000e-05\nEpoch 55/100\n40/40 [==============================] - 4s 113ms/step - loss: 0.2464 - accuracy: 0.8976 - val_loss: 0.3786 - val_accuracy: 0.8534 - lr: 3.0000e-05\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2406 - accuracy: 0.9027 - val_loss: 0.5731 - val_accuracy: 0.7727 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2424 - accuracy: 0.8980 - val_loss: 0.6617 - val_accuracy: 0.7557 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2429 - accuracy: 0.8972 - val_loss: 0.3916 - val_accuracy: 0.8568 - lr: 3.0000e-05\nEpoch 59/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2359 - accuracy: 0.9001 - val_loss: 0.4054 - val_accuracy: 0.8398 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2419 - accuracy: 0.8958 - val_loss: 0.7003 - val_accuracy: 0.7568 - lr: 3.0000e-05\nEpoch 61/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2397 - accuracy: 0.8995 - val_loss: 0.4155 - val_accuracy: 0.8273 - lr: 3.0000e-05\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2457 - accuracy: 0.8967 - val_loss: 0.5256 - val_accuracy: 0.7807 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2388 - accuracy: 0.8992 - val_loss: 0.5248 - val_accuracy: 0.7886 - lr: 3.0000e-05\nEpoch 64/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2389 - accuracy: 0.9018 - val_loss: 0.5200 - val_accuracy: 0.7795 - lr: 3.0000e-05\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2412 - accuracy: 0.9015 - val_loss: 0.8789 - val_accuracy: 0.7523 - lr: 3.0000e-05\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2374 - accuracy: 0.9008 - val_loss: 0.6458 - val_accuracy: 0.7625 - lr: 3.0000e-05\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2397 - accuracy: 0.8990 - val_loss: 0.7077 - val_accuracy: 0.7580 - lr: 3.0000e-05\nEpoch 68/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.2379 - accuracy: 0.8972 - val_loss: 0.3672 - val_accuracy: 0.8614 - lr: 3.0000e-05\nEpoch 69/100\n40/40 [==============================] - 1s 34ms/step - loss: 0.2346 - accuracy: 0.8997 - val_loss: 0.4069 - val_accuracy: 0.8420 - lr: 3.0000e-05\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2373 - accuracy: 0.8992 - val_loss: 0.7353 - val_accuracy: 0.7557 - lr: 3.0000e-05\nEpoch 71/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2353 - accuracy: 0.9027 - val_loss: 0.5771 - val_accuracy: 0.7716 - lr: 3.0000e-05\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2345 - accuracy: 0.8971 - val_loss: 0.6741 - val_accuracy: 0.7568 - lr: 3.0000e-05\nEpoch 73/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.2312 - accuracy: 0.9042 - val_loss: 0.3514 - val_accuracy: 0.8670 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2385 - accuracy: 0.8986 - val_loss: 0.7479 - val_accuracy: 0.7580 - lr: 3.0000e-05\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2290 - accuracy: 0.9033 - val_loss: 0.3725 - val_accuracy: 0.8523 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2323 - accuracy: 0.9044 - val_loss: 0.6988 - val_accuracy: 0.7534 - lr: 3.0000e-05\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2354 - accuracy: 0.9045 - val_loss: 0.6016 - val_accuracy: 0.7682 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2295 - accuracy: 0.9034 - val_loss: 0.4796 - val_accuracy: 0.7989 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2289 - accuracy: 0.9042 - val_loss: 0.4863 - val_accuracy: 0.7932 - lr: 3.0000e-05\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2331 - accuracy: 0.9073 - val_loss: 0.5295 - val_accuracy: 0.7841 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2259 - accuracy: 0.9069 - val_loss: 0.4009 - val_accuracy: 0.8330 - lr: 3.0000e-05\nEpoch 82/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2253 - accuracy: 0.9067 - val_loss: 0.7423 - val_accuracy: 0.7557 - lr: 3.0000e-05\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2309 - accuracy: 0.9020 - val_loss: 0.7600 - val_accuracy: 0.7511 - lr: 3.0000e-05\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2250 - accuracy: 0.9054 - val_loss: 0.5763 - val_accuracy: 0.7693 - lr: 3.0000e-05\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2281 - accuracy: 0.9048 - val_loss: 0.9013 - val_accuracy: 0.7580 - lr: 3.0000e-05\nEpoch 86/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2219 - accuracy: 0.9117 - val_loss: 0.4258 - val_accuracy: 0.8273 - lr: 3.0000e-05\nEpoch 87/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2276 - accuracy: 0.9058 - val_loss: 0.4048 - val_accuracy: 0.8398 - lr: 3.0000e-05\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2261 - accuracy: 0.9035 - val_loss: 0.7343 - val_accuracy: 0.7591 - lr: 3.0000e-05\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2255 - accuracy: 0.9076 - val_loss: 0.4475 - val_accuracy: 0.8205 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2227 - accuracy: 0.9068 - val_loss: 0.5765 - val_accuracy: 0.7682 - lr: 3.0000e-05\nEpoch 91/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2222 - accuracy: 0.9096 - val_loss: 0.9487 - val_accuracy: 0.7477 - lr: 3.0000e-05\nEpoch 92/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2198 - accuracy: 0.9088 - val_loss: 0.5154 - val_accuracy: 0.7864 - lr: 3.0000e-05\nEpoch 93/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.2236 - accuracy: 0.9077 - val_loss: 0.3481 - val_accuracy: 0.8625 - lr: 3.0000e-05\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2207 - accuracy: 0.9107 - val_loss: 0.9172 - val_accuracy: 0.7466 - lr: 3.0000e-05\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2176 - accuracy: 0.9097 - val_loss: 0.9003 - val_accuracy: 0.7591 - lr: 3.0000e-05\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2166 - accuracy: 0.9087 - val_loss: 0.4593 - val_accuracy: 0.8125 - lr: 3.0000e-05\nEpoch 97/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2181 - accuracy: 0.9126 - val_loss: 0.4915 - val_accuracy: 0.8000 - lr: 3.0000e-05\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2155 - accuracy: 0.9100 - val_loss: 0.8320 - val_accuracy: 0.7705 - lr: 3.0000e-05\nEpoch 99/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2188 - accuracy: 0.9073 - val_loss: 0.6389 - val_accuracy: 0.7705 - lr: 3.0000e-05\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2197 - accuracy: 0.9087 - val_loss: 0.7845 - val_accuracy: 0.7568 - lr: 3.0000e-05\n69/69 - 0s - loss: 0.7242 - accuracy: 0.7618 - 275ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.7618181705474854\nStarting training for SNR: 12\nEpoch 1/100\n 1/40 [..............................] - ETA: 40s - loss: 3.1121 - accuracy: 0.0350","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:01:33.678430: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_4/dropout_16/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 6s 122ms/step - loss: 2.2544 - accuracy: 0.2822 - val_loss: 2.6162 - val_accuracy: 0.0989 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.6920 - accuracy: 0.3913 - val_loss: 3.4352 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.4274 - accuracy: 0.4598 - val_loss: 4.5452 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.2419 - accuracy: 0.5246 - val_loss: 5.5793 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0847 - accuracy: 0.5809 - val_loss: 6.5296 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9796 - accuracy: 0.6176 - val_loss: 7.2120 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8817 - accuracy: 0.6491 - val_loss: 8.1280 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8206 - accuracy: 0.6657 - val_loss: 9.1136 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7528 - accuracy: 0.6847 - val_loss: 10.1955 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7002 - accuracy: 0.6987 - val_loss: 11.0987 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6588 - accuracy: 0.7162 - val_loss: 11.7990 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6217 - accuracy: 0.7282 - val_loss: 12.3243 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5922 - accuracy: 0.7422 - val_loss: 12.6991 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5659 - accuracy: 0.7510 - val_loss: 12.7504 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5547 - accuracy: 0.7561 - val_loss: 12.4671 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5358 - accuracy: 0.7548 - val_loss: 11.5814 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5212 - accuracy: 0.7702 - val_loss: 11.1535 - val_accuracy: 0.1216 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5091 - accuracy: 0.7673 - val_loss: 8.5187 - val_accuracy: 0.1227 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4922 - accuracy: 0.7766 - val_loss: 5.4333 - val_accuracy: 0.1602 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4825 - accuracy: 0.7811 - val_loss: 3.5440 - val_accuracy: 0.2386 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.4758 - accuracy: 0.7837 - val_loss: 0.8977 - val_accuracy: 0.5955 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.8685 - val_accuracy: 0.5784 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4682 - accuracy: 0.7807 - val_loss: 0.6448 - val_accuracy: 0.6852 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4585 - accuracy: 0.7895 - val_loss: 1.0312 - val_accuracy: 0.5659 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4428 - accuracy: 0.8021 - val_loss: 0.6822 - val_accuracy: 0.6852 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 4s 112ms/step - loss: 0.4419 - accuracy: 0.8025 - val_loss: 0.6168 - val_accuracy: 0.7250 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4436 - accuracy: 0.7970 - val_loss: 0.5103 - val_accuracy: 0.7614 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4222 - accuracy: 0.8051 - val_loss: 0.4982 - val_accuracy: 0.7375 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4248 - accuracy: 0.8044 - val_loss: 0.6558 - val_accuracy: 0.7000 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4206 - accuracy: 0.8059 - val_loss: 0.5590 - val_accuracy: 0.7545 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4091 - accuracy: 0.8105 - val_loss: 0.5991 - val_accuracy: 0.7125 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3999 - accuracy: 0.8176 - val_loss: 1.0153 - val_accuracy: 0.6170 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.4057 - accuracy: 0.8144 - val_loss: 0.8824 - val_accuracy: 0.6648 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3938 - accuracy: 0.8221 - val_loss: 0.7951 - val_accuracy: 0.6705 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3932 - accuracy: 0.8164 - val_loss: 0.5885 - val_accuracy: 0.7216 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3923 - accuracy: 0.8197 - val_loss: 1.1211 - val_accuracy: 0.6250 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3795 - accuracy: 0.8285 - val_loss: 0.6949 - val_accuracy: 0.6886 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3805 - accuracy: 0.8266 - val_loss: 0.5645 - val_accuracy: 0.7477 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3763 - accuracy: 0.8307 - val_loss: 0.5908 - val_accuracy: 0.7045 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3777 - accuracy: 0.8309 - val_loss: 0.4983 - val_accuracy: 0.7557 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.3650 - accuracy: 0.8356 - val_loss: 0.4793 - val_accuracy: 0.7682 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3544 - accuracy: 0.8394 - val_loss: 0.5664 - val_accuracy: 0.7625 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3542 - accuracy: 0.8438 - val_loss: 0.5007 - val_accuracy: 0.7705 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3529 - accuracy: 0.8394 - val_loss: 0.5301 - val_accuracy: 0.7670 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 5s 115ms/step - loss: 0.3510 - accuracy: 0.8418 - val_loss: 0.4608 - val_accuracy: 0.7739 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3421 - accuracy: 0.8461 - val_loss: 0.4643 - val_accuracy: 0.7795 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3312 - accuracy: 0.8559 - val_loss: 0.4714 - val_accuracy: 0.7682 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3334 - accuracy: 0.8582 - val_loss: 0.4907 - val_accuracy: 0.7648 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3276 - accuracy: 0.8534 - val_loss: 0.9028 - val_accuracy: 0.6886 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3297 - accuracy: 0.8528 - val_loss: 0.8355 - val_accuracy: 0.6761 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3181 - accuracy: 0.8551 - val_loss: 0.5673 - val_accuracy: 0.7568 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 4s 111ms/step - loss: 0.3174 - accuracy: 0.8636 - val_loss: 0.4559 - val_accuracy: 0.7795 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.3115 - accuracy: 0.8586 - val_loss: 0.4540 - val_accuracy: 0.7852 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.3114 - accuracy: 0.8634 - val_loss: 0.4488 - val_accuracy: 0.7761 - lr: 3.0000e-04\nEpoch 55/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3061 - accuracy: 0.8644 - val_loss: 0.4643 - val_accuracy: 0.7841 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2971 - accuracy: 0.8660 - val_loss: 0.4643 - val_accuracy: 0.7807 - lr: 3.0000e-04\nEpoch 57/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2937 - accuracy: 0.8689 - val_loss: 0.4785 - val_accuracy: 0.7818 - lr: 3.0000e-04\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2803 - accuracy: 0.8807 - val_loss: 0.4584 - val_accuracy: 0.7920 - lr: 3.0000e-04\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2850 - accuracy: 0.8740 - val_loss: 0.5216 - val_accuracy: 0.7705 - lr: 3.0000e-04\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2842 - accuracy: 0.8739 - val_loss: 0.4605 - val_accuracy: 0.7864 - lr: 3.0000e-04\nEpoch 61/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2762 - accuracy: 0.8804 - val_loss: 0.5056 - val_accuracy: 0.7784 - lr: 3.0000e-04\nEpoch 62/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2738 - accuracy: 0.8821 - val_loss: 0.4698 - val_accuracy: 0.7909 - lr: 3.0000e-04\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2668 - accuracy: 0.8862 - val_loss: 0.4576 - val_accuracy: 0.7977 - lr: 3.0000e-04\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2638 - accuracy: 0.8831 - val_loss: 0.4570 - val_accuracy: 0.7943 - lr: 3.0000e-04\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2634 - accuracy: 0.8837 - val_loss: 0.4596 - val_accuracy: 0.7932 - lr: 3.0000e-04\nEpoch 66/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2608 - accuracy: 0.8821 - val_loss: 0.5784 - val_accuracy: 0.7477 - lr: 3.0000e-04\nEpoch 67/100\n40/40 [==============================] - 4s 113ms/step - loss: 0.2499 - accuracy: 0.8912 - val_loss: 0.4431 - val_accuracy: 0.7932 - lr: 3.0000e-04\nEpoch 68/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2486 - accuracy: 0.8891 - val_loss: 0.4583 - val_accuracy: 0.7955 - lr: 3.0000e-04\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2588 - accuracy: 0.8859 - val_loss: 0.4464 - val_accuracy: 0.7909 - lr: 3.0000e-04\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2422 - accuracy: 0.8918 - val_loss: 0.4851 - val_accuracy: 0.7818 - lr: 3.0000e-04\nEpoch 71/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2436 - accuracy: 0.8905 - val_loss: 0.4534 - val_accuracy: 0.7920 - lr: 3.0000e-04\nEpoch 72/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2433 - accuracy: 0.8944 - val_loss: 0.4496 - val_accuracy: 0.7898 - lr: 3.0000e-04\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2471 - accuracy: 0.8902 - val_loss: 0.4772 - val_accuracy: 0.7943 - lr: 3.0000e-04\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2321 - accuracy: 0.8999 - val_loss: 0.4498 - val_accuracy: 0.8057 - lr: 3.0000e-04\nEpoch 75/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2379 - accuracy: 0.8966 - val_loss: 0.4994 - val_accuracy: 0.7898 - lr: 3.0000e-04\nEpoch 76/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2249 - accuracy: 0.9019 - val_loss: 0.4759 - val_accuracy: 0.7977 - lr: 3.0000e-04\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2294 - accuracy: 0.8989 - val_loss: 0.4928 - val_accuracy: 0.7943 - lr: 3.0000e-04\nEpoch 78/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2217 - accuracy: 0.9019 - val_loss: 0.5086 - val_accuracy: 0.7920 - lr: 3.0000e-04\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2223 - accuracy: 0.9029 - val_loss: 0.4820 - val_accuracy: 0.8068 - lr: 3.0000e-04\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2167 - accuracy: 0.9039 - val_loss: 0.5241 - val_accuracy: 0.7920 - lr: 3.0000e-04\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2144 - accuracy: 0.9047 - val_loss: 0.4789 - val_accuracy: 0.8000 - lr: 3.0000e-04\nEpoch 82/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2070 - accuracy: 0.9063 - val_loss: 0.4717 - val_accuracy: 0.7898 - lr: 3.0000e-04\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2163 - accuracy: 0.9038 - val_loss: 0.4595 - val_accuracy: 0.8034 - lr: 3.0000e-04\nEpoch 84/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2160 - accuracy: 0.9062 - val_loss: 0.4572 - val_accuracy: 0.8102 - lr: 3.0000e-04\nEpoch 85/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2067 - accuracy: 0.9061 - val_loss: 0.4599 - val_accuracy: 0.8000 - lr: 3.0000e-04\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2022 - accuracy: 0.9109 - val_loss: 0.4688 - val_accuracy: 0.7932 - lr: 3.0000e-04\nEpoch 87/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2003 - accuracy: 0.9099\nEpoch 87: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.1999 - accuracy: 0.9102 - val_loss: 0.4820 - val_accuracy: 0.8045 - lr: 3.0000e-04\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1986 - accuracy: 0.9129 - val_loss: 0.4610 - val_accuracy: 0.8091 - lr: 3.0000e-05\nEpoch 89/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1866 - accuracy: 0.9189 - val_loss: 0.4527 - val_accuracy: 0.8102 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1894 - accuracy: 0.9187 - val_loss: 0.4500 - val_accuracy: 0.8068 - lr: 3.0000e-05\nEpoch 91/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1899 - accuracy: 0.9172 - val_loss: 0.4518 - val_accuracy: 0.8080 - lr: 3.0000e-05\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1840 - accuracy: 0.9189 - val_loss: 0.4502 - val_accuracy: 0.8114 - lr: 3.0000e-05\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1865 - accuracy: 0.9178 - val_loss: 0.4479 - val_accuracy: 0.8102 - lr: 3.0000e-05\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1860 - accuracy: 0.9194 - val_loss: 0.4482 - val_accuracy: 0.8136 - lr: 3.0000e-05\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1858 - accuracy: 0.9206 - val_loss: 0.4490 - val_accuracy: 0.8102 - lr: 3.0000e-05\nEpoch 96/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1847 - accuracy: 0.9199 - val_loss: 0.4466 - val_accuracy: 0.8148 - lr: 3.0000e-05\nEpoch 97/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.1800 - accuracy: 0.9210 - val_loss: 0.4495 - val_accuracy: 0.8159 - lr: 3.0000e-05\nEpoch 98/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1805 - accuracy: 0.9259 - val_loss: 0.4490 - val_accuracy: 0.8114 - lr: 3.0000e-05\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1811 - accuracy: 0.9194 - val_loss: 0.4508 - val_accuracy: 0.8057 - lr: 3.0000e-05\nEpoch 100/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1870 - accuracy: 0.9168 - val_loss: 0.4503 - val_accuracy: 0.8114 - lr: 3.0000e-05\n69/69 - 0s - loss: 0.4474 - accuracy: 0.8164 - 280ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.8163636326789856\nStarting training for SNR: -6\nEpoch 1/100\n 1/40 [..............................] - ETA: 42s - loss: 3.0728 - accuracy: 0.1200","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:04:57.651886: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_5/dropout_20/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 101ms/step - loss: 2.4158 - accuracy: 0.2229 - val_loss: 2.4857 - val_accuracy: 0.1080 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.7306 - accuracy: 0.3676 - val_loss: 2.9057 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.5017 - accuracy: 0.4288 - val_loss: 3.4975 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.3892 - accuracy: 0.4667 - val_loss: 4.1002 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3138 - accuracy: 0.4833 - val_loss: 4.4825 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.2447 - accuracy: 0.5078 - val_loss: 4.7166 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1901 - accuracy: 0.5274 - val_loss: 4.9029 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.1508 - accuracy: 0.5356 - val_loss: 5.0679 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1054 - accuracy: 0.5581 - val_loss: 5.0981 - val_accuracy: 0.1307 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0803 - accuracy: 0.5585 - val_loss: 5.1857 - val_accuracy: 0.1102 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0524 - accuracy: 0.5740 - val_loss: 5.5517 - val_accuracy: 0.1080 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0203 - accuracy: 0.5818 - val_loss: 5.4869 - val_accuracy: 0.1080 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0024 - accuracy: 0.5894 - val_loss: 5.2684 - val_accuracy: 0.1080 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9829 - accuracy: 0.5937 - val_loss: 5.2059 - val_accuracy: 0.1102 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9628 - accuracy: 0.6023 - val_loss: 3.9721 - val_accuracy: 0.1523 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9539 - accuracy: 0.6107 - val_loss: 3.3047 - val_accuracy: 0.1795 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9292 - accuracy: 0.6210 - val_loss: 3.1537 - val_accuracy: 0.1784 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.9173 - accuracy: 0.6221 - val_loss: 1.8134 - val_accuracy: 0.3341 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.9065 - accuracy: 0.6253 - val_loss: 1.4030 - val_accuracy: 0.4489 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 114ms/step - loss: 0.8966 - accuracy: 0.6304 - val_loss: 0.9709 - val_accuracy: 0.5989 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.8841 - accuracy: 0.6313 - val_loss: 1.0122 - val_accuracy: 0.5920 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.8625 - accuracy: 0.6496 - val_loss: 0.9327 - val_accuracy: 0.6182 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 106ms/step - loss: 0.8468 - accuracy: 0.6499 - val_loss: 0.9249 - val_accuracy: 0.6182 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.8552 - accuracy: 0.6491 - val_loss: 0.9154 - val_accuracy: 0.6307 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 5s 115ms/step - loss: 0.8295 - accuracy: 0.6687 - val_loss: 0.9065 - val_accuracy: 0.6227 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.8206 - accuracy: 0.6631 - val_loss: 0.9566 - val_accuracy: 0.6057 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.8090 - accuracy: 0.6732 - val_loss: 0.9538 - val_accuracy: 0.5920 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7944 - accuracy: 0.6758 - val_loss: 0.9163 - val_accuracy: 0.6364 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.7864 - accuracy: 0.6819 - val_loss: 0.8953 - val_accuracy: 0.6295 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.7755 - accuracy: 0.6857 - val_loss: 0.9050 - val_accuracy: 0.6284 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7650 - accuracy: 0.6938 - val_loss: 0.9691 - val_accuracy: 0.6091 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.7619 - accuracy: 0.6833 - val_loss: 0.8753 - val_accuracy: 0.6455 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.7440 - accuracy: 0.6997 - val_loss: 0.9489 - val_accuracy: 0.6409 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.7349 - accuracy: 0.7053 - val_loss: 0.8735 - val_accuracy: 0.6477 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.7290 - accuracy: 0.7091 - val_loss: 0.8871 - val_accuracy: 0.6386 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7179 - accuracy: 0.7068 - val_loss: 0.8740 - val_accuracy: 0.6375 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.7031 - accuracy: 0.7106 - val_loss: 0.8742 - val_accuracy: 0.6386 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.6946 - accuracy: 0.7230 - val_loss: 0.8959 - val_accuracy: 0.6284 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.6997 - accuracy: 0.7245 - val_loss: 0.8701 - val_accuracy: 0.6534 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.6780 - accuracy: 0.7307 - val_loss: 0.9205 - val_accuracy: 0.6330 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 5s 116ms/step - loss: 0.6724 - accuracy: 0.7346 - val_loss: 0.8614 - val_accuracy: 0.6443 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.6589 - accuracy: 0.7365 - val_loss: 0.8826 - val_accuracy: 0.6636 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6611 - accuracy: 0.7409 - val_loss: 0.8652 - val_accuracy: 0.6500 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6512 - accuracy: 0.7417 - val_loss: 0.8785 - val_accuracy: 0.6455 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6333 - accuracy: 0.7472 - val_loss: 0.8953 - val_accuracy: 0.6261 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.6311 - accuracy: 0.7476 - val_loss: 0.8565 - val_accuracy: 0.6591 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.6160 - accuracy: 0.7595 - val_loss: 0.8586 - val_accuracy: 0.6602 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6058 - accuracy: 0.7587 - val_loss: 0.8704 - val_accuracy: 0.6580 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.6002 - accuracy: 0.7593 - val_loss: 0.8513 - val_accuracy: 0.6580 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5849 - accuracy: 0.7730 - val_loss: 0.8726 - val_accuracy: 0.6511 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5753 - accuracy: 0.7755 - val_loss: 0.8966 - val_accuracy: 0.6523 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5742 - accuracy: 0.7758 - val_loss: 0.8706 - val_accuracy: 0.6727 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5623 - accuracy: 0.7809 - val_loss: 0.9426 - val_accuracy: 0.6580 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 34ms/step - loss: 0.5602 - accuracy: 0.7803 - val_loss: 0.9100 - val_accuracy: 0.6443 - lr: 3.0000e-04\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5450 - accuracy: 0.7828 - val_loss: 1.2259 - val_accuracy: 0.5682 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5301 - accuracy: 0.7922 - val_loss: 0.8956 - val_accuracy: 0.6557 - lr: 3.0000e-04\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5224 - accuracy: 0.8004 - val_loss: 0.9006 - val_accuracy: 0.6636 - lr: 3.0000e-04\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5181 - accuracy: 0.7960 - val_loss: 0.8828 - val_accuracy: 0.6716 - lr: 3.0000e-04\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5041 - accuracy: 0.8074 - val_loss: 0.8638 - val_accuracy: 0.6659 - lr: 3.0000e-04\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5107 - accuracy: 0.8047 - val_loss: 0.8668 - val_accuracy: 0.6625 - lr: 3.0000e-04\nEpoch 61/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4947 - accuracy: 0.8105 - val_loss: 0.8678 - val_accuracy: 0.6670 - lr: 3.0000e-04\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4824 - accuracy: 0.8196 - val_loss: 0.8669 - val_accuracy: 0.6659 - lr: 3.0000e-04\nEpoch 63/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4675 - accuracy: 0.8245 - val_loss: 0.8919 - val_accuracy: 0.6659 - lr: 3.0000e-04\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4684 - accuracy: 0.8208 - val_loss: 0.9714 - val_accuracy: 0.6375 - lr: 3.0000e-04\nEpoch 65/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4562 - accuracy: 0.8261 - val_loss: 1.0052 - val_accuracy: 0.6170 - lr: 3.0000e-04\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4541 - accuracy: 0.8306 - val_loss: 0.9890 - val_accuracy: 0.6636 - lr: 3.0000e-04\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4442 - accuracy: 0.8297 - val_loss: 0.9184 - val_accuracy: 0.6580 - lr: 3.0000e-04\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4369 - accuracy: 0.8379 - val_loss: 0.9203 - val_accuracy: 0.6500 - lr: 3.0000e-04\nEpoch 69/100\n39/40 [============================>.] - ETA: 0s - loss: 0.4230 - accuracy: 0.8408\nEpoch 69: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 31ms/step - loss: 0.4227 - accuracy: 0.8408 - val_loss: 0.9190 - val_accuracy: 0.6682 - lr: 3.0000e-04\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4088 - accuracy: 0.8486 - val_loss: 0.9053 - val_accuracy: 0.6682 - lr: 3.0000e-05\nEpoch 71/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4009 - accuracy: 0.8509 - val_loss: 0.9043 - val_accuracy: 0.6682 - lr: 3.0000e-05\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4104 - accuracy: 0.8455 - val_loss: 0.9047 - val_accuracy: 0.6716 - lr: 3.0000e-05\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4052 - accuracy: 0.8491 - val_loss: 0.9041 - val_accuracy: 0.6716 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3943 - accuracy: 0.8538 - val_loss: 0.9070 - val_accuracy: 0.6659 - lr: 3.0000e-05\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3937 - accuracy: 0.8557 - val_loss: 0.9119 - val_accuracy: 0.6659 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3921 - accuracy: 0.8552 - val_loss: 0.9090 - val_accuracy: 0.6705 - lr: 3.0000e-05\nEpoch 77/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3890 - accuracy: 0.8606 - val_loss: 0.9092 - val_accuracy: 0.6670 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3894 - accuracy: 0.8630 - val_loss: 0.9127 - val_accuracy: 0.6682 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3851 - accuracy: 0.8591 - val_loss: 0.9100 - val_accuracy: 0.6659 - lr: 3.0000e-05\nEpoch 80/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3843 - accuracy: 0.8612 - val_loss: 0.9099 - val_accuracy: 0.6625 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3885 - accuracy: 0.8545 - val_loss: 0.9136 - val_accuracy: 0.6659 - lr: 3.0000e-05\nEpoch 82/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3817 - accuracy: 0.8583 - val_loss: 0.9163 - val_accuracy: 0.6659 - lr: 3.0000e-05\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3834 - accuracy: 0.8621 - val_loss: 0.9144 - val_accuracy: 0.6648 - lr: 3.0000e-05\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3846 - accuracy: 0.8588 - val_loss: 0.9180 - val_accuracy: 0.6693 - lr: 3.0000e-05\nEpoch 85/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3856 - accuracy: 0.8567 - val_loss: 0.9160 - val_accuracy: 0.6580 - lr: 3.0000e-05\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3776 - accuracy: 0.8607 - val_loss: 0.9207 - val_accuracy: 0.6625 - lr: 3.0000e-05\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3806 - accuracy: 0.8562 - val_loss: 0.9165 - val_accuracy: 0.6636 - lr: 3.0000e-05\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3845 - accuracy: 0.8569 - val_loss: 0.9226 - val_accuracy: 0.6670 - lr: 3.0000e-05\nEpoch 89/100\n39/40 [============================>.] - ETA: 0s - loss: 0.3698 - accuracy: 0.8658\nEpoch 89: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 30ms/step - loss: 0.3694 - accuracy: 0.8660 - val_loss: 0.9191 - val_accuracy: 0.6693 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3748 - accuracy: 0.8626 - val_loss: 0.9176 - val_accuracy: 0.6693 - lr: 3.0000e-06\nEpoch 91/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3736 - accuracy: 0.8583 - val_loss: 0.9179 - val_accuracy: 0.6693 - lr: 3.0000e-06\nEpoch 92/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3777 - accuracy: 0.8624 - val_loss: 0.9184 - val_accuracy: 0.6693 - lr: 3.0000e-06\nEpoch 93/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3708 - accuracy: 0.8678 - val_loss: 0.9183 - val_accuracy: 0.6693 - lr: 3.0000e-06\nEpoch 94/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3661 - accuracy: 0.8698 - val_loss: 0.9183 - val_accuracy: 0.6682 - lr: 3.0000e-06\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3654 - accuracy: 0.8662 - val_loss: 0.9183 - val_accuracy: 0.6670 - lr: 3.0000e-06\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3713 - accuracy: 0.8654 - val_loss: 0.9176 - val_accuracy: 0.6682 - lr: 3.0000e-06\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3851 - accuracy: 0.8634 - val_loss: 0.9182 - val_accuracy: 0.6670 - lr: 3.0000e-06\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3764 - accuracy: 0.8588 - val_loss: 0.9188 - val_accuracy: 0.6659 - lr: 3.0000e-06\nEpoch 99/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3681 - accuracy: 0.8686 - val_loss: 0.9185 - val_accuracy: 0.6659 - lr: 3.0000e-06\nEpoch 100/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3648 - accuracy: 0.8696 - val_loss: 0.9194 - val_accuracy: 0.6670 - lr: 3.0000e-06\n69/69 - 0s - loss: 0.8206 - accuracy: 0.6664 - 253ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.6663636565208435\nStarting training for SNR: -20\nEpoch 1/100\n 1/40 [..............................] - ETA: 40s - loss: 3.1378 - accuracy: 0.0700","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:07:41.890099: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_6/dropout_24/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 100ms/step - loss: 3.1109 - accuracy: 0.0924 - val_loss: 2.4356 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.9833 - accuracy: 0.0893 - val_loss: 2.4756 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.8313 - accuracy: 0.0960 - val_loss: 2.5138 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.7597 - accuracy: 0.0994 - val_loss: 2.5626 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.6843 - accuracy: 0.1035 - val_loss: 2.6263 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.6243 - accuracy: 0.1021 - val_loss: 2.6558 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.5639 - accuracy: 0.1140 - val_loss: 2.6728 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.5325 - accuracy: 0.1068 - val_loss: 2.6698 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.4980 - accuracy: 0.1138 - val_loss: 2.6923 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.4752 - accuracy: 0.1095 - val_loss: 2.6552 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.4552 - accuracy: 0.1168 - val_loss: 2.6296 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.4355 - accuracy: 0.1237 - val_loss: 2.6482 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.4187 - accuracy: 0.1235 - val_loss: 2.6232 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.4048 - accuracy: 0.1259 - val_loss: 2.6129 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.3908 - accuracy: 0.1354 - val_loss: 2.5939 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3855 - accuracy: 0.1400 - val_loss: 2.5315 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3753 - accuracy: 0.1355 - val_loss: 2.4779 - val_accuracy: 0.0955 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3690 - accuracy: 0.1433 - val_loss: 2.4495 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 4s 113ms/step - loss: 2.3592 - accuracy: 0.1467 - val_loss: 2.4281 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.3520 - accuracy: 0.1542 - val_loss: 2.4293 - val_accuracy: 0.0955 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3451 - accuracy: 0.1564 - val_loss: 2.4333 - val_accuracy: 0.0955 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3330 - accuracy: 0.1648 - val_loss: 2.4366 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3240 - accuracy: 0.1664 - val_loss: 2.4412 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3169 - accuracy: 0.1679 - val_loss: 2.4384 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.3157 - accuracy: 0.1684 - val_loss: 2.4493 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3108 - accuracy: 0.1774 - val_loss: 2.4514 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3016 - accuracy: 0.1778 - val_loss: 2.4486 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2979 - accuracy: 0.1856 - val_loss: 2.4495 - val_accuracy: 0.0750 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2789 - accuracy: 0.1895 - val_loss: 2.4529 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2779 - accuracy: 0.1876 - val_loss: 2.4465 - val_accuracy: 0.0864 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2687 - accuracy: 0.1963 - val_loss: 2.4573 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2502 - accuracy: 0.2033 - val_loss: 2.4647 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2559 - accuracy: 0.2032 - val_loss: 2.4664 - val_accuracy: 0.0864 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2371 - accuracy: 0.2063 - val_loss: 2.4744 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2315 - accuracy: 0.2093 - val_loss: 2.4745 - val_accuracy: 0.0739 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2221 - accuracy: 0.2130 - val_loss: 2.4841 - val_accuracy: 0.0750 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1987 - accuracy: 0.2234 - val_loss: 2.4835 - val_accuracy: 0.0807 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1851 - accuracy: 0.2319 - val_loss: 2.4828 - val_accuracy: 0.0875 - lr: 3.0000e-04\nEpoch 39/100\n39/40 [============================>.] - ETA: 0s - loss: 2.1778 - accuracy: 0.2392\nEpoch 39: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 2.1771 - accuracy: 0.2402 - val_loss: 2.4871 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1572 - accuracy: 0.2505 - val_loss: 2.4882 - val_accuracy: 0.0955 - lr: 3.0000e-05\nEpoch 41/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1555 - accuracy: 0.2461 - val_loss: 2.4907 - val_accuracy: 0.0943 - lr: 3.0000e-05\nEpoch 42/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1537 - accuracy: 0.2482 - val_loss: 2.4921 - val_accuracy: 0.0909 - lr: 3.0000e-05\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1480 - accuracy: 0.2520 - val_loss: 2.4925 - val_accuracy: 0.0830 - lr: 3.0000e-05\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1401 - accuracy: 0.2521 - val_loss: 2.4936 - val_accuracy: 0.0852 - lr: 3.0000e-05\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1556 - accuracy: 0.2413 - val_loss: 2.4936 - val_accuracy: 0.0920 - lr: 3.0000e-05\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1373 - accuracy: 0.2489 - val_loss: 2.4928 - val_accuracy: 0.0886 - lr: 3.0000e-05\nEpoch 47/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1353 - accuracy: 0.2529 - val_loss: 2.4932 - val_accuracy: 0.0852 - lr: 3.0000e-05\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1398 - accuracy: 0.2552 - val_loss: 2.4936 - val_accuracy: 0.0841 - lr: 3.0000e-05\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1334 - accuracy: 0.2567 - val_loss: 2.4937 - val_accuracy: 0.0864 - lr: 3.0000e-05\nEpoch 50/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1319 - accuracy: 0.2489 - val_loss: 2.4942 - val_accuracy: 0.0864 - lr: 3.0000e-05\nEpoch 51/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.1241 - accuracy: 0.2646 - val_loss: 2.4938 - val_accuracy: 0.0841 - lr: 3.0000e-05\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1222 - accuracy: 0.2612 - val_loss: 2.4953 - val_accuracy: 0.0852 - lr: 3.0000e-05\nEpoch 53/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1286 - accuracy: 0.2558 - val_loss: 2.4948 - val_accuracy: 0.0875 - lr: 3.0000e-05\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1225 - accuracy: 0.2598 - val_loss: 2.4948 - val_accuracy: 0.0932 - lr: 3.0000e-05\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1218 - accuracy: 0.2611 - val_loss: 2.4954 - val_accuracy: 0.0909 - lr: 3.0000e-05\nEpoch 56/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1184 - accuracy: 0.2604 - val_loss: 2.4956 - val_accuracy: 0.0920 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1037 - accuracy: 0.2678 - val_loss: 2.4962 - val_accuracy: 0.0943 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1177 - accuracy: 0.2630 - val_loss: 2.4967 - val_accuracy: 0.0943 - lr: 3.0000e-05\nEpoch 59/100\n39/40 [============================>.] - ETA: 0s - loss: 2.1087 - accuracy: 0.2708\nEpoch 59: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 30ms/step - loss: 2.1090 - accuracy: 0.2701 - val_loss: 2.4974 - val_accuracy: 0.0909 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1038 - accuracy: 0.2667 - val_loss: 2.4978 - val_accuracy: 0.0886 - lr: 3.0000e-06\nEpoch 61/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1093 - accuracy: 0.2641 - val_loss: 2.4980 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 62/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1024 - accuracy: 0.2673 - val_loss: 2.4982 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1043 - accuracy: 0.2730 - val_loss: 2.4981 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0990 - accuracy: 0.2729 - val_loss: 2.4982 - val_accuracy: 0.0909 - lr: 3.0000e-06\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1123 - accuracy: 0.2649 - val_loss: 2.4983 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 66/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1088 - accuracy: 0.2636 - val_loss: 2.4983 - val_accuracy: 0.0886 - lr: 3.0000e-06\nEpoch 67/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1029 - accuracy: 0.2615 - val_loss: 2.4987 - val_accuracy: 0.0864 - lr: 3.0000e-06\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1056 - accuracy: 0.2694 - val_loss: 2.4986 - val_accuracy: 0.0864 - lr: 3.0000e-06\nEpoch 69/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1033 - accuracy: 0.2665 - val_loss: 2.4985 - val_accuracy: 0.0875 - lr: 3.0000e-06\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1035 - accuracy: 0.2713 - val_loss: 2.4988 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 71/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1081 - accuracy: 0.2639 - val_loss: 2.4987 - val_accuracy: 0.0886 - lr: 3.0000e-06\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0967 - accuracy: 0.2706 - val_loss: 2.4987 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 73/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1035 - accuracy: 0.2694 - val_loss: 2.4986 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1039 - accuracy: 0.2697 - val_loss: 2.4987 - val_accuracy: 0.0886 - lr: 3.0000e-06\nEpoch 75/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.0965 - accuracy: 0.2735 - val_loss: 2.4986 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 76/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1077 - accuracy: 0.2736 - val_loss: 2.4990 - val_accuracy: 0.0886 - lr: 3.0000e-06\nEpoch 77/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.0893 - accuracy: 0.2771 - val_loss: 2.4989 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1084 - accuracy: 0.2710 - val_loss: 2.4989 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 79/100\n39/40 [============================>.] - ETA: 0s - loss: 2.0982 - accuracy: 0.2709\nEpoch 79: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-07.\n40/40 [==============================] - 1s 29ms/step - loss: 2.0990 - accuracy: 0.2708 - val_loss: 2.4990 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1116 - accuracy: 0.2616 - val_loss: 2.4990 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0884 - accuracy: 0.2734 - val_loss: 2.4991 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 82/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0993 - accuracy: 0.2693 - val_loss: 2.4989 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 83/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0987 - accuracy: 0.2699 - val_loss: 2.4988 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1087 - accuracy: 0.2588 - val_loss: 2.4990 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 85/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1025 - accuracy: 0.2701 - val_loss: 2.4989 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 86/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0950 - accuracy: 0.2727 - val_loss: 2.4991 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 87/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1116 - accuracy: 0.2662 - val_loss: 2.4991 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 88/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1046 - accuracy: 0.2677 - val_loss: 2.4991 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1117 - accuracy: 0.2635 - val_loss: 2.4993 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 90/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1035 - accuracy: 0.2665 - val_loss: 2.4992 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 91/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0909 - accuracy: 0.2720 - val_loss: 2.4993 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0986 - accuracy: 0.2681 - val_loss: 2.4995 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 93/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1052 - accuracy: 0.2663 - val_loss: 2.4992 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0956 - accuracy: 0.2722 - val_loss: 2.4991 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 95/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1062 - accuracy: 0.2706 - val_loss: 2.4993 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0995 - accuracy: 0.2745 - val_loss: 2.4994 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1191 - accuracy: 0.2593 - val_loss: 2.4993 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 98/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0937 - accuracy: 0.2676 - val_loss: 2.4993 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 99/100\n39/40 [============================>.] - ETA: 0s - loss: 2.1095 - accuracy: 0.2631\nEpoch 99: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-08.\n40/40 [==============================] - 1s 30ms/step - loss: 2.1098 - accuracy: 0.2620 - val_loss: 2.4994 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1046 - accuracy: 0.2641 - val_loss: 2.4993 - val_accuracy: 0.0898 - lr: 3.0000e-08\n69/69 - 0s - loss: 2.5003 - accuracy: 0.0995 - 277ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.09954545646905899\nStarting training for SNR: -18\nEpoch 1/100\n 1/40 [..............................] - ETA: 41s - loss: 3.0517 - accuracy: 0.1350","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:10:05.864917: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_7/dropout_28/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 100ms/step - loss: 3.1250 - accuracy: 0.0957 - val_loss: 2.4220 - val_accuracy: 0.0864 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.9898 - accuracy: 0.0893 - val_loss: 2.4532 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.8360 - accuracy: 0.1008 - val_loss: 2.4633 - val_accuracy: 0.1000 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.7539 - accuracy: 0.1003 - val_loss: 2.4869 - val_accuracy: 0.1000 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.6833 - accuracy: 0.1081 - val_loss: 2.5262 - val_accuracy: 0.1000 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.6242 - accuracy: 0.1081 - val_loss: 2.6525 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.5665 - accuracy: 0.1126 - val_loss: 2.7963 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.5389 - accuracy: 0.1104 - val_loss: 2.9742 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.4972 - accuracy: 0.1153 - val_loss: 3.3328 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.4673 - accuracy: 0.1210 - val_loss: 3.9583 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.4537 - accuracy: 0.1213 - val_loss: 4.6315 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.4282 - accuracy: 0.1293 - val_loss: 5.4683 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.4053 - accuracy: 0.1362 - val_loss: 6.4422 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3945 - accuracy: 0.1404 - val_loss: 7.0892 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.3744 - accuracy: 0.1463 - val_loss: 7.3671 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.3807 - accuracy: 0.1394 - val_loss: 6.9628 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3610 - accuracy: 0.1423 - val_loss: 6.3987 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3477 - accuracy: 0.1548 - val_loss: 4.3315 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3470 - accuracy: 0.1571 - val_loss: 3.0681 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3357 - accuracy: 0.1622 - val_loss: 2.6729 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 21/100\n39/40 [============================>.] - ETA: 0s - loss: 2.3347 - accuracy: 0.1671\nEpoch 21: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 2.3345 - accuracy: 0.1673 - val_loss: 2.4731 - val_accuracy: 0.1034 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3090 - accuracy: 0.1711 - val_loss: 2.4683 - val_accuracy: 0.1011 - lr: 3.0000e-05\nEpoch 23/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3133 - accuracy: 0.1712 - val_loss: 2.4710 - val_accuracy: 0.1011 - lr: 3.0000e-05\nEpoch 24/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3061 - accuracy: 0.1750 - val_loss: 2.4733 - val_accuracy: 0.1000 - lr: 3.0000e-05\nEpoch 25/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3084 - accuracy: 0.1801 - val_loss: 2.4735 - val_accuracy: 0.1045 - lr: 3.0000e-05\nEpoch 26/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3068 - accuracy: 0.1703 - val_loss: 2.4754 - val_accuracy: 0.1000 - lr: 3.0000e-05\nEpoch 27/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3098 - accuracy: 0.1723 - val_loss: 2.4781 - val_accuracy: 0.1000 - lr: 3.0000e-05\nEpoch 28/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3047 - accuracy: 0.1744 - val_loss: 2.4760 - val_accuracy: 0.1000 - lr: 3.0000e-05\nEpoch 29/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3057 - accuracy: 0.1701 - val_loss: 2.4776 - val_accuracy: 0.1000 - lr: 3.0000e-05\nEpoch 30/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2962 - accuracy: 0.1799 - val_loss: 2.4801 - val_accuracy: 0.0989 - lr: 3.0000e-05\nEpoch 31/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2969 - accuracy: 0.1717 - val_loss: 2.4789 - val_accuracy: 0.0977 - lr: 3.0000e-05\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2996 - accuracy: 0.1808 - val_loss: 2.4769 - val_accuracy: 0.0943 - lr: 3.0000e-05\nEpoch 33/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2929 - accuracy: 0.1811 - val_loss: 2.4761 - val_accuracy: 0.0909 - lr: 3.0000e-05\nEpoch 34/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2976 - accuracy: 0.1755 - val_loss: 2.4768 - val_accuracy: 0.0909 - lr: 3.0000e-05\nEpoch 35/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2980 - accuracy: 0.1785 - val_loss: 2.4754 - val_accuracy: 0.0898 - lr: 3.0000e-05\nEpoch 36/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2866 - accuracy: 0.1838 - val_loss: 2.4765 - val_accuracy: 0.0909 - lr: 3.0000e-05\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2954 - accuracy: 0.1768 - val_loss: 2.4791 - val_accuracy: 0.0898 - lr: 3.0000e-05\nEpoch 38/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.2877 - accuracy: 0.1838 - val_loss: 2.4798 - val_accuracy: 0.0920 - lr: 3.0000e-05\nEpoch 39/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2870 - accuracy: 0.1823 - val_loss: 2.4789 - val_accuracy: 0.0932 - lr: 3.0000e-05\nEpoch 40/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2989 - accuracy: 0.1775 - val_loss: 2.4787 - val_accuracy: 0.0932 - lr: 3.0000e-05\nEpoch 41/100\n39/40 [============================>.] - ETA: 0s - loss: 2.2900 - accuracy: 0.1847\nEpoch 41: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 30ms/step - loss: 2.2896 - accuracy: 0.1840 - val_loss: 2.4785 - val_accuracy: 0.0943 - lr: 3.0000e-05\nEpoch 42/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2874 - accuracy: 0.1885 - val_loss: 2.4787 - val_accuracy: 0.0943 - lr: 3.0000e-06\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2807 - accuracy: 0.1875 - val_loss: 2.4792 - val_accuracy: 0.0932 - lr: 3.0000e-06\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2911 - accuracy: 0.1779 - val_loss: 2.4796 - val_accuracy: 0.0920 - lr: 3.0000e-06\nEpoch 45/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2767 - accuracy: 0.1866 - val_loss: 2.4793 - val_accuracy: 0.0920 - lr: 3.0000e-06\nEpoch 46/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2810 - accuracy: 0.1843 - val_loss: 2.4793 - val_accuracy: 0.0920 - lr: 3.0000e-06\nEpoch 47/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2836 - accuracy: 0.1836 - val_loss: 2.4793 - val_accuracy: 0.0920 - lr: 3.0000e-06\nEpoch 48/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2860 - accuracy: 0.1883 - val_loss: 2.4792 - val_accuracy: 0.0920 - lr: 3.0000e-06\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2838 - accuracy: 0.1769 - val_loss: 2.4792 - val_accuracy: 0.0920 - lr: 3.0000e-06\nEpoch 50/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2886 - accuracy: 0.1847 - val_loss: 2.4790 - val_accuracy: 0.0920 - lr: 3.0000e-06\nEpoch 51/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2806 - accuracy: 0.1872 - val_loss: 2.4792 - val_accuracy: 0.0920 - lr: 3.0000e-06\nEpoch 52/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2819 - accuracy: 0.1842 - val_loss: 2.4790 - val_accuracy: 0.0932 - lr: 3.0000e-06\nEpoch 53/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2780 - accuracy: 0.1852 - val_loss: 2.4789 - val_accuracy: 0.0920 - lr: 3.0000e-06\nEpoch 54/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2752 - accuracy: 0.1823 - val_loss: 2.4790 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2839 - accuracy: 0.1852 - val_loss: 2.4794 - val_accuracy: 0.0909 - lr: 3.0000e-06\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2836 - accuracy: 0.1852 - val_loss: 2.4796 - val_accuracy: 0.0909 - lr: 3.0000e-06\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2823 - accuracy: 0.1878 - val_loss: 2.4800 - val_accuracy: 0.0909 - lr: 3.0000e-06\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2794 - accuracy: 0.1883 - val_loss: 2.4799 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2909 - accuracy: 0.1823 - val_loss: 2.4801 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2748 - accuracy: 0.1902 - val_loss: 2.4804 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 61/100\n39/40 [============================>.] - ETA: 0s - loss: 2.2884 - accuracy: 0.1753\nEpoch 61: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-07.\n40/40 [==============================] - 1s 30ms/step - loss: 2.2893 - accuracy: 0.1756 - val_loss: 2.4801 - val_accuracy: 0.0898 - lr: 3.0000e-06\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2834 - accuracy: 0.1886 - val_loss: 2.4802 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 63/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2726 - accuracy: 0.1922 - val_loss: 2.4803 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 64/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.2778 - accuracy: 0.1836 - val_loss: 2.4801 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2824 - accuracy: 0.1803 - val_loss: 2.4805 - val_accuracy: 0.0909 - lr: 3.0000e-07\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2799 - accuracy: 0.1876 - val_loss: 2.4805 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 67/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2838 - accuracy: 0.1827 - val_loss: 2.4804 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 68/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2804 - accuracy: 0.1861 - val_loss: 2.4803 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 69/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2832 - accuracy: 0.1893 - val_loss: 2.4802 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 70/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2723 - accuracy: 0.1936 - val_loss: 2.4802 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 71/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2717 - accuracy: 0.1890 - val_loss: 2.4802 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2728 - accuracy: 0.1861 - val_loss: 2.4803 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2817 - accuracy: 0.1862 - val_loss: 2.4802 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2740 - accuracy: 0.1881 - val_loss: 2.4801 - val_accuracy: 0.0909 - lr: 3.0000e-07\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2707 - accuracy: 0.1944 - val_loss: 2.4803 - val_accuracy: 0.0920 - lr: 3.0000e-07\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2781 - accuracy: 0.1851 - val_loss: 2.4800 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 77/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2840 - accuracy: 0.1808 - val_loss: 2.4803 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2747 - accuracy: 0.1896 - val_loss: 2.4802 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2768 - accuracy: 0.1854 - val_loss: 2.4803 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2913 - accuracy: 0.1775 - val_loss: 2.4803 - val_accuracy: 0.0898 - lr: 3.0000e-07\nEpoch 81/100\n39/40 [============================>.] - ETA: 0s - loss: 2.2813 - accuracy: 0.1828\nEpoch 81: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-08.\n40/40 [==============================] - 1s 30ms/step - loss: 2.2807 - accuracy: 0.1833 - val_loss: 2.4800 - val_accuracy: 0.0886 - lr: 3.0000e-07\nEpoch 82/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2831 - accuracy: 0.1842 - val_loss: 2.4802 - val_accuracy: 0.0898 - lr: 3.0000e-08\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2823 - accuracy: 0.1845 - val_loss: 2.4804 - val_accuracy: 0.0886 - lr: 3.0000e-08\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2842 - accuracy: 0.1874 - val_loss: 2.4803 - val_accuracy: 0.0886 - lr: 3.0000e-08\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2776 - accuracy: 0.1929 - val_loss: 2.4806 - val_accuracy: 0.0909 - lr: 3.0000e-08\nEpoch 86/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2860 - accuracy: 0.1828 - val_loss: 2.4808 - val_accuracy: 0.0920 - lr: 3.0000e-08\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2833 - accuracy: 0.1884 - val_loss: 2.4806 - val_accuracy: 0.0898 - lr: 3.0000e-08\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2724 - accuracy: 0.1972 - val_loss: 2.4808 - val_accuracy: 0.0909 - lr: 3.0000e-08\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2764 - accuracy: 0.1874 - val_loss: 2.4805 - val_accuracy: 0.0898 - lr: 3.0000e-08\nEpoch 90/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.2805 - accuracy: 0.1867 - val_loss: 2.4804 - val_accuracy: 0.0886 - lr: 3.0000e-08\nEpoch 91/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2816 - accuracy: 0.1831 - val_loss: 2.4806 - val_accuracy: 0.0886 - lr: 3.0000e-08\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2811 - accuracy: 0.1865 - val_loss: 2.4806 - val_accuracy: 0.0898 - lr: 3.0000e-08\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2767 - accuracy: 0.1878 - val_loss: 2.4809 - val_accuracy: 0.0909 - lr: 3.0000e-08\nEpoch 94/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2744 - accuracy: 0.1979 - val_loss: 2.4806 - val_accuracy: 0.0898 - lr: 3.0000e-08\nEpoch 95/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2795 - accuracy: 0.1864 - val_loss: 2.4808 - val_accuracy: 0.0898 - lr: 3.0000e-08\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2820 - accuracy: 0.1860 - val_loss: 2.4807 - val_accuracy: 0.0886 - lr: 3.0000e-08\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2743 - accuracy: 0.1840 - val_loss: 2.4808 - val_accuracy: 0.0886 - lr: 3.0000e-08\nEpoch 98/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2898 - accuracy: 0.1816 - val_loss: 2.4807 - val_accuracy: 0.0886 - lr: 3.0000e-08\nEpoch 99/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2742 - accuracy: 0.1888 - val_loss: 2.4808 - val_accuracy: 0.0898 - lr: 3.0000e-08\nEpoch 100/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2789 - accuracy: 0.1817 - val_loss: 2.4809 - val_accuracy: 0.0886 - lr: 3.0000e-08\n69/69 - 0s - loss: 2.4418 - accuracy: 0.1114 - 235ms/epoch - 3ms/step\n69/69 [==============================] - 0s 2ms/step\naccuracy = 0.11136363446712494\nStarting training for SNR: 16\nEpoch 1/100\n 1/40 [..............................] - ETA: 40s - loss: 3.1899 - accuracy: 0.1150","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:12:11.239345: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_8/dropout_32/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 103ms/step - loss: 2.2199 - accuracy: 0.2795 - val_loss: 2.6902 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.6357 - accuracy: 0.4032 - val_loss: 3.9118 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3608 - accuracy: 0.4862 - val_loss: 5.4640 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1496 - accuracy: 0.5574 - val_loss: 6.9106 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.9985 - accuracy: 0.6009 - val_loss: 8.2397 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.8861 - accuracy: 0.6374 - val_loss: 9.3448 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7915 - accuracy: 0.6698 - val_loss: 10.5623 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7302 - accuracy: 0.6860 - val_loss: 11.4603 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6816 - accuracy: 0.6970 - val_loss: 12.1111 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6354 - accuracy: 0.7186 - val_loss: 12.8294 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6113 - accuracy: 0.7215 - val_loss: 13.2126 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.5769 - accuracy: 0.7342 - val_loss: 13.6063 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5567 - accuracy: 0.7438 - val_loss: 13.4124 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.5351 - accuracy: 0.7477 - val_loss: 13.0968 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.5294 - accuracy: 0.7530 - val_loss: 12.3084 - val_accuracy: 0.1307 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5238 - accuracy: 0.7545 - val_loss: 10.8913 - val_accuracy: 0.1420 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5032 - accuracy: 0.7648 - val_loss: 8.6383 - val_accuracy: 0.1818 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4879 - accuracy: 0.7654 - val_loss: 7.2045 - val_accuracy: 0.1250 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4859 - accuracy: 0.7720 - val_loss: 4.1971 - val_accuracy: 0.2091 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 114ms/step - loss: 0.4797 - accuracy: 0.7689 - val_loss: 2.2683 - val_accuracy: 0.3932 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.4775 - accuracy: 0.7710 - val_loss: 1.6500 - val_accuracy: 0.5057 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.4722 - accuracy: 0.7697 - val_loss: 1.3270 - val_accuracy: 0.5648 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4604 - accuracy: 0.7793 - val_loss: 0.9507 - val_accuracy: 0.6455 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4637 - accuracy: 0.7763 - val_loss: 0.6224 - val_accuracy: 0.7193 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.4453 - accuracy: 0.7846 - val_loss: 0.6473 - val_accuracy: 0.7250 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4435 - accuracy: 0.7875 - val_loss: 0.6808 - val_accuracy: 0.7227 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4416 - accuracy: 0.7842 - val_loss: 0.6573 - val_accuracy: 0.7114 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4356 - accuracy: 0.7960 - val_loss: 0.7087 - val_accuracy: 0.6864 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 5s 115ms/step - loss: 0.4363 - accuracy: 0.7949 - val_loss: 0.5689 - val_accuracy: 0.7239 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4264 - accuracy: 0.7971 - val_loss: 0.5894 - val_accuracy: 0.7273 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4253 - accuracy: 0.7971 - val_loss: 0.5966 - val_accuracy: 0.7523 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.4178 - accuracy: 0.8019 - val_loss: 0.5547 - val_accuracy: 0.7170 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4238 - accuracy: 0.7995 - val_loss: 0.5279 - val_accuracy: 0.7432 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.4165 - accuracy: 0.8010 - val_loss: 0.5812 - val_accuracy: 0.7364 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4099 - accuracy: 0.8058 - val_loss: 0.6159 - val_accuracy: 0.7284 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4057 - accuracy: 0.8080 - val_loss: 0.6747 - val_accuracy: 0.7091 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3995 - accuracy: 0.8121 - val_loss: 0.5575 - val_accuracy: 0.7432 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3980 - accuracy: 0.8157 - val_loss: 0.5639 - val_accuracy: 0.7375 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3856 - accuracy: 0.8210 - val_loss: 0.5831 - val_accuracy: 0.7477 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3767 - accuracy: 0.8250 - val_loss: 0.5668 - val_accuracy: 0.7386 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.3783 - accuracy: 0.8215 - val_loss: 0.5191 - val_accuracy: 0.7602 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3850 - accuracy: 0.8157 - val_loss: 0.5484 - val_accuracy: 0.7511 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3741 - accuracy: 0.8261 - val_loss: 0.5747 - val_accuracy: 0.7489 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3654 - accuracy: 0.8287 - val_loss: 0.5720 - val_accuracy: 0.7455 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 4s 113ms/step - loss: 0.3649 - accuracy: 0.8318 - val_loss: 0.4961 - val_accuracy: 0.7591 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3563 - accuracy: 0.8354 - val_loss: 0.5114 - val_accuracy: 0.7614 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3490 - accuracy: 0.8380 - val_loss: 0.5403 - val_accuracy: 0.7534 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3492 - accuracy: 0.8370 - val_loss: 0.5262 - val_accuracy: 0.7648 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3357 - accuracy: 0.8473 - val_loss: 0.5117 - val_accuracy: 0.7739 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3380 - accuracy: 0.8442 - val_loss: 0.5125 - val_accuracy: 0.7670 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3212 - accuracy: 0.8540 - val_loss: 0.5061 - val_accuracy: 0.7693 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.3243 - accuracy: 0.8524 - val_loss: 0.4865 - val_accuracy: 0.7795 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3193 - accuracy: 0.8505 - val_loss: 0.5260 - val_accuracy: 0.7614 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3116 - accuracy: 0.8612 - val_loss: 0.5059 - val_accuracy: 0.7761 - lr: 3.0000e-04\nEpoch 55/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3203 - accuracy: 0.8501 - val_loss: 0.5134 - val_accuracy: 0.7761 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3028 - accuracy: 0.8607 - val_loss: 0.4944 - val_accuracy: 0.7761 - lr: 3.0000e-04\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3034 - accuracy: 0.8630 - val_loss: 0.6880 - val_accuracy: 0.6886 - lr: 3.0000e-04\nEpoch 58/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3022 - accuracy: 0.8617 - val_loss: 0.5303 - val_accuracy: 0.7602 - lr: 3.0000e-04\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2948 - accuracy: 0.8657 - val_loss: 0.5282 - val_accuracy: 0.7682 - lr: 3.0000e-04\nEpoch 60/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2944 - accuracy: 0.8665 - val_loss: 0.5208 - val_accuracy: 0.7807 - lr: 3.0000e-04\nEpoch 61/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2892 - accuracy: 0.8679 - val_loss: 0.5209 - val_accuracy: 0.7727 - lr: 3.0000e-04\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2866 - accuracy: 0.8678 - val_loss: 0.4958 - val_accuracy: 0.7795 - lr: 3.0000e-04\nEpoch 63/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2807 - accuracy: 0.8683 - val_loss: 0.5246 - val_accuracy: 0.7750 - lr: 3.0000e-04\nEpoch 64/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2743 - accuracy: 0.8764 - val_loss: 0.5368 - val_accuracy: 0.7739 - lr: 3.0000e-04\nEpoch 65/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2789 - accuracy: 0.8732 - val_loss: 0.5354 - val_accuracy: 0.7727 - lr: 3.0000e-04\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2740 - accuracy: 0.8702 - val_loss: 0.5986 - val_accuracy: 0.7534 - lr: 3.0000e-04\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2737 - accuracy: 0.8755 - val_loss: 0.6048 - val_accuracy: 0.7420 - lr: 3.0000e-04\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2718 - accuracy: 0.8765 - val_loss: 0.5462 - val_accuracy: 0.7727 - lr: 3.0000e-04\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2688 - accuracy: 0.8758 - val_loss: 0.6730 - val_accuracy: 0.7352 - lr: 3.0000e-04\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2557 - accuracy: 0.8784 - val_loss: 0.5387 - val_accuracy: 0.7614 - lr: 3.0000e-04\nEpoch 71/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2545 - accuracy: 0.8813 - val_loss: 0.5344 - val_accuracy: 0.7716 - lr: 3.0000e-04\nEpoch 72/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2547 - accuracy: 0.8810\nEpoch 72: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 29ms/step - loss: 0.2548 - accuracy: 0.8807 - val_loss: 0.5586 - val_accuracy: 0.7716 - lr: 3.0000e-04\nEpoch 73/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2400 - accuracy: 0.8894 - val_loss: 0.5418 - val_accuracy: 0.7716 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2385 - accuracy: 0.8937 - val_loss: 0.5380 - val_accuracy: 0.7727 - lr: 3.0000e-05\nEpoch 75/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2413 - accuracy: 0.8891 - val_loss: 0.5355 - val_accuracy: 0.7761 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2306 - accuracy: 0.8961 - val_loss: 0.5381 - val_accuracy: 0.7727 - lr: 3.0000e-05\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2361 - accuracy: 0.8920 - val_loss: 0.5324 - val_accuracy: 0.7716 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2285 - accuracy: 0.8958 - val_loss: 0.5350 - val_accuracy: 0.7750 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2294 - accuracy: 0.8955 - val_loss: 0.5350 - val_accuracy: 0.7739 - lr: 3.0000e-05\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2282 - accuracy: 0.8989 - val_loss: 0.5272 - val_accuracy: 0.7784 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2280 - accuracy: 0.8947 - val_loss: 0.5274 - val_accuracy: 0.7773 - lr: 3.0000e-05\nEpoch 82/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2310 - accuracy: 0.8941 - val_loss: 0.5313 - val_accuracy: 0.7750 - lr: 3.0000e-05\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2299 - accuracy: 0.8965 - val_loss: 0.5264 - val_accuracy: 0.7784 - lr: 3.0000e-05\nEpoch 84/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2269 - accuracy: 0.8948 - val_loss: 0.5183 - val_accuracy: 0.7773 - lr: 3.0000e-05\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2283 - accuracy: 0.8938 - val_loss: 0.5258 - val_accuracy: 0.7773 - lr: 3.0000e-05\nEpoch 86/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2263 - accuracy: 0.8966 - val_loss: 0.5293 - val_accuracy: 0.7739 - lr: 3.0000e-05\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2249 - accuracy: 0.8956 - val_loss: 0.5269 - val_accuracy: 0.7761 - lr: 3.0000e-05\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2281 - accuracy: 0.8973 - val_loss: 0.5243 - val_accuracy: 0.7739 - lr: 3.0000e-05\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2230 - accuracy: 0.8981 - val_loss: 0.5338 - val_accuracy: 0.7727 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2289 - accuracy: 0.8991 - val_loss: 0.5356 - val_accuracy: 0.7727 - lr: 3.0000e-05\nEpoch 91/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2256 - accuracy: 0.8986 - val_loss: 0.5302 - val_accuracy: 0.7739 - lr: 3.0000e-05\nEpoch 92/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2254 - accuracy: 0.8935\nEpoch 92: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 30ms/step - loss: 0.2255 - accuracy: 0.8931 - val_loss: 0.5279 - val_accuracy: 0.7761 - lr: 3.0000e-05\nEpoch 93/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2257 - accuracy: 0.8977 - val_loss: 0.5286 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2228 - accuracy: 0.8985 - val_loss: 0.5278 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2255 - accuracy: 0.8970 - val_loss: 0.5265 - val_accuracy: 0.7773 - lr: 3.0000e-06\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2226 - accuracy: 0.8982 - val_loss: 0.5266 - val_accuracy: 0.7739 - lr: 3.0000e-06\nEpoch 97/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2194 - accuracy: 0.8966 - val_loss: 0.5265 - val_accuracy: 0.7750 - lr: 3.0000e-06\nEpoch 98/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2227 - accuracy: 0.8985 - val_loss: 0.5261 - val_accuracy: 0.7773 - lr: 3.0000e-06\nEpoch 99/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2242 - accuracy: 0.9019 - val_loss: 0.5248 - val_accuracy: 0.7761 - lr: 3.0000e-06\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2223 - accuracy: 0.8991 - val_loss: 0.5263 - val_accuracy: 0.7773 - lr: 3.0000e-06\n69/69 - 0s - loss: 0.4224 - accuracy: 0.8045 - 232ms/epoch - 3ms/step\n69/69 [==============================] - 0s 2ms/step\naccuracy = 0.8045454621315002\nStarting training for SNR: 10\nEpoch 1/100\n 1/40 [..............................] - ETA: 41s - loss: 3.1168 - accuracy: 0.1200","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:14:46.969897: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_9/dropout_36/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 101ms/step - loss: 2.2162 - accuracy: 0.2832 - val_loss: 2.7290 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.6518 - accuracy: 0.3852 - val_loss: 3.7603 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.4146 - accuracy: 0.4465 - val_loss: 4.9545 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2019 - accuracy: 0.5253 - val_loss: 6.0792 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0355 - accuracy: 0.5816 - val_loss: 7.1229 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9202 - accuracy: 0.6249 - val_loss: 8.0309 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8095 - accuracy: 0.6549 - val_loss: 8.6076 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7491 - accuracy: 0.6819 - val_loss: 9.3586 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7090 - accuracy: 0.6865 - val_loss: 9.9971 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6666 - accuracy: 0.7025 - val_loss: 10.3192 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6195 - accuracy: 0.7211 - val_loss: 10.5287 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5911 - accuracy: 0.7229 - val_loss: 10.9005 - val_accuracy: 0.0875 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 33ms/step - loss: 0.5649 - accuracy: 0.7303 - val_loss: 11.1736 - val_accuracy: 0.0875 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.5453 - accuracy: 0.7472 - val_loss: 10.7531 - val_accuracy: 0.0466 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.5407 - accuracy: 0.7408 - val_loss: 10.4836 - val_accuracy: 0.0875 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.5122 - accuracy: 0.7585 - val_loss: 9.4750 - val_accuracy: 0.0875 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4944 - accuracy: 0.7596 - val_loss: 7.8208 - val_accuracy: 0.1602 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4858 - accuracy: 0.7648 - val_loss: 6.3854 - val_accuracy: 0.1716 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4785 - accuracy: 0.7674 - val_loss: 4.0016 - val_accuracy: 0.1932 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 93ms/step - loss: 0.4697 - accuracy: 0.7745 - val_loss: 2.2727 - val_accuracy: 0.4023 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 5s 115ms/step - loss: 0.4607 - accuracy: 0.7783 - val_loss: 1.6171 - val_accuracy: 0.5273 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4513 - accuracy: 0.7744 - val_loss: 1.1730 - val_accuracy: 0.6023 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4410 - accuracy: 0.7891 - val_loss: 0.6388 - val_accuracy: 0.7352 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.4426 - accuracy: 0.7813 - val_loss: 0.5572 - val_accuracy: 0.7489 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 5s 126ms/step - loss: 0.4294 - accuracy: 0.7920 - val_loss: 0.5233 - val_accuracy: 0.7580 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4293 - accuracy: 0.7927 - val_loss: 0.5260 - val_accuracy: 0.7625 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4239 - accuracy: 0.7967 - val_loss: 0.6980 - val_accuracy: 0.7136 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.4260 - accuracy: 0.7957 - val_loss: 0.5047 - val_accuracy: 0.7705 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4151 - accuracy: 0.7941 - val_loss: 0.4793 - val_accuracy: 0.7727 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4145 - accuracy: 0.7991 - val_loss: 0.5543 - val_accuracy: 0.7455 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4043 - accuracy: 0.8051 - val_loss: 0.4849 - val_accuracy: 0.7727 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4058 - accuracy: 0.8066 - val_loss: 0.5052 - val_accuracy: 0.7670 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3949 - accuracy: 0.8047 - val_loss: 0.5648 - val_accuracy: 0.7466 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.3892 - accuracy: 0.8130 - val_loss: 0.4486 - val_accuracy: 0.7909 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3884 - accuracy: 0.8101 - val_loss: 0.4487 - val_accuracy: 0.7989 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 4s 114ms/step - loss: 0.3820 - accuracy: 0.8141 - val_loss: 0.4139 - val_accuracy: 0.8000 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3859 - accuracy: 0.8114 - val_loss: 0.4683 - val_accuracy: 0.7875 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3802 - accuracy: 0.8179 - val_loss: 0.4664 - val_accuracy: 0.7761 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3789 - accuracy: 0.8187 - val_loss: 0.4628 - val_accuracy: 0.8045 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3710 - accuracy: 0.8189 - val_loss: 0.4546 - val_accuracy: 0.7898 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 4s 100ms/step - loss: 0.3626 - accuracy: 0.8237 - val_loss: 0.4040 - val_accuracy: 0.8068 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3624 - accuracy: 0.8240 - val_loss: 0.4658 - val_accuracy: 0.7898 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3548 - accuracy: 0.8324 - val_loss: 0.4607 - val_accuracy: 0.7841 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.3547 - accuracy: 0.8245 - val_loss: 0.3864 - val_accuracy: 0.8000 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3449 - accuracy: 0.8332 - val_loss: 0.3896 - val_accuracy: 0.8000 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3446 - accuracy: 0.8342 - val_loss: 0.4021 - val_accuracy: 0.8091 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3380 - accuracy: 0.8389 - val_loss: 0.4573 - val_accuracy: 0.7898 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3370 - accuracy: 0.8354 - val_loss: 0.3881 - val_accuracy: 0.8159 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.3361 - accuracy: 0.8395 - val_loss: 0.3807 - val_accuracy: 0.8148 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3254 - accuracy: 0.8415 - val_loss: 0.4179 - val_accuracy: 0.8034 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3242 - accuracy: 0.8477 - val_loss: 0.3913 - val_accuracy: 0.8125 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3197 - accuracy: 0.8473 - val_loss: 0.4170 - val_accuracy: 0.8136 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3201 - accuracy: 0.8484 - val_loss: 0.4227 - val_accuracy: 0.8080 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3091 - accuracy: 0.8497 - val_loss: 0.4484 - val_accuracy: 0.7966 - lr: 3.0000e-04\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3075 - accuracy: 0.8538 - val_loss: 0.3860 - val_accuracy: 0.8250 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3048 - accuracy: 0.8534 - val_loss: 0.4264 - val_accuracy: 0.8136 - lr: 3.0000e-04\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2946 - accuracy: 0.8668 - val_loss: 0.4961 - val_accuracy: 0.7909 - lr: 3.0000e-04\nEpoch 58/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2910 - accuracy: 0.8643 - val_loss: 0.3835 - val_accuracy: 0.8250 - lr: 3.0000e-04\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2849 - accuracy: 0.8641 - val_loss: 0.4051 - val_accuracy: 0.8227 - lr: 3.0000e-04\nEpoch 60/100\n40/40 [==============================] - 4s 102ms/step - loss: 0.2886 - accuracy: 0.8664 - val_loss: 0.3739 - val_accuracy: 0.8205 - lr: 3.0000e-04\nEpoch 61/100\n40/40 [==============================] - 5s 117ms/step - loss: 0.2843 - accuracy: 0.8679 - val_loss: 0.3720 - val_accuracy: 0.8295 - lr: 3.0000e-04\nEpoch 62/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2767 - accuracy: 0.8672 - val_loss: 0.3912 - val_accuracy: 0.8239 - lr: 3.0000e-04\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2766 - accuracy: 0.8707 - val_loss: 0.4348 - val_accuracy: 0.8045 - lr: 3.0000e-04\nEpoch 64/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.2686 - accuracy: 0.8745 - val_loss: 0.3585 - val_accuracy: 0.8341 - lr: 3.0000e-04\nEpoch 65/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2674 - accuracy: 0.8758 - val_loss: 0.3778 - val_accuracy: 0.8261 - lr: 3.0000e-04\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2659 - accuracy: 0.8746 - val_loss: 0.3885 - val_accuracy: 0.8239 - lr: 3.0000e-04\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2580 - accuracy: 0.8790 - val_loss: 0.3983 - val_accuracy: 0.8250 - lr: 3.0000e-04\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2547 - accuracy: 0.8787 - val_loss: 0.4799 - val_accuracy: 0.8057 - lr: 3.0000e-04\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2553 - accuracy: 0.8802 - val_loss: 0.4017 - val_accuracy: 0.8170 - lr: 3.0000e-04\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2498 - accuracy: 0.8817 - val_loss: 0.3944 - val_accuracy: 0.8239 - lr: 3.0000e-04\nEpoch 71/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2483 - accuracy: 0.8835 - val_loss: 0.3637 - val_accuracy: 0.8295 - lr: 3.0000e-04\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2412 - accuracy: 0.8841 - val_loss: 0.3754 - val_accuracy: 0.8295 - lr: 3.0000e-04\nEpoch 73/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.2454 - accuracy: 0.8837 - val_loss: 0.3583 - val_accuracy: 0.8364 - lr: 3.0000e-04\nEpoch 74/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2380 - accuracy: 0.8866 - val_loss: 0.4057 - val_accuracy: 0.8148 - lr: 3.0000e-04\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2372 - accuracy: 0.8898 - val_loss: 0.4505 - val_accuracy: 0.8023 - lr: 3.0000e-04\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2352 - accuracy: 0.8875 - val_loss: 0.4083 - val_accuracy: 0.8114 - lr: 3.0000e-04\nEpoch 77/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2292 - accuracy: 0.8885 - val_loss: 0.4521 - val_accuracy: 0.8023 - lr: 3.0000e-04\nEpoch 78/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.2333 - accuracy: 0.8850 - val_loss: 0.3409 - val_accuracy: 0.8352 - lr: 3.0000e-04\nEpoch 79/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2240 - accuracy: 0.8953 - val_loss: 0.3955 - val_accuracy: 0.8136 - lr: 3.0000e-04\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2256 - accuracy: 0.8919 - val_loss: 0.4561 - val_accuracy: 0.7989 - lr: 3.0000e-04\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2230 - accuracy: 0.8919 - val_loss: 0.3701 - val_accuracy: 0.8284 - lr: 3.0000e-04\nEpoch 82/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2186 - accuracy: 0.8957 - val_loss: 0.4266 - val_accuracy: 0.8136 - lr: 3.0000e-04\nEpoch 83/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2201 - accuracy: 0.8956 - val_loss: 0.5777 - val_accuracy: 0.7773 - lr: 3.0000e-04\nEpoch 84/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2120 - accuracy: 0.8979 - val_loss: 0.3982 - val_accuracy: 0.8216 - lr: 3.0000e-04\nEpoch 85/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2107 - accuracy: 0.9006 - val_loss: 0.3646 - val_accuracy: 0.8239 - lr: 3.0000e-04\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2041 - accuracy: 0.9066 - val_loss: 0.3986 - val_accuracy: 0.8341 - lr: 3.0000e-04\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2024 - accuracy: 0.9018 - val_loss: 0.4156 - val_accuracy: 0.8284 - lr: 3.0000e-04\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1981 - accuracy: 0.9052 - val_loss: 0.3702 - val_accuracy: 0.8261 - lr: 3.0000e-04\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2006 - accuracy: 0.9032 - val_loss: 0.4120 - val_accuracy: 0.8193 - lr: 3.0000e-04\nEpoch 90/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1952 - accuracy: 0.9040 - val_loss: 0.3730 - val_accuracy: 0.8250 - lr: 3.0000e-04\nEpoch 91/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1965 - accuracy: 0.9052 - val_loss: 0.3794 - val_accuracy: 0.8284 - lr: 3.0000e-04\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1976 - accuracy: 0.8992 - val_loss: 0.3927 - val_accuracy: 0.8307 - lr: 3.0000e-04\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1955 - accuracy: 0.9074 - val_loss: 0.4534 - val_accuracy: 0.8159 - lr: 3.0000e-04\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1888 - accuracy: 0.9064 - val_loss: 0.5329 - val_accuracy: 0.7977 - lr: 3.0000e-04\nEpoch 95/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1862 - accuracy: 0.9077 - val_loss: 0.4929 - val_accuracy: 0.7977 - lr: 3.0000e-04\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1880 - accuracy: 0.9074 - val_loss: 0.4040 - val_accuracy: 0.8261 - lr: 3.0000e-04\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1909 - accuracy: 0.9057 - val_loss: 0.3918 - val_accuracy: 0.8205 - lr: 3.0000e-04\nEpoch 98/100\n39/40 [============================>.] - ETA: 0s - loss: 0.1853 - accuracy: 0.9101\nEpoch 98: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.1852 - accuracy: 0.9106 - val_loss: 0.3666 - val_accuracy: 0.8318 - lr: 3.0000e-04\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1757 - accuracy: 0.9136 - val_loss: 0.3660 - val_accuracy: 0.8284 - lr: 3.0000e-05\nEpoch 100/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1717 - accuracy: 0.9150 - val_loss: 0.3571 - val_accuracy: 0.8364 - lr: 3.0000e-05\n69/69 - 0s - loss: 0.3960 - accuracy: 0.8214 - 273ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.821363627910614\nStarting training for SNR: 4\nEpoch 1/100\n 1/40 [..............................] - ETA: 40s - loss: 3.1783 - accuracy: 0.1300","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:18:10.854594: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_10/dropout_40/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 6s 126ms/step - loss: 2.2808 - accuracy: 0.2835 - val_loss: 2.5567 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.6240 - accuracy: 0.4146 - val_loss: 3.1689 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2494 - accuracy: 0.5104 - val_loss: 3.9352 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0125 - accuracy: 0.5798 - val_loss: 4.9941 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.8759 - accuracy: 0.6294 - val_loss: 6.1891 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7878 - accuracy: 0.6624 - val_loss: 7.1144 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7213 - accuracy: 0.6838 - val_loss: 8.0345 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6568 - accuracy: 0.7054 - val_loss: 8.7141 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6045 - accuracy: 0.7274 - val_loss: 9.2168 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5546 - accuracy: 0.7543 - val_loss: 9.9445 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5237 - accuracy: 0.7616 - val_loss: 10.2396 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5013 - accuracy: 0.7692 - val_loss: 10.1643 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4848 - accuracy: 0.7775 - val_loss: 10.0794 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4658 - accuracy: 0.7808 - val_loss: 9.6796 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4415 - accuracy: 0.7962 - val_loss: 9.0462 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4379 - accuracy: 0.7996 - val_loss: 8.5085 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4277 - accuracy: 0.7946 - val_loss: 5.9103 - val_accuracy: 0.1682 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4167 - accuracy: 0.8088 - val_loss: 5.8256 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4079 - accuracy: 0.8059 - val_loss: 3.2851 - val_accuracy: 0.2375 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.3905 - accuracy: 0.8197 - val_loss: 2.0062 - val_accuracy: 0.3614 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3844 - accuracy: 0.8237 - val_loss: 2.2062 - val_accuracy: 0.3818 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.3816 - accuracy: 0.8241 - val_loss: 0.7510 - val_accuracy: 0.7045 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3784 - accuracy: 0.8277 - val_loss: 0.8596 - val_accuracy: 0.6761 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.3650 - accuracy: 0.8311 - val_loss: 0.7193 - val_accuracy: 0.7045 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 5s 116ms/step - loss: 0.3568 - accuracy: 0.8359 - val_loss: 0.6038 - val_accuracy: 0.7818 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3517 - accuracy: 0.8343 - val_loss: 1.2494 - val_accuracy: 0.5864 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.3463 - accuracy: 0.8412 - val_loss: 0.5817 - val_accuracy: 0.7182 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3404 - accuracy: 0.8407 - val_loss: 0.6414 - val_accuracy: 0.7261 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3376 - accuracy: 0.8465 - val_loss: 0.9799 - val_accuracy: 0.6830 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3292 - accuracy: 0.8496 - val_loss: 0.7436 - val_accuracy: 0.7125 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3263 - accuracy: 0.8473 - val_loss: 1.2374 - val_accuracy: 0.6330 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3220 - accuracy: 0.8492 - val_loss: 0.9093 - val_accuracy: 0.7125 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3309 - accuracy: 0.8503 - val_loss: 0.8749 - val_accuracy: 0.7239 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.3068 - accuracy: 0.8595 - val_loss: 0.5239 - val_accuracy: 0.7307 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 4s 105ms/step - loss: 0.3142 - accuracy: 0.8530 - val_loss: 0.3856 - val_accuracy: 0.8193 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3088 - accuracy: 0.8576 - val_loss: 1.1531 - val_accuracy: 0.6636 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3039 - accuracy: 0.8582 - val_loss: 1.0082 - val_accuracy: 0.6955 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3085 - accuracy: 0.8611 - val_loss: 0.9622 - val_accuracy: 0.7273 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2998 - accuracy: 0.8624 - val_loss: 1.1054 - val_accuracy: 0.6875 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2962 - accuracy: 0.8598 - val_loss: 0.4094 - val_accuracy: 0.8182 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 5s 116ms/step - loss: 0.2910 - accuracy: 0.8665 - val_loss: 0.3431 - val_accuracy: 0.8511 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2976 - accuracy: 0.8606 - val_loss: 1.0254 - val_accuracy: 0.7114 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2835 - accuracy: 0.8677 - val_loss: 0.6852 - val_accuracy: 0.7648 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2859 - accuracy: 0.8692 - val_loss: 1.0223 - val_accuracy: 0.7205 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2820 - accuracy: 0.8729 - val_loss: 0.3623 - val_accuracy: 0.8318 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2762 - accuracy: 0.8745 - val_loss: 1.0827 - val_accuracy: 0.7193 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2717 - accuracy: 0.8753 - val_loss: 1.1271 - val_accuracy: 0.7034 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2675 - accuracy: 0.8782 - val_loss: 0.5584 - val_accuracy: 0.7670 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2626 - accuracy: 0.8827 - val_loss: 0.4801 - val_accuracy: 0.7989 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.2672 - accuracy: 0.8792 - val_loss: 0.3300 - val_accuracy: 0.8409 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2665 - accuracy: 0.8819 - val_loss: 0.3716 - val_accuracy: 0.8239 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2534 - accuracy: 0.8880 - val_loss: 1.0353 - val_accuracy: 0.7307 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2408 - accuracy: 0.8953 - val_loss: 1.1094 - val_accuracy: 0.7216 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2457 - accuracy: 0.8920 - val_loss: 1.1051 - val_accuracy: 0.7216 - lr: 3.0000e-04\nEpoch 55/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2467 - accuracy: 0.8910 - val_loss: 0.8434 - val_accuracy: 0.7591 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2394 - accuracy: 0.8923 - val_loss: 1.4240 - val_accuracy: 0.6568 - lr: 3.0000e-04\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2290 - accuracy: 0.8982 - val_loss: 0.9985 - val_accuracy: 0.7409 - lr: 3.0000e-04\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2306 - accuracy: 0.8972 - val_loss: 0.7619 - val_accuracy: 0.7795 - lr: 3.0000e-04\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2200 - accuracy: 0.9018 - val_loss: 1.0200 - val_accuracy: 0.7420 - lr: 3.0000e-04\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2193 - accuracy: 0.8982 - val_loss: 0.6614 - val_accuracy: 0.7977 - lr: 3.0000e-04\nEpoch 61/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2136 - accuracy: 0.9004 - val_loss: 0.5312 - val_accuracy: 0.7693 - lr: 3.0000e-04\nEpoch 62/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2244 - accuracy: 0.8991 - val_loss: 0.5144 - val_accuracy: 0.8057 - lr: 3.0000e-04\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2119 - accuracy: 0.9044 - val_loss: 0.3391 - val_accuracy: 0.8318 - lr: 3.0000e-04\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2135 - accuracy: 0.9013 - val_loss: 0.5148 - val_accuracy: 0.8136 - lr: 3.0000e-04\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2133 - accuracy: 0.9057 - val_loss: 1.1438 - val_accuracy: 0.7364 - lr: 3.0000e-04\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2046 - accuracy: 0.9105 - val_loss: 0.6810 - val_accuracy: 0.8000 - lr: 3.0000e-04\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2012 - accuracy: 0.9085 - val_loss: 0.9739 - val_accuracy: 0.7920 - lr: 3.0000e-04\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2017 - accuracy: 0.9066 - val_loss: 0.6511 - val_accuracy: 0.7500 - lr: 3.0000e-04\nEpoch 69/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2073 - accuracy: 0.9049 - val_loss: 0.6548 - val_accuracy: 0.7830 - lr: 3.0000e-04\nEpoch 70/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2009 - accuracy: 0.9099\nEpoch 70: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.2010 - accuracy: 0.9100 - val_loss: 0.9812 - val_accuracy: 0.7625 - lr: 3.0000e-04\nEpoch 71/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1863 - accuracy: 0.9174 - val_loss: 0.6536 - val_accuracy: 0.7955 - lr: 3.0000e-05\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1817 - accuracy: 0.9155 - val_loss: 0.5132 - val_accuracy: 0.8148 - lr: 3.0000e-05\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1836 - accuracy: 0.9188 - val_loss: 0.3433 - val_accuracy: 0.8511 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1798 - accuracy: 0.9210 - val_loss: 0.3417 - val_accuracy: 0.8477 - lr: 3.0000e-05\nEpoch 75/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.1808 - accuracy: 0.9169 - val_loss: 0.3167 - val_accuracy: 0.8557 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.1734 - accuracy: 0.9227 - val_loss: 0.2829 - val_accuracy: 0.8636 - lr: 3.0000e-05\nEpoch 77/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.1814 - accuracy: 0.9173 - val_loss: 0.2823 - val_accuracy: 0.8693 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1807 - accuracy: 0.9184 - val_loss: 0.3357 - val_accuracy: 0.8523 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1801 - accuracy: 0.9179 - val_loss: 0.3482 - val_accuracy: 0.8545 - lr: 3.0000e-05\nEpoch 80/100\n40/40 [==============================] - 4s 115ms/step - loss: 0.1772 - accuracy: 0.9213 - val_loss: 0.2314 - val_accuracy: 0.8977 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1774 - accuracy: 0.9192 - val_loss: 0.2448 - val_accuracy: 0.8920 - lr: 3.0000e-05\nEpoch 82/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.1755 - accuracy: 0.9221 - val_loss: 0.2258 - val_accuracy: 0.9057 - lr: 3.0000e-05\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1777 - accuracy: 0.9192 - val_loss: 0.2956 - val_accuracy: 0.8705 - lr: 3.0000e-05\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1780 - accuracy: 0.9157 - val_loss: 0.2459 - val_accuracy: 0.8898 - lr: 3.0000e-05\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1731 - accuracy: 0.9202 - val_loss: 0.2404 - val_accuracy: 0.8977 - lr: 3.0000e-05\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1743 - accuracy: 0.9187 - val_loss: 0.3257 - val_accuracy: 0.8580 - lr: 3.0000e-05\nEpoch 87/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1749 - accuracy: 0.9240 - val_loss: 0.2402 - val_accuracy: 0.8989 - lr: 3.0000e-05\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1757 - accuracy: 0.9202 - val_loss: 0.2408 - val_accuracy: 0.9000 - lr: 3.0000e-05\nEpoch 89/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1750 - accuracy: 0.9216 - val_loss: 0.3083 - val_accuracy: 0.8670 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.1740 - accuracy: 0.9211 - val_loss: 0.2212 - val_accuracy: 0.9034 - lr: 3.0000e-05\nEpoch 91/100\n40/40 [==============================] - 4s 104ms/step - loss: 0.1736 - accuracy: 0.9186 - val_loss: 0.2193 - val_accuracy: 0.9057 - lr: 3.0000e-05\nEpoch 92/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.1703 - accuracy: 0.9240 - val_loss: 0.2505 - val_accuracy: 0.8920 - lr: 3.0000e-05\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1747 - accuracy: 0.9213 - val_loss: 0.2213 - val_accuracy: 0.9068 - lr: 3.0000e-05\nEpoch 94/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1734 - accuracy: 0.9215 - val_loss: 0.2372 - val_accuracy: 0.9000 - lr: 3.0000e-05\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1744 - accuracy: 0.9170 - val_loss: 0.2339 - val_accuracy: 0.8989 - lr: 3.0000e-05\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1735 - accuracy: 0.9221 - val_loss: 0.2372 - val_accuracy: 0.9000 - lr: 3.0000e-05\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1688 - accuracy: 0.9263 - val_loss: 0.2256 - val_accuracy: 0.9045 - lr: 3.0000e-05\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1666 - accuracy: 0.9212 - val_loss: 0.2689 - val_accuracy: 0.8841 - lr: 3.0000e-05\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1721 - accuracy: 0.9207 - val_loss: 0.2257 - val_accuracy: 0.9068 - lr: 3.0000e-05\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1713 - accuracy: 0.9211 - val_loss: 0.2437 - val_accuracy: 0.9000 - lr: 3.0000e-05\n69/69 - 0s - loss: 0.3020 - accuracy: 0.8818 - 236ms/epoch - 3ms/step\n69/69 [==============================] - 0s 2ms/step\naccuracy = 0.8818181753158569\nStarting training for SNR: -2\nEpoch 1/100\n 1/40 [..............................] - ETA: 1:15 - loss: 3.1595 - accuracy: 0.1100","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:21:03.016622: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_11/dropout_44/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 6s 105ms/step - loss: 2.1889 - accuracy: 0.2845 - val_loss: 2.4723 - val_accuracy: 0.0886 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.4769 - accuracy: 0.4340 - val_loss: 2.6193 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2066 - accuracy: 0.5221 - val_loss: 2.8343 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0399 - accuracy: 0.5742 - val_loss: 3.3312 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9452 - accuracy: 0.6206 - val_loss: 3.9576 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.8679 - accuracy: 0.6437 - val_loss: 4.5319 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7940 - accuracy: 0.6735 - val_loss: 5.0535 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7464 - accuracy: 0.6941 - val_loss: 5.5975 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6960 - accuracy: 0.7213 - val_loss: 6.2421 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6587 - accuracy: 0.7288 - val_loss: 6.3644 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.6276 - accuracy: 0.7381 - val_loss: 6.5081 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.5905 - accuracy: 0.7544 - val_loss: 6.4533 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5608 - accuracy: 0.7626 - val_loss: 6.0382 - val_accuracy: 0.1773 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5418 - accuracy: 0.7665 - val_loss: 5.0123 - val_accuracy: 0.1784 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5150 - accuracy: 0.7879 - val_loss: 4.8723 - val_accuracy: 0.1841 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5031 - accuracy: 0.7840 - val_loss: 3.7769 - val_accuracy: 0.1989 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.4845 - accuracy: 0.7966 - val_loss: 2.3577 - val_accuracy: 0.2750 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.4687 - accuracy: 0.7984 - val_loss: 1.9782 - val_accuracy: 0.3375 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 5s 114ms/step - loss: 0.4535 - accuracy: 0.8052 - val_loss: 0.9783 - val_accuracy: 0.6011 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4492 - accuracy: 0.8018 - val_loss: 0.8807 - val_accuracy: 0.6307 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4360 - accuracy: 0.8110 - val_loss: 1.1757 - val_accuracy: 0.6682 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4229 - accuracy: 0.8117 - val_loss: 0.5393 - val_accuracy: 0.7568 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4146 - accuracy: 0.8181 - val_loss: 0.7551 - val_accuracy: 0.7216 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4080 - accuracy: 0.8201 - val_loss: 0.7224 - val_accuracy: 0.7273 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 4s 105ms/step - loss: 0.4096 - accuracy: 0.8205 - val_loss: 0.4259 - val_accuracy: 0.8011 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.3954 - accuracy: 0.8230 - val_loss: 0.3988 - val_accuracy: 0.8057 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3963 - accuracy: 0.8230 - val_loss: 0.4180 - val_accuracy: 0.8057 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3827 - accuracy: 0.8297 - val_loss: 0.5114 - val_accuracy: 0.7795 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3838 - accuracy: 0.8268 - val_loss: 1.1903 - val_accuracy: 0.7114 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3813 - accuracy: 0.8292 - val_loss: 0.4212 - val_accuracy: 0.7932 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3761 - accuracy: 0.8357 - val_loss: 0.4342 - val_accuracy: 0.7909 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 5s 115ms/step - loss: 0.3705 - accuracy: 0.8335 - val_loss: 0.3729 - val_accuracy: 0.8068 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 4s 100ms/step - loss: 0.3525 - accuracy: 0.8460 - val_loss: 0.3712 - val_accuracy: 0.8205 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3643 - accuracy: 0.8336 - val_loss: 0.3923 - val_accuracy: 0.8080 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3442 - accuracy: 0.8457 - val_loss: 0.4784 - val_accuracy: 0.7875 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3459 - accuracy: 0.8457 - val_loss: 0.4314 - val_accuracy: 0.7943 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3470 - accuracy: 0.8448 - val_loss: 0.4980 - val_accuracy: 0.7739 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3326 - accuracy: 0.8509 - val_loss: 0.4210 - val_accuracy: 0.8011 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3266 - accuracy: 0.8571 - val_loss: 0.5665 - val_accuracy: 0.7636 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3347 - accuracy: 0.8471 - val_loss: 0.4174 - val_accuracy: 0.7966 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3238 - accuracy: 0.8576 - val_loss: 0.6056 - val_accuracy: 0.7511 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3264 - accuracy: 0.8509 - val_loss: 0.4117 - val_accuracy: 0.8023 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3146 - accuracy: 0.8606 - val_loss: 0.5516 - val_accuracy: 0.7716 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3103 - accuracy: 0.8617 - val_loss: 0.4785 - val_accuracy: 0.8034 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3119 - accuracy: 0.8621 - val_loss: 0.3827 - val_accuracy: 0.8102 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3078 - accuracy: 0.8631 - val_loss: 0.4004 - val_accuracy: 0.8205 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2989 - accuracy: 0.8657 - val_loss: 0.7443 - val_accuracy: 0.7091 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3004 - accuracy: 0.8639 - val_loss: 0.4422 - val_accuracy: 0.7977 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2931 - accuracy: 0.8707 - val_loss: 0.3891 - val_accuracy: 0.8170 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2906 - accuracy: 0.8676 - val_loss: 0.3778 - val_accuracy: 0.8182 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2823 - accuracy: 0.8758 - val_loss: 0.3804 - val_accuracy: 0.8239 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2818 - accuracy: 0.8755 - val_loss: 0.3867 - val_accuracy: 0.8159 - lr: 3.0000e-04\nEpoch 53/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2803 - accuracy: 0.8714\nEpoch 53: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.2794 - accuracy: 0.8720 - val_loss: 0.3785 - val_accuracy: 0.8102 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2685 - accuracy: 0.8797 - val_loss: 0.3749 - val_accuracy: 0.8136 - lr: 3.0000e-05\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2661 - accuracy: 0.8806 - val_loss: 0.3731 - val_accuracy: 0.8273 - lr: 3.0000e-05\nEpoch 56/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.2635 - accuracy: 0.8862 - val_loss: 0.3694 - val_accuracy: 0.8193 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2602 - accuracy: 0.8842 - val_loss: 0.3898 - val_accuracy: 0.8216 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2610 - accuracy: 0.8847 - val_loss: 0.3757 - val_accuracy: 0.8216 - lr: 3.0000e-05\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2564 - accuracy: 0.8900 - val_loss: 0.3808 - val_accuracy: 0.8170 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2566 - accuracy: 0.8854 - val_loss: 0.3851 - val_accuracy: 0.8216 - lr: 3.0000e-05\nEpoch 61/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2566 - accuracy: 0.8870 - val_loss: 0.3837 - val_accuracy: 0.8227 - lr: 3.0000e-05\nEpoch 62/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2569 - accuracy: 0.8893 - val_loss: 0.3858 - val_accuracy: 0.8216 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2583 - accuracy: 0.8880 - val_loss: 0.3897 - val_accuracy: 0.8205 - lr: 3.0000e-05\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2552 - accuracy: 0.8880 - val_loss: 0.3778 - val_accuracy: 0.8227 - lr: 3.0000e-05\nEpoch 65/100\n40/40 [==============================] - 4s 107ms/step - loss: 0.2581 - accuracy: 0.8875 - val_loss: 0.3687 - val_accuracy: 0.8227 - lr: 3.0000e-05\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2613 - accuracy: 0.8843 - val_loss: 0.3846 - val_accuracy: 0.8261 - lr: 3.0000e-05\nEpoch 67/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2531 - accuracy: 0.8900 - val_loss: 0.3767 - val_accuracy: 0.8216 - lr: 3.0000e-05\nEpoch 68/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2534 - accuracy: 0.8924 - val_loss: 0.3849 - val_accuracy: 0.8182 - lr: 3.0000e-05\nEpoch 69/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2587 - accuracy: 0.8809 - val_loss: 0.3907 - val_accuracy: 0.8193 - lr: 3.0000e-05\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2576 - accuracy: 0.8878 - val_loss: 0.3751 - val_accuracy: 0.8193 - lr: 3.0000e-05\nEpoch 71/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2553 - accuracy: 0.8861 - val_loss: 0.3821 - val_accuracy: 0.8205 - lr: 3.0000e-05\nEpoch 72/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2513 - accuracy: 0.8896 - val_loss: 0.3758 - val_accuracy: 0.8216 - lr: 3.0000e-05\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2527 - accuracy: 0.8861 - val_loss: 0.3855 - val_accuracy: 0.8193 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2521 - accuracy: 0.8883 - val_loss: 0.3754 - val_accuracy: 0.8239 - lr: 3.0000e-05\nEpoch 75/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2499 - accuracy: 0.8876 - val_loss: 0.3949 - val_accuracy: 0.8148 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2508 - accuracy: 0.8920 - val_loss: 0.3816 - val_accuracy: 0.8205 - lr: 3.0000e-05\nEpoch 77/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2493 - accuracy: 0.8880 - val_loss: 0.3887 - val_accuracy: 0.8148 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2501 - accuracy: 0.8920 - val_loss: 0.3758 - val_accuracy: 0.8205 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2474 - accuracy: 0.8929 - val_loss: 0.3923 - val_accuracy: 0.8182 - lr: 3.0000e-05\nEpoch 80/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2489 - accuracy: 0.8903 - val_loss: 0.3717 - val_accuracy: 0.8227 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2414 - accuracy: 0.8922 - val_loss: 0.3854 - val_accuracy: 0.8205 - lr: 3.0000e-05\nEpoch 82/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2518 - accuracy: 0.8904 - val_loss: 0.3867 - val_accuracy: 0.8250 - lr: 3.0000e-05\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2450 - accuracy: 0.8941 - val_loss: 0.3776 - val_accuracy: 0.8227 - lr: 3.0000e-05\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2505 - accuracy: 0.8920 - val_loss: 0.3918 - val_accuracy: 0.8227 - lr: 3.0000e-05\nEpoch 85/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.8936\nEpoch 85: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 29ms/step - loss: 0.2491 - accuracy: 0.8926 - val_loss: 0.3789 - val_accuracy: 0.8205 - lr: 3.0000e-05\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2421 - accuracy: 0.8962 - val_loss: 0.3767 - val_accuracy: 0.8250 - lr: 3.0000e-06\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2441 - accuracy: 0.8931 - val_loss: 0.3776 - val_accuracy: 0.8216 - lr: 3.0000e-06\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2385 - accuracy: 0.8972 - val_loss: 0.3799 - val_accuracy: 0.8216 - lr: 3.0000e-06\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2440 - accuracy: 0.8939 - val_loss: 0.3817 - val_accuracy: 0.8205 - lr: 3.0000e-06\nEpoch 90/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2454 - accuracy: 0.8896 - val_loss: 0.3860 - val_accuracy: 0.8205 - lr: 3.0000e-06\nEpoch 91/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2415 - accuracy: 0.8951 - val_loss: 0.3838 - val_accuracy: 0.8193 - lr: 3.0000e-06\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2472 - accuracy: 0.8949 - val_loss: 0.3821 - val_accuracy: 0.8193 - lr: 3.0000e-06\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2405 - accuracy: 0.8955 - val_loss: 0.3831 - val_accuracy: 0.8193 - lr: 3.0000e-06\nEpoch 94/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2390 - accuracy: 0.8968 - val_loss: 0.3830 - val_accuracy: 0.8193 - lr: 3.0000e-06\nEpoch 95/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2425 - accuracy: 0.8944 - val_loss: 0.3826 - val_accuracy: 0.8227 - lr: 3.0000e-06\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2432 - accuracy: 0.8920 - val_loss: 0.3828 - val_accuracy: 0.8239 - lr: 3.0000e-06\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2427 - accuracy: 0.8963 - val_loss: 0.3836 - val_accuracy: 0.8250 - lr: 3.0000e-06\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2366 - accuracy: 0.8929 - val_loss: 0.3835 - val_accuracy: 0.8239 - lr: 3.0000e-06\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2393 - accuracy: 0.8960 - val_loss: 0.3844 - val_accuracy: 0.8239 - lr: 3.0000e-06\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2515 - accuracy: 0.8905 - val_loss: 0.3819 - val_accuracy: 0.8239 - lr: 3.0000e-06\n69/69 - 0s - loss: 0.4415 - accuracy: 0.7995 - 275ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.7995454668998718\nStarting training for SNR: -8\nEpoch 1/100\n 1/40 [..............................] - ETA: 40s - loss: 3.2837 - accuracy: 0.0750","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:24:26.951127: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_12/dropout_48/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 6s 128ms/step - loss: 2.6168 - accuracy: 0.1955 - val_loss: 2.5126 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.0406 - accuracy: 0.3027 - val_loss: 2.7478 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7870 - accuracy: 0.3523 - val_loss: 3.1354 - val_accuracy: 0.0693 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6572 - accuracy: 0.3841 - val_loss: 3.6231 - val_accuracy: 0.0693 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.5884 - accuracy: 0.4024 - val_loss: 4.0023 - val_accuracy: 0.0693 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5166 - accuracy: 0.4208 - val_loss: 4.3598 - val_accuracy: 0.0693 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4840 - accuracy: 0.4298 - val_loss: 4.4478 - val_accuracy: 0.0693 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4506 - accuracy: 0.4466 - val_loss: 4.4355 - val_accuracy: 0.0693 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4277 - accuracy: 0.4497 - val_loss: 4.4106 - val_accuracy: 0.0693 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4065 - accuracy: 0.4525 - val_loss: 4.4078 - val_accuracy: 0.0693 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3753 - accuracy: 0.4658 - val_loss: 4.1693 - val_accuracy: 0.0705 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3585 - accuracy: 0.4744 - val_loss: 3.9789 - val_accuracy: 0.1750 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3329 - accuracy: 0.4808 - val_loss: 3.7989 - val_accuracy: 0.1545 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.3148 - accuracy: 0.4891 - val_loss: 3.5571 - val_accuracy: 0.1784 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2997 - accuracy: 0.4908 - val_loss: 3.3409 - val_accuracy: 0.2045 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2886 - accuracy: 0.4951 - val_loss: 3.0158 - val_accuracy: 0.2261 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2661 - accuracy: 0.4999 - val_loss: 2.6598 - val_accuracy: 0.2466 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 4s 99ms/step - loss: 1.2544 - accuracy: 0.5111 - val_loss: 2.1695 - val_accuracy: 0.3011 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 4s 100ms/step - loss: 1.2374 - accuracy: 0.5230 - val_loss: 1.8193 - val_accuracy: 0.3511 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 98ms/step - loss: 1.2293 - accuracy: 0.5187 - val_loss: 1.5062 - val_accuracy: 0.3989 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 5s 115ms/step - loss: 1.2049 - accuracy: 0.5273 - val_loss: 1.3761 - val_accuracy: 0.4466 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 98ms/step - loss: 1.1929 - accuracy: 0.5372 - val_loss: 1.2985 - val_accuracy: 0.4727 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 100ms/step - loss: 1.1763 - accuracy: 0.5472 - val_loss: 1.2706 - val_accuracy: 0.4795 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 95ms/step - loss: 1.1616 - accuracy: 0.5473 - val_loss: 1.2627 - val_accuracy: 0.5045 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.1623 - accuracy: 0.5506 - val_loss: 1.2682 - val_accuracy: 0.4909 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 4s 111ms/step - loss: 1.1432 - accuracy: 0.5556 - val_loss: 1.1803 - val_accuracy: 0.5284 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.1357 - accuracy: 0.5544 - val_loss: 1.1840 - val_accuracy: 0.5182 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.1236 - accuracy: 0.5600 - val_loss: 1.2163 - val_accuracy: 0.5045 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1186 - accuracy: 0.5598 - val_loss: 1.1908 - val_accuracy: 0.5250 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1129 - accuracy: 0.5672 - val_loss: 1.2741 - val_accuracy: 0.5034 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 4s 101ms/step - loss: 1.1007 - accuracy: 0.5699 - val_loss: 1.1680 - val_accuracy: 0.5273 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.0979 - accuracy: 0.5792 - val_loss: 1.2027 - val_accuracy: 0.5239 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 4s 97ms/step - loss: 1.0788 - accuracy: 0.5816 - val_loss: 1.1542 - val_accuracy: 0.5239 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.0620 - accuracy: 0.5918 - val_loss: 1.1552 - val_accuracy: 0.5386 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0587 - accuracy: 0.5938 - val_loss: 1.1764 - val_accuracy: 0.5148 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0337 - accuracy: 0.6067 - val_loss: 1.1570 - val_accuracy: 0.5273 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0456 - accuracy: 0.5989 - val_loss: 1.1843 - val_accuracy: 0.5284 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0308 - accuracy: 0.6011 - val_loss: 1.1663 - val_accuracy: 0.5250 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.0097 - accuracy: 0.6159 - val_loss: 1.1712 - val_accuracy: 0.5136 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0085 - accuracy: 0.6159 - val_loss: 1.1930 - val_accuracy: 0.5114 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9961 - accuracy: 0.6130 - val_loss: 1.1601 - val_accuracy: 0.5284 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9916 - accuracy: 0.6229 - val_loss: 1.2482 - val_accuracy: 0.4977 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9696 - accuracy: 0.6359 - val_loss: 1.1710 - val_accuracy: 0.5193 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9683 - accuracy: 0.6290 - val_loss: 1.3602 - val_accuracy: 0.4955 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.9595 - accuracy: 0.6279 - val_loss: 1.4793 - val_accuracy: 0.4659 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9371 - accuracy: 0.6495 - val_loss: 1.2802 - val_accuracy: 0.4932 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.9296 - accuracy: 0.6437 - val_loss: 1.2070 - val_accuracy: 0.5102 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.9177 - accuracy: 0.6477 - val_loss: 1.2642 - val_accuracy: 0.4977 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9147 - accuracy: 0.6573 - val_loss: 1.2299 - val_accuracy: 0.5227 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.9043 - accuracy: 0.6601 - val_loss: 1.2647 - val_accuracy: 0.4966 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.8825 - accuracy: 0.6657 - val_loss: 1.3349 - val_accuracy: 0.4886 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.8736 - accuracy: 0.6737 - val_loss: 1.2338 - val_accuracy: 0.5102 - lr: 3.0000e-04\nEpoch 53/100\n39/40 [============================>.] - ETA: 0s - loss: 0.8546 - accuracy: 0.6771\nEpoch 53: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 31ms/step - loss: 0.8558 - accuracy: 0.6766 - val_loss: 1.2354 - val_accuracy: 0.5159 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.8411 - accuracy: 0.6833 - val_loss: 1.2237 - val_accuracy: 0.5227 - lr: 3.0000e-05\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8294 - accuracy: 0.6944 - val_loss: 1.2097 - val_accuracy: 0.5216 - lr: 3.0000e-05\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8317 - accuracy: 0.6923 - val_loss: 1.2078 - val_accuracy: 0.5148 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8302 - accuracy: 0.6928 - val_loss: 1.2118 - val_accuracy: 0.5216 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8232 - accuracy: 0.6915 - val_loss: 1.2120 - val_accuracy: 0.5261 - lr: 3.0000e-05\nEpoch 59/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.8273 - accuracy: 0.6915 - val_loss: 1.2093 - val_accuracy: 0.5284 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8311 - accuracy: 0.6895 - val_loss: 1.2124 - val_accuracy: 0.5261 - lr: 3.0000e-05\nEpoch 61/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8210 - accuracy: 0.6960 - val_loss: 1.2120 - val_accuracy: 0.5284 - lr: 3.0000e-05\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8089 - accuracy: 0.7087 - val_loss: 1.2129 - val_accuracy: 0.5295 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8234 - accuracy: 0.6966 - val_loss: 1.2159 - val_accuracy: 0.5216 - lr: 3.0000e-05\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8190 - accuracy: 0.6926 - val_loss: 1.2151 - val_accuracy: 0.5295 - lr: 3.0000e-05\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8157 - accuracy: 0.6949 - val_loss: 1.2148 - val_accuracy: 0.5250 - lr: 3.0000e-05\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8123 - accuracy: 0.7049 - val_loss: 1.2176 - val_accuracy: 0.5250 - lr: 3.0000e-05\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8121 - accuracy: 0.7003 - val_loss: 1.2150 - val_accuracy: 0.5227 - lr: 3.0000e-05\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8035 - accuracy: 0.7043 - val_loss: 1.2191 - val_accuracy: 0.5193 - lr: 3.0000e-05\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8051 - accuracy: 0.6997 - val_loss: 1.2169 - val_accuracy: 0.5216 - lr: 3.0000e-05\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8068 - accuracy: 0.6952 - val_loss: 1.2207 - val_accuracy: 0.5170 - lr: 3.0000e-05\nEpoch 71/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.8193 - accuracy: 0.6958 - val_loss: 1.2184 - val_accuracy: 0.5250 - lr: 3.0000e-05\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7942 - accuracy: 0.7072 - val_loss: 1.2258 - val_accuracy: 0.5000 - lr: 3.0000e-05\nEpoch 73/100\n39/40 [============================>.] - ETA: 0s - loss: 0.8095 - accuracy: 0.7056\nEpoch 73: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 30ms/step - loss: 0.8099 - accuracy: 0.7053 - val_loss: 1.2225 - val_accuracy: 0.5193 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7959 - accuracy: 0.7085 - val_loss: 1.2218 - val_accuracy: 0.5216 - lr: 3.0000e-06\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7962 - accuracy: 0.7048 - val_loss: 1.2229 - val_accuracy: 0.5227 - lr: 3.0000e-06\nEpoch 76/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7970 - accuracy: 0.7028 - val_loss: 1.2234 - val_accuracy: 0.5250 - lr: 3.0000e-06\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7966 - accuracy: 0.7045 - val_loss: 1.2236 - val_accuracy: 0.5239 - lr: 3.0000e-06\nEpoch 78/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.7943 - accuracy: 0.7077 - val_loss: 1.2240 - val_accuracy: 0.5250 - lr: 3.0000e-06\nEpoch 79/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.8002 - accuracy: 0.7005 - val_loss: 1.2237 - val_accuracy: 0.5261 - lr: 3.0000e-06\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7871 - accuracy: 0.7111 - val_loss: 1.2231 - val_accuracy: 0.5239 - lr: 3.0000e-06\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7942 - accuracy: 0.7101 - val_loss: 1.2237 - val_accuracy: 0.5239 - lr: 3.0000e-06\nEpoch 82/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7991 - accuracy: 0.6987 - val_loss: 1.2247 - val_accuracy: 0.5250 - lr: 3.0000e-06\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7832 - accuracy: 0.7049 - val_loss: 1.2246 - val_accuracy: 0.5250 - lr: 3.0000e-06\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7980 - accuracy: 0.7045 - val_loss: 1.2245 - val_accuracy: 0.5216 - lr: 3.0000e-06\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7950 - accuracy: 0.7086 - val_loss: 1.2241 - val_accuracy: 0.5216 - lr: 3.0000e-06\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7957 - accuracy: 0.7068 - val_loss: 1.2240 - val_accuracy: 0.5239 - lr: 3.0000e-06\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7970 - accuracy: 0.7048 - val_loss: 1.2238 - val_accuracy: 0.5250 - lr: 3.0000e-06\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7927 - accuracy: 0.7080 - val_loss: 1.2236 - val_accuracy: 0.5239 - lr: 3.0000e-06\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7852 - accuracy: 0.7096 - val_loss: 1.2239 - val_accuracy: 0.5227 - lr: 3.0000e-06\nEpoch 90/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.8031 - accuracy: 0.6989 - val_loss: 1.2238 - val_accuracy: 0.5227 - lr: 3.0000e-06\nEpoch 91/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7897 - accuracy: 0.7029 - val_loss: 1.2244 - val_accuracy: 0.5227 - lr: 3.0000e-06\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7884 - accuracy: 0.7078 - val_loss: 1.2249 - val_accuracy: 0.5216 - lr: 3.0000e-06\nEpoch 93/100\n39/40 [============================>.] - ETA: 0s - loss: 0.7851 - accuracy: 0.7074\nEpoch 93: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-07.\n40/40 [==============================] - 1s 30ms/step - loss: 0.7849 - accuracy: 0.7081 - val_loss: 1.2245 - val_accuracy: 0.5193 - lr: 3.0000e-06\nEpoch 94/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7976 - accuracy: 0.6965 - val_loss: 1.2250 - val_accuracy: 0.5182 - lr: 3.0000e-07\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7998 - accuracy: 0.7058 - val_loss: 1.2253 - val_accuracy: 0.5193 - lr: 3.0000e-07\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7910 - accuracy: 0.7117 - val_loss: 1.2252 - val_accuracy: 0.5205 - lr: 3.0000e-07\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7872 - accuracy: 0.7106 - val_loss: 1.2249 - val_accuracy: 0.5205 - lr: 3.0000e-07\nEpoch 98/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7860 - accuracy: 0.7051 - val_loss: 1.2251 - val_accuracy: 0.5205 - lr: 3.0000e-07\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7935 - accuracy: 0.7052 - val_loss: 1.2248 - val_accuracy: 0.5216 - lr: 3.0000e-07\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7847 - accuracy: 0.7124 - val_loss: 1.2248 - val_accuracy: 0.5227 - lr: 3.0000e-07\n69/69 - 0s - loss: 1.2398 - accuracy: 0.5286 - 230ms/epoch - 3ms/step\n69/69 [==============================] - 0s 2ms/step\naccuracy = 0.5286363363265991\nStarting training for SNR: -12\nEpoch 1/100\n 1/40 [..............................] - ETA: 41s - loss: 3.2306 - accuracy: 0.1000","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:27:01.337116: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_13/dropout_52/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 6s 114ms/step - loss: 2.9850 - accuracy: 0.1193 - val_loss: 2.4827 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.5654 - accuracy: 0.1972 - val_loss: 2.6057 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.3573 - accuracy: 0.2148 - val_loss: 2.6832 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2438 - accuracy: 0.2359 - val_loss: 2.7134 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1496 - accuracy: 0.2500 - val_loss: 2.6948 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0939 - accuracy: 0.2534 - val_loss: 2.6314 - val_accuracy: 0.0761 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0303 - accuracy: 0.2726 - val_loss: 2.5834 - val_accuracy: 0.0750 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0001 - accuracy: 0.2710 - val_loss: 2.5605 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9596 - accuracy: 0.2846 - val_loss: 2.5594 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9475 - accuracy: 0.2888 - val_loss: 2.5541 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9190 - accuracy: 0.2982 - val_loss: 2.5313 - val_accuracy: 0.0955 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9169 - accuracy: 0.3006 - val_loss: 2.6513 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8898 - accuracy: 0.3087 - val_loss: 3.4930 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8921 - accuracy: 0.3071 - val_loss: 3.5072 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8837 - accuracy: 0.3110 - val_loss: 3.0621 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8689 - accuracy: 0.3106 - val_loss: 3.1531 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 5s 117ms/step - loss: 1.8526 - accuracy: 0.3208 - val_loss: 2.4584 - val_accuracy: 0.1443 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 4s 99ms/step - loss: 1.8483 - accuracy: 0.3258 - val_loss: 2.0558 - val_accuracy: 0.2625 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 4s 106ms/step - loss: 1.8464 - accuracy: 0.3207 - val_loss: 1.9626 - val_accuracy: 0.2886 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.8308 - accuracy: 0.3356 - val_loss: 1.9757 - val_accuracy: 0.2818 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 96ms/step - loss: 1.8310 - accuracy: 0.3282 - val_loss: 1.9240 - val_accuracy: 0.2955 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 97ms/step - loss: 1.8166 - accuracy: 0.3364 - val_loss: 1.9128 - val_accuracy: 0.3011 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.8044 - accuracy: 0.3433 - val_loss: 1.9229 - val_accuracy: 0.2920 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8044 - accuracy: 0.3436 - val_loss: 1.9583 - val_accuracy: 0.2841 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.7898 - accuracy: 0.3479 - val_loss: 1.9573 - val_accuracy: 0.2830 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7837 - accuracy: 0.3577 - val_loss: 1.9341 - val_accuracy: 0.2898 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7808 - accuracy: 0.3624 - val_loss: 1.9265 - val_accuracy: 0.2920 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7683 - accuracy: 0.3610 - val_loss: 1.9603 - val_accuracy: 0.2932 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.7547 - accuracy: 0.3669 - val_loss: 2.0243 - val_accuracy: 0.2659 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7565 - accuracy: 0.3653 - val_loss: 2.0112 - val_accuracy: 0.2705 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7404 - accuracy: 0.3710 - val_loss: 1.9247 - val_accuracy: 0.2886 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7390 - accuracy: 0.3741 - val_loss: 1.9355 - val_accuracy: 0.2886 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7314 - accuracy: 0.3747 - val_loss: 1.9477 - val_accuracy: 0.2830 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7205 - accuracy: 0.3696 - val_loss: 1.9485 - val_accuracy: 0.2864 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7184 - accuracy: 0.3847 - val_loss: 1.9733 - val_accuracy: 0.2989 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6967 - accuracy: 0.3965 - val_loss: 1.9333 - val_accuracy: 0.2830 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6865 - accuracy: 0.3977 - val_loss: 2.0540 - val_accuracy: 0.2557 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6705 - accuracy: 0.4064 - val_loss: 2.0615 - val_accuracy: 0.2648 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.6734 - accuracy: 0.4020 - val_loss: 2.1166 - val_accuracy: 0.2614 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.6712 - accuracy: 0.4027 - val_loss: 1.9435 - val_accuracy: 0.2864 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.6520 - accuracy: 0.4114 - val_loss: 1.9682 - val_accuracy: 0.2841 - lr: 3.0000e-04\nEpoch 42/100\n39/40 [============================>.] - ETA: 0s - loss: 1.6465 - accuracy: 0.4132\nEpoch 42: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 31ms/step - loss: 1.6465 - accuracy: 0.4133 - val_loss: 1.9962 - val_accuracy: 0.2807 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6168 - accuracy: 0.4199 - val_loss: 1.9696 - val_accuracy: 0.2784 - lr: 3.0000e-05\nEpoch 44/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.6168 - accuracy: 0.4230 - val_loss: 1.9565 - val_accuracy: 0.2841 - lr: 3.0000e-05\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5989 - accuracy: 0.4350 - val_loss: 1.9495 - val_accuracy: 0.2830 - lr: 3.0000e-05\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6064 - accuracy: 0.4314 - val_loss: 1.9500 - val_accuracy: 0.2761 - lr: 3.0000e-05\nEpoch 47/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6176 - accuracy: 0.4293 - val_loss: 1.9513 - val_accuracy: 0.2807 - lr: 3.0000e-05\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6049 - accuracy: 0.4283 - val_loss: 1.9514 - val_accuracy: 0.2750 - lr: 3.0000e-05\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5957 - accuracy: 0.4336 - val_loss: 1.9519 - val_accuracy: 0.2795 - lr: 3.0000e-05\nEpoch 50/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6036 - accuracy: 0.4293 - val_loss: 1.9548 - val_accuracy: 0.2875 - lr: 3.0000e-05\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6014 - accuracy: 0.4332 - val_loss: 1.9534 - val_accuracy: 0.2830 - lr: 3.0000e-05\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5948 - accuracy: 0.4378 - val_loss: 1.9537 - val_accuracy: 0.2784 - lr: 3.0000e-05\nEpoch 53/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5877 - accuracy: 0.4407 - val_loss: 1.9552 - val_accuracy: 0.2807 - lr: 3.0000e-05\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5925 - accuracy: 0.4355 - val_loss: 1.9566 - val_accuracy: 0.2773 - lr: 3.0000e-05\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5891 - accuracy: 0.4495 - val_loss: 1.9566 - val_accuracy: 0.2784 - lr: 3.0000e-05\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5911 - accuracy: 0.4335 - val_loss: 1.9586 - val_accuracy: 0.2750 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5768 - accuracy: 0.4466 - val_loss: 1.9587 - val_accuracy: 0.2795 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5730 - accuracy: 0.4471 - val_loss: 1.9597 - val_accuracy: 0.2830 - lr: 3.0000e-05\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5729 - accuracy: 0.4527 - val_loss: 1.9690 - val_accuracy: 0.2807 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5837 - accuracy: 0.4431 - val_loss: 1.9679 - val_accuracy: 0.2784 - lr: 3.0000e-05\nEpoch 61/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5759 - accuracy: 0.4452 - val_loss: 1.9659 - val_accuracy: 0.2830 - lr: 3.0000e-05\nEpoch 62/100\n39/40 [============================>.] - ETA: 0s - loss: 1.5783 - accuracy: 0.4362\nEpoch 62: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 31ms/step - loss: 1.5785 - accuracy: 0.4362 - val_loss: 1.9667 - val_accuracy: 0.2807 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5683 - accuracy: 0.4490 - val_loss: 1.9668 - val_accuracy: 0.2807 - lr: 3.0000e-06\nEpoch 64/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.5663 - accuracy: 0.4496 - val_loss: 1.9669 - val_accuracy: 0.2807 - lr: 3.0000e-06\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5736 - accuracy: 0.4448 - val_loss: 1.9673 - val_accuracy: 0.2818 - lr: 3.0000e-06\nEpoch 66/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5708 - accuracy: 0.4395 - val_loss: 1.9674 - val_accuracy: 0.2818 - lr: 3.0000e-06\nEpoch 67/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5739 - accuracy: 0.4436 - val_loss: 1.9668 - val_accuracy: 0.2830 - lr: 3.0000e-06\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5554 - accuracy: 0.4540 - val_loss: 1.9667 - val_accuracy: 0.2830 - lr: 3.0000e-06\nEpoch 69/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.5774 - accuracy: 0.4400 - val_loss: 1.9661 - val_accuracy: 0.2830 - lr: 3.0000e-06\nEpoch 70/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.5534 - accuracy: 0.4566 - val_loss: 1.9665 - val_accuracy: 0.2830 - lr: 3.0000e-06\nEpoch 71/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5674 - accuracy: 0.4467 - val_loss: 1.9663 - val_accuracy: 0.2841 - lr: 3.0000e-06\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5707 - accuracy: 0.4497 - val_loss: 1.9665 - val_accuracy: 0.2841 - lr: 3.0000e-06\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5559 - accuracy: 0.4544 - val_loss: 1.9663 - val_accuracy: 0.2818 - lr: 3.0000e-06\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5677 - accuracy: 0.4400 - val_loss: 1.9667 - val_accuracy: 0.2830 - lr: 3.0000e-06\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5679 - accuracy: 0.4490 - val_loss: 1.9668 - val_accuracy: 0.2830 - lr: 3.0000e-06\nEpoch 76/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.5607 - accuracy: 0.4529 - val_loss: 1.9666 - val_accuracy: 0.2841 - lr: 3.0000e-06\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5609 - accuracy: 0.4525 - val_loss: 1.9656 - val_accuracy: 0.2864 - lr: 3.0000e-06\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5640 - accuracy: 0.4519 - val_loss: 1.9658 - val_accuracy: 0.2830 - lr: 3.0000e-06\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5684 - accuracy: 0.4499 - val_loss: 1.9667 - val_accuracy: 0.2852 - lr: 3.0000e-06\nEpoch 80/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5709 - accuracy: 0.4468 - val_loss: 1.9668 - val_accuracy: 0.2830 - lr: 3.0000e-06\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5641 - accuracy: 0.4475 - val_loss: 1.9664 - val_accuracy: 0.2852 - lr: 3.0000e-06\nEpoch 82/100\n39/40 [============================>.] - ETA: 0s - loss: 1.5646 - accuracy: 0.4462\nEpoch 82: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-07.\n40/40 [==============================] - 1s 30ms/step - loss: 1.5640 - accuracy: 0.4471 - val_loss: 1.9662 - val_accuracy: 0.2841 - lr: 3.0000e-06\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5681 - accuracy: 0.4491 - val_loss: 1.9672 - val_accuracy: 0.2830 - lr: 3.0000e-07\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5675 - accuracy: 0.4477 - val_loss: 1.9675 - val_accuracy: 0.2818 - lr: 3.0000e-07\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5622 - accuracy: 0.4482 - val_loss: 1.9675 - val_accuracy: 0.2818 - lr: 3.0000e-07\nEpoch 86/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5656 - accuracy: 0.4545 - val_loss: 1.9676 - val_accuracy: 0.2818 - lr: 3.0000e-07\nEpoch 87/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.5602 - accuracy: 0.4494 - val_loss: 1.9674 - val_accuracy: 0.2830 - lr: 3.0000e-07\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5614 - accuracy: 0.4537 - val_loss: 1.9675 - val_accuracy: 0.2864 - lr: 3.0000e-07\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5634 - accuracy: 0.4547 - val_loss: 1.9675 - val_accuracy: 0.2807 - lr: 3.0000e-07\nEpoch 90/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.5624 - accuracy: 0.4476 - val_loss: 1.9678 - val_accuracy: 0.2807 - lr: 3.0000e-07\nEpoch 91/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5569 - accuracy: 0.4529 - val_loss: 1.9678 - val_accuracy: 0.2807 - lr: 3.0000e-07\nEpoch 92/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5684 - accuracy: 0.4486 - val_loss: 1.9676 - val_accuracy: 0.2807 - lr: 3.0000e-07\nEpoch 93/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5661 - accuracy: 0.4504 - val_loss: 1.9679 - val_accuracy: 0.2807 - lr: 3.0000e-07\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5598 - accuracy: 0.4495 - val_loss: 1.9678 - val_accuracy: 0.2818 - lr: 3.0000e-07\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5591 - accuracy: 0.4542 - val_loss: 1.9676 - val_accuracy: 0.2830 - lr: 3.0000e-07\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5700 - accuracy: 0.4439 - val_loss: 1.9676 - val_accuracy: 0.2830 - lr: 3.0000e-07\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5583 - accuracy: 0.4480 - val_loss: 1.9677 - val_accuracy: 0.2830 - lr: 3.0000e-07\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5742 - accuracy: 0.4456 - val_loss: 1.9677 - val_accuracy: 0.2830 - lr: 3.0000e-07\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5630 - accuracy: 0.4523 - val_loss: 1.9678 - val_accuracy: 0.2830 - lr: 3.0000e-07\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5717 - accuracy: 0.4499 - val_loss: 1.9678 - val_accuracy: 0.2830 - lr: 3.0000e-07\n69/69 - 0s - loss: 2.0027 - accuracy: 0.2691 - 230ms/epoch - 3ms/step\n69/69 [==============================] - 0s 2ms/step\naccuracy = 0.2690909206867218\nStarting training for SNR: 0\nEpoch 1/100\n 1/40 [..............................] - ETA: 40s - loss: 3.1269 - accuracy: 0.0900","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:29:21.451161: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_14/dropout_56/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 6s 124ms/step - loss: 2.3193 - accuracy: 0.2726 - val_loss: 2.5686 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5038 - accuracy: 0.4359 - val_loss: 2.9843 - val_accuracy: 0.0807 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.2314 - accuracy: 0.5059 - val_loss: 3.4870 - val_accuracy: 0.0807 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0753 - accuracy: 0.5587 - val_loss: 4.0360 - val_accuracy: 0.0807 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.9657 - accuracy: 0.5955 - val_loss: 4.6290 - val_accuracy: 0.0807 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8825 - accuracy: 0.6422 - val_loss: 5.3237 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8112 - accuracy: 0.6645 - val_loss: 6.1197 - val_accuracy: 0.0898 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7509 - accuracy: 0.6903 - val_loss: 6.7298 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6965 - accuracy: 0.7130 - val_loss: 7.3124 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6640 - accuracy: 0.7280 - val_loss: 7.7313 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6059 - accuracy: 0.7557 - val_loss: 7.8698 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5817 - accuracy: 0.7598 - val_loss: 7.7004 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5531 - accuracy: 0.7689 - val_loss: 7.2965 - val_accuracy: 0.1000 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5215 - accuracy: 0.7831 - val_loss: 6.5444 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4891 - accuracy: 0.7937 - val_loss: 5.2453 - val_accuracy: 0.1250 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4658 - accuracy: 0.7986 - val_loss: 3.8825 - val_accuracy: 0.2591 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4417 - accuracy: 0.8109 - val_loss: 3.3267 - val_accuracy: 0.3750 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4291 - accuracy: 0.8112 - val_loss: 2.7986 - val_accuracy: 0.3580 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.4260 - accuracy: 0.8107 - val_loss: 1.8201 - val_accuracy: 0.4159 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4032 - accuracy: 0.8251 - val_loss: 1.1548 - val_accuracy: 0.5852 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.3873 - accuracy: 0.8298 - val_loss: 0.9734 - val_accuracy: 0.6034 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 5s 119ms/step - loss: 0.3816 - accuracy: 0.8279 - val_loss: 0.8999 - val_accuracy: 0.6511 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.3861 - accuracy: 0.8313 - val_loss: 0.5943 - val_accuracy: 0.7148 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.3690 - accuracy: 0.8361 - val_loss: 0.5721 - val_accuracy: 0.7466 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 1s 33ms/step - loss: 0.3628 - accuracy: 0.8415 - val_loss: 0.7881 - val_accuracy: 0.6898 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.3521 - accuracy: 0.8452 - val_loss: 0.5009 - val_accuracy: 0.7705 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3541 - accuracy: 0.8410 - val_loss: 0.6872 - val_accuracy: 0.7136 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3517 - accuracy: 0.8386 - val_loss: 0.7585 - val_accuracy: 0.7114 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3434 - accuracy: 0.8456 - val_loss: 0.5548 - val_accuracy: 0.7580 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 5s 118ms/step - loss: 0.3408 - accuracy: 0.8465 - val_loss: 0.4349 - val_accuracy: 0.8011 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.3297 - accuracy: 0.8538 - val_loss: 0.4098 - val_accuracy: 0.7989 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3340 - accuracy: 0.8490 - val_loss: 0.4727 - val_accuracy: 0.7773 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3311 - accuracy: 0.8513 - val_loss: 0.4139 - val_accuracy: 0.7955 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3183 - accuracy: 0.8602 - val_loss: 0.4489 - val_accuracy: 0.7875 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3189 - accuracy: 0.8554 - val_loss: 0.5903 - val_accuracy: 0.7443 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 4s 100ms/step - loss: 0.3204 - accuracy: 0.8520 - val_loss: 0.4025 - val_accuracy: 0.8136 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.3156 - accuracy: 0.8578 - val_loss: 0.3745 - val_accuracy: 0.8227 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 4s 107ms/step - loss: 0.3042 - accuracy: 0.8641 - val_loss: 0.3399 - val_accuracy: 0.8216 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2984 - accuracy: 0.8625 - val_loss: 0.4076 - val_accuracy: 0.7966 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2992 - accuracy: 0.8729 - val_loss: 0.5027 - val_accuracy: 0.7693 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2958 - accuracy: 0.8659 - val_loss: 0.5477 - val_accuracy: 0.7648 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2930 - accuracy: 0.8689 - val_loss: 0.3911 - val_accuracy: 0.8148 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2931 - accuracy: 0.8692 - val_loss: 1.0768 - val_accuracy: 0.7239 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2827 - accuracy: 0.8747 - val_loss: 1.4420 - val_accuracy: 0.6966 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2853 - accuracy: 0.8665 - val_loss: 0.5175 - val_accuracy: 0.7841 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2756 - accuracy: 0.8780 - val_loss: 0.7102 - val_accuracy: 0.7420 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2785 - accuracy: 0.8788 - val_loss: 0.3447 - val_accuracy: 0.8386 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2777 - accuracy: 0.8790 - val_loss: 0.4710 - val_accuracy: 0.7841 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2739 - accuracy: 0.8779 - val_loss: 0.7388 - val_accuracy: 0.7352 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2725 - accuracy: 0.8773 - val_loss: 0.3790 - val_accuracy: 0.8466 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 5s 117ms/step - loss: 0.2668 - accuracy: 0.8808 - val_loss: 0.3304 - val_accuracy: 0.8375 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2579 - accuracy: 0.8869 - val_loss: 0.3765 - val_accuracy: 0.8136 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2588 - accuracy: 0.8847 - val_loss: 0.3605 - val_accuracy: 0.8341 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2564 - accuracy: 0.8856 - val_loss: 0.3566 - val_accuracy: 0.8216 - lr: 3.0000e-04\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2559 - accuracy: 0.8861 - val_loss: 0.3613 - val_accuracy: 0.8261 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2634 - accuracy: 0.8823 - val_loss: 0.3713 - val_accuracy: 0.8239 - lr: 3.0000e-04\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2496 - accuracy: 0.8900 - val_loss: 0.3999 - val_accuracy: 0.8148 - lr: 3.0000e-04\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2479 - accuracy: 0.8889 - val_loss: 0.8452 - val_accuracy: 0.7477 - lr: 3.0000e-04\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2436 - accuracy: 0.8919 - val_loss: 0.3458 - val_accuracy: 0.8318 - lr: 3.0000e-04\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2432 - accuracy: 0.8912 - val_loss: 0.6009 - val_accuracy: 0.7591 - lr: 3.0000e-04\nEpoch 61/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2358 - accuracy: 0.8952 - val_loss: 0.9867 - val_accuracy: 0.7591 - lr: 3.0000e-04\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2326 - accuracy: 0.8961 - val_loss: 0.4380 - val_accuracy: 0.8034 - lr: 3.0000e-04\nEpoch 63/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2370 - accuracy: 0.8943 - val_loss: 0.4053 - val_accuracy: 0.8216 - lr: 3.0000e-04\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2345 - accuracy: 0.8941 - val_loss: 0.3396 - val_accuracy: 0.8398 - lr: 3.0000e-04\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2252 - accuracy: 0.8973 - val_loss: 0.3464 - val_accuracy: 0.8432 - lr: 3.0000e-04\nEpoch 66/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2240 - accuracy: 0.9021 - val_loss: 0.3522 - val_accuracy: 0.8386 - lr: 3.0000e-04\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2274 - accuracy: 0.9004 - val_loss: 0.3423 - val_accuracy: 0.8364 - lr: 3.0000e-04\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2147 - accuracy: 0.9044 - val_loss: 0.3454 - val_accuracy: 0.8330 - lr: 3.0000e-04\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2118 - accuracy: 0.9085 - val_loss: 0.4832 - val_accuracy: 0.7909 - lr: 3.0000e-04\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2092 - accuracy: 0.9052 - val_loss: 0.3530 - val_accuracy: 0.8420 - lr: 3.0000e-04\nEpoch 71/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9042\nEpoch 71: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.2146 - accuracy: 0.9037 - val_loss: 0.3631 - val_accuracy: 0.8284 - lr: 3.0000e-04\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1941 - accuracy: 0.9160 - val_loss: 0.3506 - val_accuracy: 0.8318 - lr: 3.0000e-05\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1954 - accuracy: 0.9136 - val_loss: 0.3370 - val_accuracy: 0.8364 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1965 - accuracy: 0.9150 - val_loss: 0.3431 - val_accuracy: 0.8352 - lr: 3.0000e-05\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1892 - accuracy: 0.9196 - val_loss: 0.3473 - val_accuracy: 0.8341 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1926 - accuracy: 0.9135 - val_loss: 0.3371 - val_accuracy: 0.8352 - lr: 3.0000e-05\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1924 - accuracy: 0.9170 - val_loss: 0.3424 - val_accuracy: 0.8341 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1880 - accuracy: 0.9160 - val_loss: 0.3377 - val_accuracy: 0.8386 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1884 - accuracy: 0.9163 - val_loss: 0.3430 - val_accuracy: 0.8352 - lr: 3.0000e-05\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1916 - accuracy: 0.9186 - val_loss: 0.3380 - val_accuracy: 0.8352 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1899 - accuracy: 0.9173 - val_loss: 0.3387 - val_accuracy: 0.8375 - lr: 3.0000e-05\nEpoch 82/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1864 - accuracy: 0.9199 - val_loss: 0.3362 - val_accuracy: 0.8375 - lr: 3.0000e-05\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1903 - accuracy: 0.9170 - val_loss: 0.3334 - val_accuracy: 0.8341 - lr: 3.0000e-05\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1889 - accuracy: 0.9160 - val_loss: 0.3352 - val_accuracy: 0.8330 - lr: 3.0000e-05\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1898 - accuracy: 0.9199 - val_loss: 0.3454 - val_accuracy: 0.8307 - lr: 3.0000e-05\nEpoch 86/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1893 - accuracy: 0.9203 - val_loss: 0.3402 - val_accuracy: 0.8341 - lr: 3.0000e-05\nEpoch 87/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1820 - accuracy: 0.9216 - val_loss: 0.3397 - val_accuracy: 0.8375 - lr: 3.0000e-05\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1888 - accuracy: 0.9177 - val_loss: 0.3407 - val_accuracy: 0.8420 - lr: 3.0000e-05\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1889 - accuracy: 0.9173 - val_loss: 0.3425 - val_accuracy: 0.8432 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1850 - accuracy: 0.9183 - val_loss: 0.3458 - val_accuracy: 0.8352 - lr: 3.0000e-05\nEpoch 91/100\n39/40 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.9210\nEpoch 91: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 30ms/step - loss: 0.1827 - accuracy: 0.9213 - val_loss: 0.3437 - val_accuracy: 0.8364 - lr: 3.0000e-05\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1881 - accuracy: 0.9176 - val_loss: 0.3415 - val_accuracy: 0.8364 - lr: 3.0000e-06\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1802 - accuracy: 0.9217 - val_loss: 0.3407 - val_accuracy: 0.8364 - lr: 3.0000e-06\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1801 - accuracy: 0.9246 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 3.0000e-06\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1824 - accuracy: 0.9192 - val_loss: 0.3407 - val_accuracy: 0.8398 - lr: 3.0000e-06\nEpoch 96/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.1845 - accuracy: 0.9165 - val_loss: 0.3405 - val_accuracy: 0.8409 - lr: 3.0000e-06\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1833 - accuracy: 0.9197 - val_loss: 0.3414 - val_accuracy: 0.8398 - lr: 3.0000e-06\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.1748 - accuracy: 0.9254 - val_loss: 0.3408 - val_accuracy: 0.8386 - lr: 3.0000e-06\nEpoch 99/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1840 - accuracy: 0.9220 - val_loss: 0.3411 - val_accuracy: 0.8386 - lr: 3.0000e-06\nEpoch 100/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.1780 - accuracy: 0.9237 - val_loss: 0.3409 - val_accuracy: 0.8409 - lr: 3.0000e-06\n69/69 - 0s - loss: 0.3709 - accuracy: 0.8418 - 276ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.8418181538581848\nStarting training for SNR: -16\nEpoch 1/100\n 1/40 [..............................] - ETA: 43s - loss: 3.3945 - accuracy: 0.0650","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:32:45.375522: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_15/dropout_60/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 112ms/step - loss: 3.1123 - accuracy: 0.0889 - val_loss: 2.4343 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.9627 - accuracy: 0.0977 - val_loss: 2.4661 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.8155 - accuracy: 0.1098 - val_loss: 2.4714 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.7047 - accuracy: 0.1206 - val_loss: 2.5107 - val_accuracy: 0.0795 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.6182 - accuracy: 0.1247 - val_loss: 2.5328 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.5385 - accuracy: 0.1467 - val_loss: 2.5791 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.4739 - accuracy: 0.1479 - val_loss: 2.6219 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.4343 - accuracy: 0.1520 - val_loss: 2.6476 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.4055 - accuracy: 0.1563 - val_loss: 2.6452 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3762 - accuracy: 0.1672 - val_loss: 2.6346 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3565 - accuracy: 0.1654 - val_loss: 2.6190 - val_accuracy: 0.0977 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3261 - accuracy: 0.1761 - val_loss: 2.6007 - val_accuracy: 0.0773 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.3254 - accuracy: 0.1737 - val_loss: 2.5961 - val_accuracy: 0.0875 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3081 - accuracy: 0.1763 - val_loss: 2.5876 - val_accuracy: 0.0818 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2971 - accuracy: 0.1755 - val_loss: 2.5670 - val_accuracy: 0.0841 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2850 - accuracy: 0.1889 - val_loss: 2.5498 - val_accuracy: 0.0830 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2681 - accuracy: 0.1878 - val_loss: 2.5112 - val_accuracy: 0.0875 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2678 - accuracy: 0.1963 - val_loss: 2.4768 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2502 - accuracy: 0.1957 - val_loss: 2.4543 - val_accuracy: 0.1102 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 95ms/step - loss: 2.2537 - accuracy: 0.2004 - val_loss: 2.4238 - val_accuracy: 0.1205 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 114ms/step - loss: 2.2361 - accuracy: 0.2058 - val_loss: 2.4051 - val_accuracy: 0.1148 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 99ms/step - loss: 2.2310 - accuracy: 0.2059 - val_loss: 2.4000 - val_accuracy: 0.1284 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2155 - accuracy: 0.2159 - val_loss: 2.4033 - val_accuracy: 0.1125 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 96ms/step - loss: 2.2171 - accuracy: 0.2149 - val_loss: 2.3734 - val_accuracy: 0.1273 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.2032 - accuracy: 0.2217 - val_loss: 2.3886 - val_accuracy: 0.1182 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1868 - accuracy: 0.2289 - val_loss: 2.3768 - val_accuracy: 0.1284 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 4s 93ms/step - loss: 2.1904 - accuracy: 0.2210 - val_loss: 2.3504 - val_accuracy: 0.1398 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1718 - accuracy: 0.2364 - val_loss: 2.3779 - val_accuracy: 0.1409 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1742 - accuracy: 0.2270 - val_loss: 2.3965 - val_accuracy: 0.1193 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1604 - accuracy: 0.2403 - val_loss: 2.3863 - val_accuracy: 0.1205 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1540 - accuracy: 0.2335 - val_loss: 2.3835 - val_accuracy: 0.1330 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1422 - accuracy: 0.2523 - val_loss: 2.3654 - val_accuracy: 0.1261 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1330 - accuracy: 0.2494 - val_loss: 2.3723 - val_accuracy: 0.1364 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.1216 - accuracy: 0.2615 - val_loss: 2.3646 - val_accuracy: 0.1341 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1158 - accuracy: 0.2578 - val_loss: 2.3821 - val_accuracy: 0.1284 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1056 - accuracy: 0.2619 - val_loss: 2.3947 - val_accuracy: 0.1250 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0947 - accuracy: 0.2710 - val_loss: 2.3632 - val_accuracy: 0.1489 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0862 - accuracy: 0.2730 - val_loss: 2.3597 - val_accuracy: 0.1489 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0813 - accuracy: 0.2678 - val_loss: 2.3678 - val_accuracy: 0.1330 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0619 - accuracy: 0.2827 - val_loss: 2.4157 - val_accuracy: 0.1239 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.0508 - accuracy: 0.2867 - val_loss: 2.3922 - val_accuracy: 0.1330 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 33ms/step - loss: 2.0478 - accuracy: 0.2922 - val_loss: 2.4138 - val_accuracy: 0.1307 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0220 - accuracy: 0.3013 - val_loss: 2.3879 - val_accuracy: 0.1364 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0190 - accuracy: 0.3062 - val_loss: 2.4058 - val_accuracy: 0.1409 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9922 - accuracy: 0.3117 - val_loss: 2.3984 - val_accuracy: 0.1341 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9943 - accuracy: 0.3122 - val_loss: 2.4440 - val_accuracy: 0.1216 - lr: 3.0000e-04\nEpoch 47/100\n39/40 [============================>.] - ETA: 0s - loss: 1.9648 - accuracy: 0.3276\nEpoch 47: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 1.9652 - accuracy: 0.3275 - val_loss: 2.4108 - val_accuracy: 0.1386 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9501 - accuracy: 0.3216 - val_loss: 2.4163 - val_accuracy: 0.1386 - lr: 3.0000e-05\nEpoch 49/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9425 - accuracy: 0.3389 - val_loss: 2.4196 - val_accuracy: 0.1375 - lr: 3.0000e-05\nEpoch 50/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9478 - accuracy: 0.3269 - val_loss: 2.4208 - val_accuracy: 0.1330 - lr: 3.0000e-05\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9344 - accuracy: 0.3351 - val_loss: 2.4194 - val_accuracy: 0.1364 - lr: 3.0000e-05\nEpoch 52/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9384 - accuracy: 0.3365 - val_loss: 2.4185 - val_accuracy: 0.1318 - lr: 3.0000e-05\nEpoch 53/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9420 - accuracy: 0.3304 - val_loss: 2.4219 - val_accuracy: 0.1341 - lr: 3.0000e-05\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9368 - accuracy: 0.3341 - val_loss: 2.4219 - val_accuracy: 0.1364 - lr: 3.0000e-05\nEpoch 55/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9247 - accuracy: 0.3389 - val_loss: 2.4222 - val_accuracy: 0.1318 - lr: 3.0000e-05\nEpoch 56/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9237 - accuracy: 0.3376 - val_loss: 2.4252 - val_accuracy: 0.1364 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9220 - accuracy: 0.3381 - val_loss: 2.4290 - val_accuracy: 0.1295 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9234 - accuracy: 0.3453 - val_loss: 2.4235 - val_accuracy: 0.1341 - lr: 3.0000e-05\nEpoch 59/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9170 - accuracy: 0.3463 - val_loss: 2.4226 - val_accuracy: 0.1341 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.9163 - accuracy: 0.3396 - val_loss: 2.4145 - val_accuracy: 0.1432 - lr: 3.0000e-05\nEpoch 61/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.9163 - accuracy: 0.3413 - val_loss: 2.4207 - val_accuracy: 0.1341 - lr: 3.0000e-05\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9140 - accuracy: 0.3485 - val_loss: 2.4216 - val_accuracy: 0.1318 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9137 - accuracy: 0.3456 - val_loss: 2.4242 - val_accuracy: 0.1318 - lr: 3.0000e-05\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9070 - accuracy: 0.3515 - val_loss: 2.4229 - val_accuracy: 0.1284 - lr: 3.0000e-05\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9061 - accuracy: 0.3449 - val_loss: 2.4208 - val_accuracy: 0.1307 - lr: 3.0000e-05\nEpoch 66/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.9048 - accuracy: 0.3504 - val_loss: 2.4208 - val_accuracy: 0.1295 - lr: 3.0000e-05\nEpoch 67/100\n39/40 [============================>.] - ETA: 0s - loss: 1.8979 - accuracy: 0.3486\nEpoch 67: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 31ms/step - loss: 1.8969 - accuracy: 0.3494 - val_loss: 2.4224 - val_accuracy: 0.1295 - lr: 3.0000e-05\nEpoch 68/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.8913 - accuracy: 0.3520 - val_loss: 2.4242 - val_accuracy: 0.1284 - lr: 3.0000e-06\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8986 - accuracy: 0.3481 - val_loss: 2.4250 - val_accuracy: 0.1273 - lr: 3.0000e-06\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9136 - accuracy: 0.3391 - val_loss: 2.4259 - val_accuracy: 0.1284 - lr: 3.0000e-06\nEpoch 71/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.8921 - accuracy: 0.3562 - val_loss: 2.4259 - val_accuracy: 0.1295 - lr: 3.0000e-06\nEpoch 72/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8857 - accuracy: 0.3551 - val_loss: 2.4262 - val_accuracy: 0.1295 - lr: 3.0000e-06\nEpoch 73/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8908 - accuracy: 0.3563 - val_loss: 2.4263 - val_accuracy: 0.1273 - lr: 3.0000e-06\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9044 - accuracy: 0.3465 - val_loss: 2.4262 - val_accuracy: 0.1284 - lr: 3.0000e-06\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8932 - accuracy: 0.3578 - val_loss: 2.4267 - val_accuracy: 0.1273 - lr: 3.0000e-06\nEpoch 76/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.8983 - accuracy: 0.3456 - val_loss: 2.4271 - val_accuracy: 0.1284 - lr: 3.0000e-06\nEpoch 77/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9009 - accuracy: 0.3508 - val_loss: 2.4274 - val_accuracy: 0.1261 - lr: 3.0000e-06\nEpoch 78/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.8970 - accuracy: 0.3508 - val_loss: 2.4274 - val_accuracy: 0.1284 - lr: 3.0000e-06\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8990 - accuracy: 0.3485 - val_loss: 2.4272 - val_accuracy: 0.1284 - lr: 3.0000e-06\nEpoch 80/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8955 - accuracy: 0.3508 - val_loss: 2.4262 - val_accuracy: 0.1273 - lr: 3.0000e-06\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9017 - accuracy: 0.3495 - val_loss: 2.4259 - val_accuracy: 0.1273 - lr: 3.0000e-06\nEpoch 82/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8873 - accuracy: 0.3521 - val_loss: 2.4266 - val_accuracy: 0.1273 - lr: 3.0000e-06\nEpoch 83/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9007 - accuracy: 0.3540 - val_loss: 2.4268 - val_accuracy: 0.1295 - lr: 3.0000e-06\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8975 - accuracy: 0.3417 - val_loss: 2.4271 - val_accuracy: 0.1295 - lr: 3.0000e-06\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8901 - accuracy: 0.3534 - val_loss: 2.4268 - val_accuracy: 0.1284 - lr: 3.0000e-06\nEpoch 86/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8943 - accuracy: 0.3505 - val_loss: 2.4274 - val_accuracy: 0.1284 - lr: 3.0000e-06\nEpoch 87/100\n39/40 [============================>.] - ETA: 0s - loss: 1.8904 - accuracy: 0.3606\nEpoch 87: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-07.\n40/40 [==============================] - 1s 30ms/step - loss: 1.8887 - accuracy: 0.3615 - val_loss: 2.4286 - val_accuracy: 0.1284 - lr: 3.0000e-06\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8943 - accuracy: 0.3490 - val_loss: 2.4286 - val_accuracy: 0.1284 - lr: 3.0000e-07\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8918 - accuracy: 0.3557 - val_loss: 2.4281 - val_accuracy: 0.1284 - lr: 3.0000e-07\nEpoch 90/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8922 - accuracy: 0.3529 - val_loss: 2.4282 - val_accuracy: 0.1284 - lr: 3.0000e-07\nEpoch 91/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8936 - accuracy: 0.3494 - val_loss: 2.4282 - val_accuracy: 0.1284 - lr: 3.0000e-07\nEpoch 92/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8848 - accuracy: 0.3549 - val_loss: 2.4281 - val_accuracy: 0.1284 - lr: 3.0000e-07\nEpoch 93/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.8833 - accuracy: 0.3580 - val_loss: 2.4282 - val_accuracy: 0.1284 - lr: 3.0000e-07\nEpoch 94/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.8926 - accuracy: 0.3451 - val_loss: 2.4283 - val_accuracy: 0.1273 - lr: 3.0000e-07\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8894 - accuracy: 0.3453 - val_loss: 2.4287 - val_accuracy: 0.1284 - lr: 3.0000e-07\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8968 - accuracy: 0.3485 - val_loss: 2.4288 - val_accuracy: 0.1273 - lr: 3.0000e-07\nEpoch 97/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.8907 - accuracy: 0.3489 - val_loss: 2.4288 - val_accuracy: 0.1273 - lr: 3.0000e-07\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8886 - accuracy: 0.3578 - val_loss: 2.4286 - val_accuracy: 0.1273 - lr: 3.0000e-07\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8959 - accuracy: 0.3453 - val_loss: 2.4286 - val_accuracy: 0.1284 - lr: 3.0000e-07\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8864 - accuracy: 0.3573 - val_loss: 2.4284 - val_accuracy: 0.1284 - lr: 3.0000e-07\n69/69 - 0s - loss: 2.4695 - accuracy: 0.1309 - 239ms/epoch - 3ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.13090908527374268\nStarting training for SNR: -10\nEpoch 1/100\n 1/40 [..............................] - ETA: 40s - loss: 3.1827 - accuracy: 0.1150","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:35:04.517300: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_16/dropout_64/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 98ms/step - loss: 2.8634 - accuracy: 0.1511 - val_loss: 2.4325 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.3146 - accuracy: 0.2314 - val_loss: 2.4558 - val_accuracy: 0.1011 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.0439 - accuracy: 0.2787 - val_loss: 2.5450 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9068 - accuracy: 0.3067 - val_loss: 2.7399 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8472 - accuracy: 0.3163 - val_loss: 2.8981 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7864 - accuracy: 0.3316 - val_loss: 3.1090 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7517 - accuracy: 0.3444 - val_loss: 3.2539 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7239 - accuracy: 0.3551 - val_loss: 3.3701 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6942 - accuracy: 0.3657 - val_loss: 3.4029 - val_accuracy: 0.0852 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6897 - accuracy: 0.3593 - val_loss: 3.4493 - val_accuracy: 0.1602 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6686 - accuracy: 0.3739 - val_loss: 3.4287 - val_accuracy: 0.1830 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6528 - accuracy: 0.3761 - val_loss: 3.7850 - val_accuracy: 0.1295 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6464 - accuracy: 0.3804 - val_loss: 3.1918 - val_accuracy: 0.1739 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6304 - accuracy: 0.3850 - val_loss: 3.1791 - val_accuracy: 0.1568 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6126 - accuracy: 0.3960 - val_loss: 2.8206 - val_accuracy: 0.1852 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.6176 - accuracy: 0.3939 - val_loss: 2.5143 - val_accuracy: 0.2477 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6037 - accuracy: 0.3961 - val_loss: 2.4875 - val_accuracy: 0.2193 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.5992 - accuracy: 0.3989 - val_loss: 2.7487 - val_accuracy: 0.1898 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 5s 118ms/step - loss: 1.5951 - accuracy: 0.3989 - val_loss: 2.2586 - val_accuracy: 0.2261 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 96ms/step - loss: 1.5780 - accuracy: 0.3984 - val_loss: 1.9155 - val_accuracy: 0.3011 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 95ms/step - loss: 1.5799 - accuracy: 0.4095 - val_loss: 1.7730 - val_accuracy: 0.3443 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 95ms/step - loss: 1.5694 - accuracy: 0.4130 - val_loss: 1.7378 - val_accuracy: 0.3716 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5637 - accuracy: 0.4138 - val_loss: 1.8830 - val_accuracy: 0.3182 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 4s 115ms/step - loss: 1.5459 - accuracy: 0.4215 - val_loss: 1.6732 - val_accuracy: 0.3568 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 4s 100ms/step - loss: 1.5458 - accuracy: 0.4188 - val_loss: 1.6664 - val_accuracy: 0.3989 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 4s 106ms/step - loss: 1.5360 - accuracy: 0.4242 - val_loss: 1.6574 - val_accuracy: 0.3977 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.5198 - accuracy: 0.4323 - val_loss: 1.6684 - val_accuracy: 0.3875 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 4s 94ms/step - loss: 1.5112 - accuracy: 0.4245 - val_loss: 1.6267 - val_accuracy: 0.4080 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 5s 116ms/step - loss: 1.5006 - accuracy: 0.4350 - val_loss: 1.6138 - val_accuracy: 0.4170 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.4907 - accuracy: 0.4390 - val_loss: 1.6391 - val_accuracy: 0.3955 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4772 - accuracy: 0.4496 - val_loss: 1.6699 - val_accuracy: 0.3852 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4707 - accuracy: 0.4499 - val_loss: 1.6217 - val_accuracy: 0.4011 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4548 - accuracy: 0.4590 - val_loss: 1.6780 - val_accuracy: 0.3898 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4633 - accuracy: 0.4509 - val_loss: 1.8262 - val_accuracy: 0.3591 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 4s 97ms/step - loss: 1.4398 - accuracy: 0.4639 - val_loss: 1.6121 - val_accuracy: 0.3989 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.4311 - accuracy: 0.4617 - val_loss: 1.8310 - val_accuracy: 0.3386 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 4s 95ms/step - loss: 1.4244 - accuracy: 0.4725 - val_loss: 1.6038 - val_accuracy: 0.4148 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.4138 - accuracy: 0.4751 - val_loss: 1.6246 - val_accuracy: 0.4068 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4036 - accuracy: 0.4797 - val_loss: 1.7058 - val_accuracy: 0.3716 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 4s 106ms/step - loss: 1.3869 - accuracy: 0.4851 - val_loss: 1.5964 - val_accuracy: 0.4102 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.3854 - accuracy: 0.4835 - val_loss: 1.6118 - val_accuracy: 0.3966 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3708 - accuracy: 0.4999 - val_loss: 1.6687 - val_accuracy: 0.3841 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3700 - accuracy: 0.4874 - val_loss: 1.6650 - val_accuracy: 0.3830 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3595 - accuracy: 0.4975 - val_loss: 1.6502 - val_accuracy: 0.3977 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3421 - accuracy: 0.5052 - val_loss: 1.6323 - val_accuracy: 0.4125 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3232 - accuracy: 0.5134 - val_loss: 1.6442 - val_accuracy: 0.3932 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3080 - accuracy: 0.5207 - val_loss: 1.6049 - val_accuracy: 0.4170 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.3074 - accuracy: 0.5268 - val_loss: 1.6147 - val_accuracy: 0.4091 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2890 - accuracy: 0.5245 - val_loss: 1.7636 - val_accuracy: 0.3830 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2779 - accuracy: 0.5335 - val_loss: 1.7266 - val_accuracy: 0.3818 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2547 - accuracy: 0.5443 - val_loss: 1.7580 - val_accuracy: 0.3818 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2583 - accuracy: 0.5438 - val_loss: 1.6887 - val_accuracy: 0.3977 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2321 - accuracy: 0.5497 - val_loss: 1.7112 - val_accuracy: 0.3966 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2411 - accuracy: 0.5553 - val_loss: 1.7174 - val_accuracy: 0.3875 - lr: 3.0000e-04\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2112 - accuracy: 0.5572 - val_loss: 1.6989 - val_accuracy: 0.3920 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.2053 - accuracy: 0.5631 - val_loss: 1.6857 - val_accuracy: 0.3966 - lr: 3.0000e-04\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1925 - accuracy: 0.5668 - val_loss: 1.6802 - val_accuracy: 0.4000 - lr: 3.0000e-04\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1666 - accuracy: 0.5808 - val_loss: 1.7773 - val_accuracy: 0.3875 - lr: 3.0000e-04\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1585 - accuracy: 0.5780 - val_loss: 1.7034 - val_accuracy: 0.3977 - lr: 3.0000e-04\nEpoch 60/100\n39/40 [============================>.] - ETA: 0s - loss: 1.1431 - accuracy: 0.5921\nEpoch 60: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 1.1424 - accuracy: 0.5924 - val_loss: 1.7348 - val_accuracy: 0.3989 - lr: 3.0000e-04\nEpoch 61/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.1223 - accuracy: 0.6010 - val_loss: 1.7028 - val_accuracy: 0.3989 - lr: 3.0000e-05\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1102 - accuracy: 0.5939 - val_loss: 1.6932 - val_accuracy: 0.4045 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1056 - accuracy: 0.6064 - val_loss: 1.6972 - val_accuracy: 0.4057 - lr: 3.0000e-05\nEpoch 64/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.1043 - accuracy: 0.6071 - val_loss: 1.6944 - val_accuracy: 0.4034 - lr: 3.0000e-05\nEpoch 65/100\n40/40 [==============================] - 1s 33ms/step - loss: 1.0984 - accuracy: 0.6116 - val_loss: 1.6931 - val_accuracy: 0.4080 - lr: 3.0000e-05\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0961 - accuracy: 0.6110 - val_loss: 1.6985 - val_accuracy: 0.4068 - lr: 3.0000e-05\nEpoch 67/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.1049 - accuracy: 0.6081 - val_loss: 1.6960 - val_accuracy: 0.4034 - lr: 3.0000e-05\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0930 - accuracy: 0.6121 - val_loss: 1.6959 - val_accuracy: 0.4068 - lr: 3.0000e-05\nEpoch 69/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0927 - accuracy: 0.6068 - val_loss: 1.6937 - val_accuracy: 0.4080 - lr: 3.0000e-05\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0992 - accuracy: 0.6043 - val_loss: 1.6916 - val_accuracy: 0.4091 - lr: 3.0000e-05\nEpoch 71/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0946 - accuracy: 0.6072 - val_loss: 1.6928 - val_accuracy: 0.4125 - lr: 3.0000e-05\nEpoch 72/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0855 - accuracy: 0.6178 - val_loss: 1.6928 - val_accuracy: 0.4182 - lr: 3.0000e-05\nEpoch 73/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0751 - accuracy: 0.6134 - val_loss: 1.6990 - val_accuracy: 0.4136 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0874 - accuracy: 0.6126 - val_loss: 1.6971 - val_accuracy: 0.4102 - lr: 3.0000e-05\nEpoch 75/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0747 - accuracy: 0.6217 - val_loss: 1.6970 - val_accuracy: 0.4125 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0716 - accuracy: 0.6236 - val_loss: 1.7025 - val_accuracy: 0.4068 - lr: 3.0000e-05\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0606 - accuracy: 0.6258 - val_loss: 1.7067 - val_accuracy: 0.4034 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0689 - accuracy: 0.6239 - val_loss: 1.7170 - val_accuracy: 0.4023 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0588 - accuracy: 0.6236 - val_loss: 1.7240 - val_accuracy: 0.4045 - lr: 3.0000e-05\nEpoch 80/100\n39/40 [============================>.] - ETA: 0s - loss: 1.0688 - accuracy: 0.6168\nEpoch 80: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 30ms/step - loss: 1.0685 - accuracy: 0.6168 - val_loss: 1.7194 - val_accuracy: 0.4057 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0533 - accuracy: 0.6313 - val_loss: 1.7115 - val_accuracy: 0.4091 - lr: 3.0000e-06\nEpoch 82/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0577 - accuracy: 0.6239 - val_loss: 1.7080 - val_accuracy: 0.4114 - lr: 3.0000e-06\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0628 - accuracy: 0.6264 - val_loss: 1.7049 - val_accuracy: 0.4102 - lr: 3.0000e-06\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0569 - accuracy: 0.6303 - val_loss: 1.7042 - val_accuracy: 0.4080 - lr: 3.0000e-06\nEpoch 85/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0499 - accuracy: 0.6342 - val_loss: 1.7033 - val_accuracy: 0.4102 - lr: 3.0000e-06\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0749 - accuracy: 0.6198 - val_loss: 1.7029 - val_accuracy: 0.4170 - lr: 3.0000e-06\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0478 - accuracy: 0.6294 - val_loss: 1.7028 - val_accuracy: 0.4159 - lr: 3.0000e-06\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0632 - accuracy: 0.6206 - val_loss: 1.7032 - val_accuracy: 0.4102 - lr: 3.0000e-06\nEpoch 89/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0481 - accuracy: 0.6327 - val_loss: 1.7038 - val_accuracy: 0.4091 - lr: 3.0000e-06\nEpoch 90/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0635 - accuracy: 0.6255 - val_loss: 1.7043 - val_accuracy: 0.4102 - lr: 3.0000e-06\nEpoch 91/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.0562 - accuracy: 0.6211 - val_loss: 1.7042 - val_accuracy: 0.4080 - lr: 3.0000e-06\nEpoch 92/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.0601 - accuracy: 0.6297 - val_loss: 1.7048 - val_accuracy: 0.4125 - lr: 3.0000e-06\nEpoch 93/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0483 - accuracy: 0.6285 - val_loss: 1.7050 - val_accuracy: 0.4114 - lr: 3.0000e-06\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0455 - accuracy: 0.6345 - val_loss: 1.7051 - val_accuracy: 0.4136 - lr: 3.0000e-06\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0610 - accuracy: 0.6270 - val_loss: 1.7055 - val_accuracy: 0.4125 - lr: 3.0000e-06\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0522 - accuracy: 0.6274 - val_loss: 1.7055 - val_accuracy: 0.4114 - lr: 3.0000e-06\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0606 - accuracy: 0.6201 - val_loss: 1.7046 - val_accuracy: 0.4114 - lr: 3.0000e-06\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0590 - accuracy: 0.6266 - val_loss: 1.7043 - val_accuracy: 0.4125 - lr: 3.0000e-06\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0681 - accuracy: 0.6279 - val_loss: 1.7053 - val_accuracy: 0.4102 - lr: 3.0000e-06\nEpoch 100/100\n39/40 [============================>.] - ETA: 0s - loss: 1.0600 - accuracy: 0.6232\nEpoch 100: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-07.\n40/40 [==============================] - 1s 30ms/step - loss: 1.0593 - accuracy: 0.6237 - val_loss: 1.7061 - val_accuracy: 0.4136 - lr: 3.0000e-06\n69/69 - 0s - loss: 1.7101 - accuracy: 0.3768 - 230ms/epoch - 3ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.3768181800842285\nStarting training for SNR: 14\nEpoch 1/100\n 1/40 [..............................] - ETA: 43s - loss: 3.2462 - accuracy: 0.0700","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:37:43.851839: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_17/dropout_68/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 6s 123ms/step - loss: 2.2349 - accuracy: 0.2870 - val_loss: 2.6573 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.6635 - accuracy: 0.3966 - val_loss: 3.5521 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.3950 - accuracy: 0.4770 - val_loss: 4.6054 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2037 - accuracy: 0.5417 - val_loss: 5.7672 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.0467 - accuracy: 0.5899 - val_loss: 7.0602 - val_accuracy: 0.0966 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9204 - accuracy: 0.6318 - val_loss: 8.3465 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8408 - accuracy: 0.6542 - val_loss: 9.6756 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.7832 - accuracy: 0.6742 - val_loss: 11.0624 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7242 - accuracy: 0.6885 - val_loss: 12.0283 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.6893 - accuracy: 0.6986 - val_loss: 12.5898 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.6573 - accuracy: 0.7136 - val_loss: 12.9095 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6257 - accuracy: 0.7311 - val_loss: 12.8393 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.5859 - accuracy: 0.7395 - val_loss: 13.4613 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5693 - accuracy: 0.7398 - val_loss: 13.4566 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5438 - accuracy: 0.7542 - val_loss: 13.1095 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5339 - accuracy: 0.7593 - val_loss: 11.9453 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5235 - accuracy: 0.7586 - val_loss: 10.3712 - val_accuracy: 0.1670 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5043 - accuracy: 0.7691 - val_loss: 8.1660 - val_accuracy: 0.1636 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4940 - accuracy: 0.7689 - val_loss: 7.5747 - val_accuracy: 0.1443 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4900 - accuracy: 0.7723 - val_loss: 4.5442 - val_accuracy: 0.1545 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4757 - accuracy: 0.7759 - val_loss: 2.4006 - val_accuracy: 0.3784 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4724 - accuracy: 0.7751 - val_loss: 1.3119 - val_accuracy: 0.5648 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4566 - accuracy: 0.7909 - val_loss: 1.1176 - val_accuracy: 0.6330 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 5s 118ms/step - loss: 0.4519 - accuracy: 0.7879 - val_loss: 1.0248 - val_accuracy: 0.6557 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.4474 - accuracy: 0.7837 - val_loss: 0.9793 - val_accuracy: 0.6636 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 4s 109ms/step - loss: 0.4431 - accuracy: 0.7953 - val_loss: 0.5897 - val_accuracy: 0.7420 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.4339 - accuracy: 0.7956 - val_loss: 0.5418 - val_accuracy: 0.7511 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4272 - accuracy: 0.8020 - val_loss: 0.9827 - val_accuracy: 0.6625 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4247 - accuracy: 0.8009 - val_loss: 0.6527 - val_accuracy: 0.7159 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4219 - accuracy: 0.7976 - val_loss: 0.7619 - val_accuracy: 0.6977 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4214 - accuracy: 0.7980 - val_loss: 0.5655 - val_accuracy: 0.7307 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4141 - accuracy: 0.8019 - val_loss: 0.5447 - val_accuracy: 0.7352 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4129 - accuracy: 0.8044 - val_loss: 0.5978 - val_accuracy: 0.7443 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 4s 114ms/step - loss: 0.4071 - accuracy: 0.8034 - val_loss: 0.4748 - val_accuracy: 0.7602 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.3999 - accuracy: 0.8121 - val_loss: 0.4552 - val_accuracy: 0.7693 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3920 - accuracy: 0.8155 - val_loss: 0.5041 - val_accuracy: 0.7557 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3889 - accuracy: 0.8144 - val_loss: 0.4650 - val_accuracy: 0.7648 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3799 - accuracy: 0.8184 - val_loss: 0.6691 - val_accuracy: 0.7341 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3829 - accuracy: 0.8181 - val_loss: 0.5545 - val_accuracy: 0.7568 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3701 - accuracy: 0.8236 - val_loss: 0.5074 - val_accuracy: 0.7602 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 4s 106ms/step - loss: 0.3725 - accuracy: 0.8206 - val_loss: 0.4449 - val_accuracy: 0.7818 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3680 - accuracy: 0.8234 - val_loss: 0.4689 - val_accuracy: 0.7727 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3602 - accuracy: 0.8256 - val_loss: 0.4510 - val_accuracy: 0.7705 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3547 - accuracy: 0.8324 - val_loss: 0.5811 - val_accuracy: 0.7443 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3571 - accuracy: 0.8336 - val_loss: 0.6152 - val_accuracy: 0.7466 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3507 - accuracy: 0.8333 - val_loss: 0.4878 - val_accuracy: 0.7705 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3391 - accuracy: 0.8399 - val_loss: 0.4780 - val_accuracy: 0.7648 - lr: 3.0000e-04\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3395 - accuracy: 0.8394 - val_loss: 0.6535 - val_accuracy: 0.7398 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3337 - accuracy: 0.8460 - val_loss: 0.7180 - val_accuracy: 0.7216 - lr: 3.0000e-04\nEpoch 50/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3302 - accuracy: 0.8468 - val_loss: 0.4697 - val_accuracy: 0.7659 - lr: 3.0000e-04\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3326 - accuracy: 0.8426 - val_loss: 0.4764 - val_accuracy: 0.7727 - lr: 3.0000e-04\nEpoch 52/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3345 - accuracy: 0.8405 - val_loss: 0.5068 - val_accuracy: 0.7750 - lr: 3.0000e-04\nEpoch 53/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3160 - accuracy: 0.8519 - val_loss: 0.5662 - val_accuracy: 0.7625 - lr: 3.0000e-04\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3146 - accuracy: 0.8542 - val_loss: 0.4459 - val_accuracy: 0.7909 - lr: 3.0000e-04\nEpoch 55/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.3131 - accuracy: 0.8516 - val_loss: 0.4390 - val_accuracy: 0.7966 - lr: 3.0000e-04\nEpoch 56/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.3038 - accuracy: 0.8585 - val_loss: 0.4192 - val_accuracy: 0.8000 - lr: 3.0000e-04\nEpoch 57/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3130 - accuracy: 0.8511 - val_loss: 0.4428 - val_accuracy: 0.7886 - lr: 3.0000e-04\nEpoch 58/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2989 - accuracy: 0.8598 - val_loss: 0.4355 - val_accuracy: 0.7989 - lr: 3.0000e-04\nEpoch 59/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2975 - accuracy: 0.8624 - val_loss: 0.4311 - val_accuracy: 0.7943 - lr: 3.0000e-04\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2897 - accuracy: 0.8614 - val_loss: 0.8375 - val_accuracy: 0.7091 - lr: 3.0000e-04\nEpoch 61/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2809 - accuracy: 0.8682 - val_loss: 0.5028 - val_accuracy: 0.7807 - lr: 3.0000e-04\nEpoch 62/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2902 - accuracy: 0.8619 - val_loss: 0.4853 - val_accuracy: 0.7807 - lr: 3.0000e-04\nEpoch 63/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.2792 - accuracy: 0.8679 - val_loss: 0.4879 - val_accuracy: 0.7716 - lr: 3.0000e-04\nEpoch 64/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2771 - accuracy: 0.8736 - val_loss: 0.6528 - val_accuracy: 0.7466 - lr: 3.0000e-04\nEpoch 65/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2694 - accuracy: 0.8716 - val_loss: 0.4969 - val_accuracy: 0.7693 - lr: 3.0000e-04\nEpoch 66/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2724 - accuracy: 0.8721 - val_loss: 0.4732 - val_accuracy: 0.7841 - lr: 3.0000e-04\nEpoch 67/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2679 - accuracy: 0.8713 - val_loss: 0.4822 - val_accuracy: 0.7830 - lr: 3.0000e-04\nEpoch 68/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2616 - accuracy: 0.8747 - val_loss: 0.4694 - val_accuracy: 0.7852 - lr: 3.0000e-04\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2608 - accuracy: 0.8785 - val_loss: 0.6195 - val_accuracy: 0.7466 - lr: 3.0000e-04\nEpoch 70/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2573 - accuracy: 0.8785 - val_loss: 0.5069 - val_accuracy: 0.7864 - lr: 3.0000e-04\nEpoch 71/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2554 - accuracy: 0.8789 - val_loss: 0.4948 - val_accuracy: 0.7864 - lr: 3.0000e-04\nEpoch 72/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2476 - accuracy: 0.8836 - val_loss: 0.4844 - val_accuracy: 0.7818 - lr: 3.0000e-04\nEpoch 73/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2525 - accuracy: 0.8789 - val_loss: 0.4227 - val_accuracy: 0.8045 - lr: 3.0000e-04\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2449 - accuracy: 0.8847 - val_loss: 0.4403 - val_accuracy: 0.8114 - lr: 3.0000e-04\nEpoch 75/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2433 - accuracy: 0.8816 - val_loss: 0.4295 - val_accuracy: 0.8182 - lr: 3.0000e-04\nEpoch 76/100\n39/40 [============================>.] - ETA: 0s - loss: 0.2389 - accuracy: 0.8887\nEpoch 76: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.2393 - accuracy: 0.8885 - val_loss: 0.4441 - val_accuracy: 0.7989 - lr: 3.0000e-04\nEpoch 77/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2312 - accuracy: 0.8886 - val_loss: 0.4207 - val_accuracy: 0.8091 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 5s 117ms/step - loss: 0.2205 - accuracy: 0.8942 - val_loss: 0.4170 - val_accuracy: 0.8057 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.2207 - accuracy: 0.8956 - val_loss: 0.4095 - val_accuracy: 0.8136 - lr: 3.0000e-05\nEpoch 80/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.2178 - accuracy: 0.8980 - val_loss: 0.4081 - val_accuracy: 0.8136 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 33ms/step - loss: 0.2245 - accuracy: 0.8937 - val_loss: 0.4099 - val_accuracy: 0.8068 - lr: 3.0000e-05\nEpoch 82/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2177 - accuracy: 0.8980 - val_loss: 0.4111 - val_accuracy: 0.8034 - lr: 3.0000e-05\nEpoch 83/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2173 - accuracy: 0.8965 - val_loss: 0.4097 - val_accuracy: 0.8057 - lr: 3.0000e-05\nEpoch 84/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2191 - accuracy: 0.8989 - val_loss: 0.4115 - val_accuracy: 0.8091 - lr: 3.0000e-05\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2201 - accuracy: 0.8971 - val_loss: 0.4104 - val_accuracy: 0.8080 - lr: 3.0000e-05\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2130 - accuracy: 0.9019 - val_loss: 0.4131 - val_accuracy: 0.8114 - lr: 3.0000e-05\nEpoch 87/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2149 - accuracy: 0.9006 - val_loss: 0.4115 - val_accuracy: 0.8091 - lr: 3.0000e-05\nEpoch 88/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2126 - accuracy: 0.8979 - val_loss: 0.4134 - val_accuracy: 0.8136 - lr: 3.0000e-05\nEpoch 89/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2153 - accuracy: 0.8972 - val_loss: 0.4104 - val_accuracy: 0.8057 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2163 - accuracy: 0.8981 - val_loss: 0.4111 - val_accuracy: 0.8045 - lr: 3.0000e-05\nEpoch 91/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.2166 - accuracy: 0.8981 - val_loss: 0.4096 - val_accuracy: 0.8068 - lr: 3.0000e-05\nEpoch 92/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.2129 - accuracy: 0.9000 - val_loss: 0.4079 - val_accuracy: 0.8045 - lr: 3.0000e-05\nEpoch 93/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2125 - accuracy: 0.9011 - val_loss: 0.4091 - val_accuracy: 0.8136 - lr: 3.0000e-05\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2120 - accuracy: 0.8990 - val_loss: 0.4103 - val_accuracy: 0.8125 - lr: 3.0000e-05\nEpoch 95/100\n40/40 [==============================] - 5s 117ms/step - loss: 0.2131 - accuracy: 0.9019 - val_loss: 0.4059 - val_accuracy: 0.8114 - lr: 3.0000e-05\nEpoch 96/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.2091 - accuracy: 0.9010 - val_loss: 0.4098 - val_accuracy: 0.8068 - lr: 3.0000e-05\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2106 - accuracy: 0.8965 - val_loss: 0.4123 - val_accuracy: 0.8159 - lr: 3.0000e-05\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2119 - accuracy: 0.9043 - val_loss: 0.4102 - val_accuracy: 0.8034 - lr: 3.0000e-05\nEpoch 99/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2096 - accuracy: 0.9024 - val_loss: 0.4094 - val_accuracy: 0.8136 - lr: 3.0000e-05\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.2085 - accuracy: 0.9023 - val_loss: 0.4118 - val_accuracy: 0.8091 - lr: 3.0000e-05\n69/69 - 0s - loss: 0.4526 - accuracy: 0.8055 - 232ms/epoch - 3ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.8054545521736145\nStarting training for SNR: 18\nEpoch 1/100\n 1/40 [..............................] - ETA: 44s - loss: 3.1270 - accuracy: 0.0800","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:40:38.347328: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_18/dropout_72/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 107ms/step - loss: 2.2108 - accuracy: 0.2859 - val_loss: 2.6019 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.6349 - accuracy: 0.4001 - val_loss: 3.4703 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.4024 - accuracy: 0.4667 - val_loss: 4.6888 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.2318 - accuracy: 0.5241 - val_loss: 5.8943 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.0836 - accuracy: 0.5773 - val_loss: 6.7333 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.9590 - accuracy: 0.6247 - val_loss: 7.2668 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.8728 - accuracy: 0.6484 - val_loss: 7.8475 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.8022 - accuracy: 0.6760 - val_loss: 8.3046 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.7459 - accuracy: 0.6836 - val_loss: 8.5200 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6918 - accuracy: 0.6992 - val_loss: 8.9209 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6479 - accuracy: 0.7154 - val_loss: 9.2028 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.6081 - accuracy: 0.7290 - val_loss: 9.6372 - val_accuracy: 0.0932 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5834 - accuracy: 0.7372 - val_loss: 9.9148 - val_accuracy: 0.1466 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5593 - accuracy: 0.7473 - val_loss: 9.9354 - val_accuracy: 0.1045 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5482 - accuracy: 0.7447 - val_loss: 9.6929 - val_accuracy: 0.1023 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5206 - accuracy: 0.7569 - val_loss: 9.2969 - val_accuracy: 0.1261 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.5142 - accuracy: 0.7587 - val_loss: 7.3083 - val_accuracy: 0.1705 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.5021 - accuracy: 0.7602 - val_loss: 5.7568 - val_accuracy: 0.2500 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4945 - accuracy: 0.7670 - val_loss: 3.2826 - val_accuracy: 0.3807 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4869 - accuracy: 0.7646 - val_loss: 3.3993 - val_accuracy: 0.4068 - lr: 3.0000e-04\nEpoch 21/100\n39/40 [============================>.] - ETA: 0s - loss: 0.4767 - accuracy: 0.7779\nEpoch 21: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 0.4750 - accuracy: 0.7787 - val_loss: 2.8248 - val_accuracy: 0.4307 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 4s 101ms/step - loss: 0.4608 - accuracy: 0.7860 - val_loss: 1.7717 - val_accuracy: 0.5420 - lr: 3.0000e-05\nEpoch 23/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4607 - accuracy: 0.7854 - val_loss: 1.2307 - val_accuracy: 0.6091 - lr: 3.0000e-05\nEpoch 24/100\n40/40 [==============================] - 5s 115ms/step - loss: 0.4549 - accuracy: 0.7876 - val_loss: 0.9974 - val_accuracy: 0.6500 - lr: 3.0000e-05\nEpoch 25/100\n40/40 [==============================] - 4s 99ms/step - loss: 0.4570 - accuracy: 0.7870 - val_loss: 0.9806 - val_accuracy: 0.6568 - lr: 3.0000e-05\nEpoch 26/100\n40/40 [==============================] - 4s 96ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.8437 - val_accuracy: 0.6727 - lr: 3.0000e-05\nEpoch 27/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.4565 - accuracy: 0.7848 - val_loss: 0.7129 - val_accuracy: 0.6864 - lr: 3.0000e-05\nEpoch 28/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4553 - accuracy: 0.7845 - val_loss: 0.7464 - val_accuracy: 0.6898 - lr: 3.0000e-05\nEpoch 29/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4523 - accuracy: 0.7794 - val_loss: 0.7207 - val_accuracy: 0.6830 - lr: 3.0000e-05\nEpoch 30/100\n40/40 [==============================] - 4s 113ms/step - loss: 0.4470 - accuracy: 0.7880 - val_loss: 0.6956 - val_accuracy: 0.6909 - lr: 3.0000e-05\nEpoch 31/100\n40/40 [==============================] - 4s 97ms/step - loss: 0.4524 - accuracy: 0.7845 - val_loss: 0.6792 - val_accuracy: 0.6966 - lr: 3.0000e-05\nEpoch 32/100\n40/40 [==============================] - 1s 34ms/step - loss: 0.4447 - accuracy: 0.7963 - val_loss: 0.7777 - val_accuracy: 0.6852 - lr: 3.0000e-05\nEpoch 33/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4422 - accuracy: 0.7864 - val_loss: 0.7076 - val_accuracy: 0.6932 - lr: 3.0000e-05\nEpoch 34/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4420 - accuracy: 0.7942 - val_loss: 0.7191 - val_accuracy: 0.6955 - lr: 3.0000e-05\nEpoch 35/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4420 - accuracy: 0.7904 - val_loss: 0.7742 - val_accuracy: 0.7000 - lr: 3.0000e-05\nEpoch 36/100\n40/40 [==============================] - 4s 95ms/step - loss: 0.4389 - accuracy: 0.7923 - val_loss: 0.6520 - val_accuracy: 0.7034 - lr: 3.0000e-05\nEpoch 37/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4386 - accuracy: 0.7878 - val_loss: 0.7096 - val_accuracy: 0.6886 - lr: 3.0000e-05\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4340 - accuracy: 0.7904 - val_loss: 0.7496 - val_accuracy: 0.6830 - lr: 3.0000e-05\nEpoch 39/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4372 - accuracy: 0.7944 - val_loss: 0.6738 - val_accuracy: 0.6955 - lr: 3.0000e-05\nEpoch 40/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4439 - accuracy: 0.7848 - val_loss: 0.7487 - val_accuracy: 0.6909 - lr: 3.0000e-05\nEpoch 41/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4433 - accuracy: 0.7869 - val_loss: 0.7628 - val_accuracy: 0.6943 - lr: 3.0000e-05\nEpoch 42/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4327 - accuracy: 0.7929 - val_loss: 0.7181 - val_accuracy: 0.6864 - lr: 3.0000e-05\nEpoch 43/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4375 - accuracy: 0.7938 - val_loss: 0.7854 - val_accuracy: 0.6864 - lr: 3.0000e-05\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4320 - accuracy: 0.7949 - val_loss: 0.7116 - val_accuracy: 0.6932 - lr: 3.0000e-05\nEpoch 45/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4383 - accuracy: 0.7888 - val_loss: 0.6901 - val_accuracy: 0.6977 - lr: 3.0000e-05\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4351 - accuracy: 0.7968 - val_loss: 0.6978 - val_accuracy: 0.6943 - lr: 3.0000e-05\nEpoch 47/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4314 - accuracy: 0.7929 - val_loss: 0.7084 - val_accuracy: 0.6943 - lr: 3.0000e-05\nEpoch 48/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4371 - accuracy: 0.7941 - val_loss: 0.6747 - val_accuracy: 0.6943 - lr: 3.0000e-05\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4298 - accuracy: 0.7973 - val_loss: 0.7362 - val_accuracy: 0.6886 - lr: 3.0000e-05\nEpoch 50/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4320 - accuracy: 0.7941 - val_loss: 0.7122 - val_accuracy: 0.6955 - lr: 3.0000e-05\nEpoch 51/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4322 - accuracy: 0.7907 - val_loss: 0.7329 - val_accuracy: 0.6955 - lr: 3.0000e-05\nEpoch 52/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.4300 - accuracy: 0.7910 - val_loss: 0.6130 - val_accuracy: 0.7057 - lr: 3.0000e-05\nEpoch 53/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.4325 - accuracy: 0.7963 - val_loss: 0.6700 - val_accuracy: 0.7080 - lr: 3.0000e-05\nEpoch 54/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4288 - accuracy: 0.7960 - val_loss: 0.6507 - val_accuracy: 0.7125 - lr: 3.0000e-05\nEpoch 55/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4262 - accuracy: 0.7915 - val_loss: 0.7044 - val_accuracy: 0.6966 - lr: 3.0000e-05\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4271 - accuracy: 0.7946 - val_loss: 0.6638 - val_accuracy: 0.7034 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4230 - accuracy: 0.7971 - val_loss: 0.6556 - val_accuracy: 0.7057 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4263 - accuracy: 0.7984 - val_loss: 0.6441 - val_accuracy: 0.7068 - lr: 3.0000e-05\nEpoch 59/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4240 - accuracy: 0.7973 - val_loss: 0.7072 - val_accuracy: 0.7011 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4198 - accuracy: 0.7944 - val_loss: 0.6437 - val_accuracy: 0.7080 - lr: 3.0000e-05\nEpoch 61/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.7233 - val_accuracy: 0.6784 - lr: 3.0000e-05\nEpoch 62/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4150 - accuracy: 0.8025 - val_loss: 0.6653 - val_accuracy: 0.7057 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4207 - accuracy: 0.7947 - val_loss: 0.6627 - val_accuracy: 0.7011 - lr: 3.0000e-05\nEpoch 64/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4197 - accuracy: 0.8033 - val_loss: 0.6743 - val_accuracy: 0.7114 - lr: 3.0000e-05\nEpoch 65/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4152 - accuracy: 0.7977 - val_loss: 0.6402 - val_accuracy: 0.7136 - lr: 3.0000e-05\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4152 - accuracy: 0.8009 - val_loss: 0.6616 - val_accuracy: 0.7125 - lr: 3.0000e-05\nEpoch 67/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4104 - accuracy: 0.8043 - val_loss: 0.6358 - val_accuracy: 0.7114 - lr: 3.0000e-05\nEpoch 68/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4203 - accuracy: 0.7960 - val_loss: 0.7533 - val_accuracy: 0.6989 - lr: 3.0000e-05\nEpoch 69/100\n40/40 [==============================] - 4s 94ms/step - loss: 0.4091 - accuracy: 0.8053 - val_loss: 0.6063 - val_accuracy: 0.7216 - lr: 3.0000e-05\nEpoch 70/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4132 - accuracy: 0.8025 - val_loss: 0.6299 - val_accuracy: 0.7239 - lr: 3.0000e-05\nEpoch 71/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4153 - accuracy: 0.7981 - val_loss: 0.6075 - val_accuracy: 0.7227 - lr: 3.0000e-05\nEpoch 72/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4093 - accuracy: 0.8030 - val_loss: 0.7353 - val_accuracy: 0.6955 - lr: 3.0000e-05\nEpoch 73/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4110 - accuracy: 0.8018 - val_loss: 0.7057 - val_accuracy: 0.7023 - lr: 3.0000e-05\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4103 - accuracy: 0.8005 - val_loss: 0.6274 - val_accuracy: 0.7148 - lr: 3.0000e-05\nEpoch 75/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4038 - accuracy: 0.8107 - val_loss: 0.6310 - val_accuracy: 0.7159 - lr: 3.0000e-05\nEpoch 76/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4054 - accuracy: 0.8086 - val_loss: 0.6163 - val_accuracy: 0.7216 - lr: 3.0000e-05\nEpoch 77/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.4070 - accuracy: 0.8092 - val_loss: 0.6630 - val_accuracy: 0.7136 - lr: 3.0000e-05\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4096 - accuracy: 0.8025 - val_loss: 0.6157 - val_accuracy: 0.7205 - lr: 3.0000e-05\nEpoch 79/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.6284 - val_accuracy: 0.7193 - lr: 3.0000e-05\nEpoch 80/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4016 - accuracy: 0.8111 - val_loss: 0.6576 - val_accuracy: 0.7205 - lr: 3.0000e-05\nEpoch 81/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.4024 - accuracy: 0.8048 - val_loss: 0.7150 - val_accuracy: 0.7080 - lr: 3.0000e-05\nEpoch 82/100\n40/40 [==============================] - 5s 117ms/step - loss: 0.4048 - accuracy: 0.8114 - val_loss: 0.5828 - val_accuracy: 0.7273 - lr: 3.0000e-05\nEpoch 83/100\n40/40 [==============================] - 4s 98ms/step - loss: 0.4004 - accuracy: 0.8063 - val_loss: 0.5643 - val_accuracy: 0.7341 - lr: 3.0000e-05\nEpoch 84/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3983 - accuracy: 0.8081 - val_loss: 0.6347 - val_accuracy: 0.7182 - lr: 3.0000e-05\nEpoch 85/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4000 - accuracy: 0.8093 - val_loss: 0.6163 - val_accuracy: 0.7216 - lr: 3.0000e-05\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4046 - accuracy: 0.8072 - val_loss: 0.6095 - val_accuracy: 0.7239 - lr: 3.0000e-05\nEpoch 87/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3976 - accuracy: 0.8087 - val_loss: 0.6195 - val_accuracy: 0.7239 - lr: 3.0000e-05\nEpoch 88/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4031 - accuracy: 0.8040 - val_loss: 0.6338 - val_accuracy: 0.7284 - lr: 3.0000e-05\nEpoch 89/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.4001 - accuracy: 0.8049 - val_loss: 0.6034 - val_accuracy: 0.7341 - lr: 3.0000e-05\nEpoch 90/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3981 - accuracy: 0.8073 - val_loss: 0.7916 - val_accuracy: 0.6977 - lr: 3.0000e-05\nEpoch 91/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3930 - accuracy: 0.8122 - val_loss: 0.6300 - val_accuracy: 0.7216 - lr: 3.0000e-05\nEpoch 92/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3957 - accuracy: 0.8134 - val_loss: 0.6080 - val_accuracy: 0.7193 - lr: 3.0000e-05\nEpoch 93/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3937 - accuracy: 0.8143 - val_loss: 0.6513 - val_accuracy: 0.7170 - lr: 3.0000e-05\nEpoch 94/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3942 - accuracy: 0.8062 - val_loss: 0.6043 - val_accuracy: 0.7216 - lr: 3.0000e-05\nEpoch 95/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3916 - accuracy: 0.8105 - val_loss: 0.7070 - val_accuracy: 0.7011 - lr: 3.0000e-05\nEpoch 96/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3906 - accuracy: 0.8145 - val_loss: 0.6083 - val_accuracy: 0.7261 - lr: 3.0000e-05\nEpoch 97/100\n40/40 [==============================] - 1s 29ms/step - loss: 0.3862 - accuracy: 0.8152 - val_loss: 0.7212 - val_accuracy: 0.7125 - lr: 3.0000e-05\nEpoch 98/100\n40/40 [==============================] - 1s 31ms/step - loss: 0.3894 - accuracy: 0.8104 - val_loss: 0.6596 - val_accuracy: 0.7136 - lr: 3.0000e-05\nEpoch 99/100\n40/40 [==============================] - 1s 32ms/step - loss: 0.3874 - accuracy: 0.8140 - val_loss: 0.6108 - val_accuracy: 0.7250 - lr: 3.0000e-05\nEpoch 100/100\n40/40 [==============================] - 1s 30ms/step - loss: 0.3850 - accuracy: 0.8158 - val_loss: 0.5723 - val_accuracy: 0.7375 - lr: 3.0000e-05\n69/69 - 0s - loss: 0.5410 - accuracy: 0.7405 - 283ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.7404545545578003\nStarting training for SNR: -14\nEpoch 1/100\n 1/40 [..............................] - ETA: 41s - loss: 3.1500 - accuracy: 0.1050","output_type":"stream"},{"name":"stderr","text":"2023-04-22 01:44:02.315579: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_19/dropout_76/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"40/40 [==============================] - 5s 100ms/step - loss: 3.1017 - accuracy: 0.0994 - val_loss: 2.4452 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 2/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.8456 - accuracy: 0.1277 - val_loss: 2.5459 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 3/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.6245 - accuracy: 0.1657 - val_loss: 2.6340 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 4/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.5109 - accuracy: 0.1753 - val_loss: 2.6707 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 5/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.4088 - accuracy: 0.1851 - val_loss: 2.6879 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 6/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.3440 - accuracy: 0.1934 - val_loss: 2.7388 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 7/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.2901 - accuracy: 0.2057 - val_loss: 2.7421 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 8/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2535 - accuracy: 0.2032 - val_loss: 2.6919 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 9/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.2233 - accuracy: 0.2117 - val_loss: 2.6218 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 10/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1950 - accuracy: 0.2198 - val_loss: 2.6067 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 11/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.1772 - accuracy: 0.2193 - val_loss: 2.5919 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 12/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1589 - accuracy: 0.2298 - val_loss: 2.5830 - val_accuracy: 0.0943 - lr: 3.0000e-04\nEpoch 13/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1430 - accuracy: 0.2424 - val_loss: 2.5516 - val_accuracy: 0.0909 - lr: 3.0000e-04\nEpoch 14/100\n40/40 [==============================] - 1s 30ms/step - loss: 2.1234 - accuracy: 0.2365 - val_loss: 2.5350 - val_accuracy: 0.0920 - lr: 3.0000e-04\nEpoch 15/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.1104 - accuracy: 0.2460 - val_loss: 2.4782 - val_accuracy: 0.1045 - lr: 3.0000e-04\nEpoch 16/100\n40/40 [==============================] - 4s 93ms/step - loss: 2.1056 - accuracy: 0.2403 - val_loss: 2.3946 - val_accuracy: 0.1261 - lr: 3.0000e-04\nEpoch 17/100\n40/40 [==============================] - 5s 117ms/step - loss: 2.0966 - accuracy: 0.2413 - val_loss: 2.2950 - val_accuracy: 0.1682 - lr: 3.0000e-04\nEpoch 18/100\n40/40 [==============================] - 4s 97ms/step - loss: 2.0931 - accuracy: 0.2403 - val_loss: 2.2344 - val_accuracy: 0.1920 - lr: 3.0000e-04\nEpoch 19/100\n40/40 [==============================] - 4s 95ms/step - loss: 2.0841 - accuracy: 0.2558 - val_loss: 2.1840 - val_accuracy: 0.2125 - lr: 3.0000e-04\nEpoch 20/100\n40/40 [==============================] - 4s 96ms/step - loss: 2.0739 - accuracy: 0.2596 - val_loss: 2.1788 - val_accuracy: 0.2080 - lr: 3.0000e-04\nEpoch 21/100\n40/40 [==============================] - 5s 115ms/step - loss: 2.0574 - accuracy: 0.2652 - val_loss: 2.1637 - val_accuracy: 0.2136 - lr: 3.0000e-04\nEpoch 22/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.0465 - accuracy: 0.2664 - val_loss: 2.1722 - val_accuracy: 0.2102 - lr: 3.0000e-04\nEpoch 23/100\n40/40 [==============================] - 1s 32ms/step - loss: 2.0395 - accuracy: 0.2677 - val_loss: 2.1914 - val_accuracy: 0.1966 - lr: 3.0000e-04\nEpoch 24/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0367 - accuracy: 0.2702 - val_loss: 2.1689 - val_accuracy: 0.2102 - lr: 3.0000e-04\nEpoch 25/100\n40/40 [==============================] - 1s 31ms/step - loss: 2.0253 - accuracy: 0.2747 - val_loss: 2.1656 - val_accuracy: 0.2068 - lr: 3.0000e-04\nEpoch 26/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0115 - accuracy: 0.2784 - val_loss: 2.1851 - val_accuracy: 0.2000 - lr: 3.0000e-04\nEpoch 27/100\n40/40 [==============================] - 1s 29ms/step - loss: 2.0111 - accuracy: 0.2784 - val_loss: 2.1727 - val_accuracy: 0.2159 - lr: 3.0000e-04\nEpoch 28/100\n40/40 [==============================] - 4s 94ms/step - loss: 2.0056 - accuracy: 0.2818 - val_loss: 2.1572 - val_accuracy: 0.2068 - lr: 3.0000e-04\nEpoch 29/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.9959 - accuracy: 0.2900 - val_loss: 2.1573 - val_accuracy: 0.2080 - lr: 3.0000e-04\nEpoch 30/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9856 - accuracy: 0.2909 - val_loss: 2.1629 - val_accuracy: 0.1989 - lr: 3.0000e-04\nEpoch 31/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9811 - accuracy: 0.2908 - val_loss: 2.1729 - val_accuracy: 0.2102 - lr: 3.0000e-04\nEpoch 32/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9725 - accuracy: 0.2914 - val_loss: 2.1766 - val_accuracy: 0.2114 - lr: 3.0000e-04\nEpoch 33/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9603 - accuracy: 0.3029 - val_loss: 2.1692 - val_accuracy: 0.2091 - lr: 3.0000e-04\nEpoch 34/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9575 - accuracy: 0.3071 - val_loss: 2.1620 - val_accuracy: 0.2205 - lr: 3.0000e-04\nEpoch 35/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9479 - accuracy: 0.3067 - val_loss: 2.2038 - val_accuracy: 0.1943 - lr: 3.0000e-04\nEpoch 36/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.9347 - accuracy: 0.3140 - val_loss: 2.2054 - val_accuracy: 0.1886 - lr: 3.0000e-04\nEpoch 37/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9259 - accuracy: 0.3128 - val_loss: 2.2203 - val_accuracy: 0.1784 - lr: 3.0000e-04\nEpoch 38/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.9077 - accuracy: 0.3292 - val_loss: 2.1971 - val_accuracy: 0.1955 - lr: 3.0000e-04\nEpoch 39/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.8925 - accuracy: 0.3306 - val_loss: 2.1937 - val_accuracy: 0.1977 - lr: 3.0000e-04\nEpoch 40/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.8919 - accuracy: 0.3372 - val_loss: 2.2181 - val_accuracy: 0.1898 - lr: 3.0000e-04\nEpoch 41/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.8723 - accuracy: 0.3438 - val_loss: 2.2548 - val_accuracy: 0.1773 - lr: 3.0000e-04\nEpoch 42/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8700 - accuracy: 0.3444 - val_loss: 2.2117 - val_accuracy: 0.2068 - lr: 3.0000e-04\nEpoch 43/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.8601 - accuracy: 0.3439 - val_loss: 2.2362 - val_accuracy: 0.1920 - lr: 3.0000e-04\nEpoch 44/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8404 - accuracy: 0.3530 - val_loss: 2.2473 - val_accuracy: 0.2023 - lr: 3.0000e-04\nEpoch 45/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.8320 - accuracy: 0.3567 - val_loss: 2.2648 - val_accuracy: 0.1727 - lr: 3.0000e-04\nEpoch 46/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.8089 - accuracy: 0.3665 - val_loss: 2.2322 - val_accuracy: 0.2023 - lr: 3.0000e-04\nEpoch 47/100\n40/40 [==============================] - 1s 32ms/step - loss: 1.8069 - accuracy: 0.3678 - val_loss: 2.3821 - val_accuracy: 0.1568 - lr: 3.0000e-04\nEpoch 48/100\n39/40 [============================>.] - ETA: 0s - loss: 1.7770 - accuracy: 0.3799\nEpoch 48: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n40/40 [==============================] - 1s 30ms/step - loss: 1.7781 - accuracy: 0.3795 - val_loss: 2.3507 - val_accuracy: 0.1625 - lr: 3.0000e-04\nEpoch 49/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7465 - accuracy: 0.3952 - val_loss: 2.2783 - val_accuracy: 0.1807 - lr: 3.0000e-05\nEpoch 50/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.7616 - accuracy: 0.3928 - val_loss: 2.2564 - val_accuracy: 0.1909 - lr: 3.0000e-05\nEpoch 51/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7482 - accuracy: 0.3972 - val_loss: 2.2470 - val_accuracy: 0.1909 - lr: 3.0000e-05\nEpoch 52/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7533 - accuracy: 0.3908 - val_loss: 2.2421 - val_accuracy: 0.1943 - lr: 3.0000e-05\nEpoch 53/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7491 - accuracy: 0.3936 - val_loss: 2.2441 - val_accuracy: 0.1955 - lr: 3.0000e-05\nEpoch 54/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7462 - accuracy: 0.3995 - val_loss: 2.2483 - val_accuracy: 0.1966 - lr: 3.0000e-05\nEpoch 55/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7385 - accuracy: 0.3915 - val_loss: 2.2456 - val_accuracy: 0.1977 - lr: 3.0000e-05\nEpoch 56/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7429 - accuracy: 0.4003 - val_loss: 2.2468 - val_accuracy: 0.1955 - lr: 3.0000e-05\nEpoch 57/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7343 - accuracy: 0.4000 - val_loss: 2.2501 - val_accuracy: 0.1932 - lr: 3.0000e-05\nEpoch 58/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7361 - accuracy: 0.4008 - val_loss: 2.2518 - val_accuracy: 0.1932 - lr: 3.0000e-05\nEpoch 59/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7331 - accuracy: 0.4051 - val_loss: 2.2566 - val_accuracy: 0.1955 - lr: 3.0000e-05\nEpoch 60/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.7343 - accuracy: 0.3957 - val_loss: 2.2521 - val_accuracy: 0.1966 - lr: 3.0000e-05\nEpoch 61/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7262 - accuracy: 0.3985 - val_loss: 2.2500 - val_accuracy: 0.1966 - lr: 3.0000e-05\nEpoch 62/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7218 - accuracy: 0.4025 - val_loss: 2.2518 - val_accuracy: 0.1943 - lr: 3.0000e-05\nEpoch 63/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7203 - accuracy: 0.4092 - val_loss: 2.2483 - val_accuracy: 0.1977 - lr: 3.0000e-05\nEpoch 64/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7157 - accuracy: 0.4078 - val_loss: 2.2496 - val_accuracy: 0.1989 - lr: 3.0000e-05\nEpoch 65/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7269 - accuracy: 0.4030 - val_loss: 2.2535 - val_accuracy: 0.1977 - lr: 3.0000e-05\nEpoch 66/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6983 - accuracy: 0.4186 - val_loss: 2.2590 - val_accuracy: 0.1977 - lr: 3.0000e-05\nEpoch 67/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7242 - accuracy: 0.3996 - val_loss: 2.2566 - val_accuracy: 0.1943 - lr: 3.0000e-05\nEpoch 68/100\n39/40 [============================>.] - ETA: 0s - loss: 1.7160 - accuracy: 0.4024\nEpoch 68: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n40/40 [==============================] - 1s 29ms/step - loss: 1.7189 - accuracy: 0.4015 - val_loss: 2.2599 - val_accuracy: 0.1966 - lr: 3.0000e-05\nEpoch 69/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7143 - accuracy: 0.4101 - val_loss: 2.2590 - val_accuracy: 0.1955 - lr: 3.0000e-06\nEpoch 70/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7099 - accuracy: 0.4102 - val_loss: 2.2590 - val_accuracy: 0.1966 - lr: 3.0000e-06\nEpoch 71/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6990 - accuracy: 0.4152 - val_loss: 2.2593 - val_accuracy: 0.1955 - lr: 3.0000e-06\nEpoch 72/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6958 - accuracy: 0.4082 - val_loss: 2.2599 - val_accuracy: 0.1966 - lr: 3.0000e-06\nEpoch 73/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.7057 - accuracy: 0.4154 - val_loss: 2.2594 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 74/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7025 - accuracy: 0.4196 - val_loss: 2.2595 - val_accuracy: 0.1966 - lr: 3.0000e-06\nEpoch 75/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6987 - accuracy: 0.4073 - val_loss: 2.2595 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 76/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.7061 - accuracy: 0.4154 - val_loss: 2.2592 - val_accuracy: 0.1989 - lr: 3.0000e-06\nEpoch 77/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6908 - accuracy: 0.4194 - val_loss: 2.2594 - val_accuracy: 0.1989 - lr: 3.0000e-06\nEpoch 78/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7065 - accuracy: 0.4140 - val_loss: 2.2588 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 79/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7027 - accuracy: 0.4143 - val_loss: 2.2595 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 80/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7069 - accuracy: 0.4077 - val_loss: 2.2602 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 81/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7017 - accuracy: 0.4116 - val_loss: 2.2605 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 82/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7188 - accuracy: 0.4021 - val_loss: 2.2602 - val_accuracy: 0.1966 - lr: 3.0000e-06\nEpoch 83/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7002 - accuracy: 0.4133 - val_loss: 2.2602 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 84/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7077 - accuracy: 0.4131 - val_loss: 2.2596 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 85/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7072 - accuracy: 0.4150 - val_loss: 2.2593 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 86/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7038 - accuracy: 0.4201 - val_loss: 2.2596 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 87/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7133 - accuracy: 0.4087 - val_loss: 2.2612 - val_accuracy: 0.1977 - lr: 3.0000e-06\nEpoch 88/100\n39/40 [============================>.] - ETA: 0s - loss: 1.7050 - accuracy: 0.4144\nEpoch 88: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-07.\n40/40 [==============================] - 1s 30ms/step - loss: 1.7048 - accuracy: 0.4131 - val_loss: 2.2611 - val_accuracy: 0.1966 - lr: 3.0000e-06\nEpoch 89/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6924 - accuracy: 0.4173 - val_loss: 2.2613 - val_accuracy: 0.1955 - lr: 3.0000e-07\nEpoch 90/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6984 - accuracy: 0.4192 - val_loss: 2.2616 - val_accuracy: 0.1977 - lr: 3.0000e-07\nEpoch 91/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7112 - accuracy: 0.4085 - val_loss: 2.2617 - val_accuracy: 0.1977 - lr: 3.0000e-07\nEpoch 92/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7067 - accuracy: 0.4130 - val_loss: 2.2617 - val_accuracy: 0.1966 - lr: 3.0000e-07\nEpoch 93/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.7105 - accuracy: 0.4018 - val_loss: 2.2619 - val_accuracy: 0.1966 - lr: 3.0000e-07\nEpoch 94/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7108 - accuracy: 0.4066 - val_loss: 2.2616 - val_accuracy: 0.1966 - lr: 3.0000e-07\nEpoch 95/100\n40/40 [==============================] - 1s 29ms/step - loss: 1.6989 - accuracy: 0.4158 - val_loss: 2.2620 - val_accuracy: 0.1966 - lr: 3.0000e-07\nEpoch 96/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7023 - accuracy: 0.4178 - val_loss: 2.2617 - val_accuracy: 0.1966 - lr: 3.0000e-07\nEpoch 97/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.7032 - accuracy: 0.4081 - val_loss: 2.2618 - val_accuracy: 0.1977 - lr: 3.0000e-07\nEpoch 98/100\n40/40 [==============================] - 1s 30ms/step - loss: 1.6995 - accuracy: 0.4174 - val_loss: 2.2617 - val_accuracy: 0.1966 - lr: 3.0000e-07\nEpoch 99/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.7051 - accuracy: 0.4140 - val_loss: 2.2618 - val_accuracy: 0.1966 - lr: 3.0000e-07\nEpoch 100/100\n40/40 [==============================] - 1s 31ms/step - loss: 1.7070 - accuracy: 0.4109 - val_loss: 2.2617 - val_accuracy: 0.1966 - lr: 3.0000e-07\n69/69 - 0s - loss: 2.2590 - accuracy: 0.2023 - 244ms/epoch - 4ms/step\n69/69 [==============================] - 0s 3ms/step\naccuracy = 0.20227272808551788\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\nimport os\nimport pickle\nimport numpy as np\n# Use this code only if you want to generate 20 different models corresponding to 20 SNR values\naccuracies_All_dnn = []\nconfusion_matrices_All_dnn = []\n\nfor key in SNRs.keys():\n    dataset = []\n    labels = []\n\n    for values in SNRs[key]:\n        labels.append(values[0])\n        dataset.append(values[1])\n\n    print('Starting training for SNR:', key)\n\n    N = len(dataset)\n    shuffled_indeces = np.random.permutation(range(N))\n    new_dataset = np.array(dataset)[shuffled_indeces,:,:]\n    new_labels = np.array(labels)[shuffled_indeces,:]\n\n    num_train = int(0.8*N)\n    x_train = new_dataset[:num_train,:,:]\n    y_train = new_labels[:num_train,:]\n\n    num_val = int(0.1*len(x_train))\n\n    x_val = x_train[:num_val,:,:]\n    x_val = x_val.reshape(x_val.shape[0],x_val.shape[1],x_val.shape[2], -1)\n    y_val = y_train[:num_val,:]\n\n    x_train = x_train[num_val:,:,:]\n    x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2], -1)\n    y_train = y_train[num_val:,:]\n\n    x_test = new_dataset[num_train:,:,:]\n    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2], -1)\n    y_test = new_labels[num_train:,:]\n\n    models_dnn = DNN()\n    opt = Adam(learning_rate=0.0003)\n    models_dnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n\n    num_epochs = 100\n\n    # Checkpoint for models\n    ckpt_folder = \"dnn_models/\"\n    ckpt_file_path = 'dnn_model_SNR_{}'.format(key)\n    if not os.path.exists(ckpt_folder):\n        os.mkdir(ckpt_folder)\n    model_ckpt_callback = ModelCheckpoint(filepath=ckpt_folder+ckpt_file_path,monitor='val_loss', mode='min', save_best_only=True)\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1, epsilon=1e-4, mode='min')\n\n    history_dnn = models.fit(x_train,\n                         y_train,\n                         epochs=num_epochs,\n                         batch_size=200,\n                         callbacks = [reduce_lr_loss, model_ckpt_callback],\n                         validation_data=(x_val, y_val))\n    loss, acc = models_dnn.evaluate(x_test, y_test, verbose=2)\n    predicted_data = models_dnn.predict(x_test)\n    accuracies_All_dnn.append([acc, key])\n    print('accuracy =', acc)\n    res = np.argmax(predicted_data, 1)\n    y_test_res = np.argmax(y_test, 1)\n    results = confusion_matrix((y_test_res+1), (res+1))\n    confusion_matrices_All_dnn.append([results, key])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T01:13:29.403327Z","iopub.status.idle":"2023-04-21T01:13:29.404175Z","shell.execute_reply.started":"2023-04-21T01:13:29.403898Z","shell.execute_reply":"2023-04-21T01:13:29.403936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\nimport os\nimport pickle\nimport numpy as np\n\naccuracies_All_lstm = []\nconfusion_matrices_All_lstm = []\n\nfor key in SNRs.keys():\n    dataset = []\n    labels = []\n\n    for values in SNRs[key]:\n        labels.append(values[0])\n        dataset.append(values[1])\n\n    print('Starting training for SNR:', key)\n\n    N = len(dataset)\n    shuffled_indeces = np.random.permutation(range(N))\n    new_dataset = np.array(dataset)[shuffled_indeces,:,:]\n    new_labels = np.array(labels)[shuffled_indeces,:]\n\n    num_train = int(0.8*N)\n    x_train = new_dataset[:num_train,:,:]\n    y_train = new_labels[:num_train,:]\n\n    num_val = int(0.1*len(x_train))\n\n    x_val = x_train[:num_val,:,:]\n    x_val = x_val.reshape(x_val.shape[0],x_val.shape[1],x_val.shape[2], -1)\n    y_val = y_train[:num_val,:]\n\n    x_train = x_train[num_val:,:,:]\n    x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2], -1)\n    y_train = y_train[num_val:,:]\n\n    x_test = new_dataset[num_train:,:,:]\n    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2], -1)\n    y_test = new_labels[num_train:,:]\n\n# Build the LSTM model\n    models_lstm = Robust_LSTM()\n\n    # Compile the model\n    models_lstm.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss='categorical_crossentropy', metrics=['accuracy'])\n\n    ckpt_folder = \"lstm_models/\"\n    ckpt_file_path = 'lstm_model_SNR_{}'.format(key)\n    if not os.path.exists(ckpt_folder):\n        os.mkdir(ckpt_folder)\n    model_ckpt_callback = ModelCheckpoint(filepath=ckpt_folder+ckpt_file_path,monitor='val_loss', mode='min', save_best_only=True)\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1, epsilon=1e-4, mode='min')\n\n    history_lstm = models_lstm.fit(x_train,\n                         y_train,\n                         epochs=200,\n                         batch_size=200,\n                         callbacks = [reduce_lr_loss, model_ckpt_callback],\n                         validation_data=(x_val, y_val))\n    loss, acc = models_lstm.evaluate(x_test, y_test, verbose=2)\n    predicted_data = models_lstm.predict(x_test)\n    accuracies_All_lstm.append([acc, key])\n    print('accuracy =', acc)\n    res = np.argmax(predicted_data, 1)\n    y_test_res = np.argmax(y_test, 1)\n    results = confusion_matrix((y_test_res+1), (res+1))\n    confusion_matrices_All_lstm.append([results, key])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T01:13:29.405685Z","iopub.status.idle":"2023-04-21T01:13:29.406599Z","shell.execute_reply.started":"2023-04-21T01:13:29.406313Z","shell.execute_reply":"2023-04-21T01:13:29.406343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:52:07.474117Z","iopub.execute_input":"2023-04-22T01:52:07.475123Z","iopub.status.idle":"2023-04-22T01:52:07.532725Z","shell.execute_reply.started":"2023-04-22T01:52:07.475081Z","shell.execute_reply":"2023-04-22T01:52:07.531999Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"sequential_19\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_76 (Conv2D)          (None, 2, 128, 256)       2560      \n                                                                 \n batch_normalization_95 (Bat  (None, 2, 128, 256)      1024      \n chNormalization)                                                \n                                                                 \n max_pooling2d_76 (MaxPoolin  (None, 2, 64, 256)       0         \n g2D)                                                            \n                                                                 \n dropout_76 (Dropout)        (None, 2, 64, 256)        0         \n                                                                 \n conv2d_77 (Conv2D)          (None, 2, 64, 128)        295040    \n                                                                 \n batch_normalization_96 (Bat  (None, 2, 64, 128)       512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_77 (MaxPoolin  (None, 2, 32, 128)       0         \n g2D)                                                            \n                                                                 \n dropout_77 (Dropout)        (None, 2, 32, 128)        0         \n                                                                 \n conv2d_78 (Conv2D)          (None, 2, 32, 64)         73792     \n                                                                 \n batch_normalization_97 (Bat  (None, 2, 32, 64)        256       \n chNormalization)                                                \n                                                                 \n max_pooling2d_78 (MaxPoolin  (None, 2, 16, 64)        0         \n g2D)                                                            \n                                                                 \n dropout_78 (Dropout)        (None, 2, 16, 64)         0         \n                                                                 \n conv2d_79 (Conv2D)          (None, 2, 16, 64)         36928     \n                                                                 \n batch_normalization_98 (Bat  (None, 2, 16, 64)        256       \n chNormalization)                                                \n                                                                 \n max_pooling2d_79 (MaxPoolin  (None, 2, 8, 64)         0         \n g2D)                                                            \n                                                                 \n dropout_79 (Dropout)        (None, 2, 8, 64)          0         \n                                                                 \n flatten_19 (Flatten)        (None, 1024)              0         \n                                                                 \n dense_38 (Dense)            (None, 128)               131200    \n                                                                 \n batch_normalization_99 (Bat  (None, 128)              512       \n chNormalization)                                                \n                                                                 \n dense_39 (Dense)            (None, 11)                1419      \n                                                                 \n=================================================================\nTotal params: 543,499\nTrainable params: 542,219\nNon-trainable params: 1,280\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracies_All_cnn.sort()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:52:22.824045Z","iopub.execute_input":"2023-04-22T01:52:22.825201Z","iopub.status.idle":"2023-04-22T01:52:22.830796Z","shell.execute_reply.started":"2023-04-22T01:52:22.825151Z","shell.execute_reply":"2023-04-22T01:52:22.829425Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"accuracies_All_cnn","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:52:25.853889Z","iopub.execute_input":"2023-04-22T01:52:25.854868Z","iopub.status.idle":"2023-04-22T01:52:25.862740Z","shell.execute_reply.started":"2023-04-22T01:52:25.854813Z","shell.execute_reply":"2023-04-22T01:52:25.861419Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[[0.09954545646905899, -20],\n [0.11136363446712494, -18],\n [0.13090908527374268, -16],\n [0.20227272808551788, -14],\n [0.2690909206867218, -12],\n [0.3768181800842285, -10],\n [0.5286363363265991, -8],\n [0.6663636565208435, -6],\n [0.7404545545578003, 18],\n [0.7618181705474854, 6],\n [0.7636363506317139, -4],\n [0.7995454668998718, -2],\n [0.8045454621315002, 16],\n [0.8054545521736145, 14],\n [0.8163636326789856, 12],\n [0.821363627910614, 10],\n [0.8418181538581848, 0],\n [0.8731818199157715, 2],\n [0.8818181753158569, 4],\n [0.8822727203369141, 8]]"},"metadata":{}}]},{"cell_type":"code","source":"dic = dict()\nfor i in accuracies_All_cnn:\n    dic[i[1]] = i[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:52:27.893839Z","iopub.execute_input":"2023-04-22T01:52:27.895002Z","iopub.status.idle":"2023-04-22T01:52:27.901191Z","shell.execute_reply.started":"2023-04-22T01:52:27.894955Z","shell.execute_reply":"2023-04-22T01:52:27.899793Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"dic","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:52:28.553745Z","iopub.execute_input":"2023-04-22T01:52:28.554870Z","iopub.status.idle":"2023-04-22T01:52:28.562678Z","shell.execute_reply.started":"2023-04-22T01:52:28.554803Z","shell.execute_reply":"2023-04-22T01:52:28.561439Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{-20: 0.09954545646905899,\n -18: 0.11136363446712494,\n -16: 0.13090908527374268,\n -14: 0.20227272808551788,\n -12: 0.2690909206867218,\n -10: 0.3768181800842285,\n -8: 0.5286363363265991,\n -6: 0.6663636565208435,\n 18: 0.7404545545578003,\n 6: 0.7618181705474854,\n -4: 0.7636363506317139,\n -2: 0.7995454668998718,\n 16: 0.8045454621315002,\n 14: 0.8054545521736145,\n 12: 0.8163636326789856,\n 10: 0.821363627910614,\n 0: 0.8418181538581848,\n 2: 0.8731818199157715,\n 4: 0.8818181753158569,\n 8: 0.8822727203369141}"},"metadata":{}}]},{"cell_type":"code","source":"snr = []\nacc = []\nfor i in dic:\n    snr.append(i)\nsnr.sort()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:52:29.373749Z","iopub.execute_input":"2023-04-22T01:52:29.374432Z","iopub.status.idle":"2023-04-22T01:52:29.380388Z","shell.execute_reply.started":"2023-04-22T01:52:29.374385Z","shell.execute_reply":"2023-04-22T01:52:29.379342Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"for i in snr:\n    acc.append(dic[i])\nacc = acc[:20]","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:52:31.433962Z","iopub.execute_input":"2023-04-22T01:52:31.434329Z","iopub.status.idle":"2023-04-22T01:52:31.440868Z","shell.execute_reply.started":"2023-04-22T01:52:31.434299Z","shell.execute_reply":"2023-04-22T01:52:31.439763Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(snr,acc,color='green')\nplt.xlabel(\"SNR\")\nplt.ylabel(\"ACCURACY\")\nplt.title(\"Accuracy vs Snr for CNN model\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-22T01:52:31.953567Z","iopub.execute_input":"2023-04-22T01:52:31.954064Z","iopub.status.idle":"2023-04-22T01:52:32.233822Z","shell.execute_reply.started":"2023-04-22T01:52:31.954031Z","shell.execute_reply":"2023-04-22T01:52:32.232842Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"models_cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-21T13:46:55.405785Z","iopub.execute_input":"2023-04-21T13:46:55.406553Z","iopub.status.idle":"2023-04-21T13:46:55.462770Z","shell.execute_reply.started":"2023-04-21T13:46:55.406515Z","shell.execute_reply":"2023-04-21T13:46:55.461959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_cnn.save(\"CNN_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-04-22T02:51:23.144817Z","iopub.execute_input":"2023-04-22T02:51:23.145409Z","iopub.status.idle":"2023-04-22T02:51:23.226389Z","shell.execute_reply.started":"2023-04-22T02:51:23.145364Z","shell.execute_reply":"2023-04-22T02:51:23.224898Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1712586010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CNN_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'models_cnn' is not defined"],"ename":"NameError","evalue":"name 'models_cnn' is not defined","output_type":"error"}]},{"cell_type":"code","source":"confusion_matrices_All_cnn","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}